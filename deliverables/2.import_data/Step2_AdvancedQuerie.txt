#Query String
*&$filter=rating_average gt 3 and rating_count gt 100&$top=5

#Request URL
https://kbm-searchservice.search.windows.net/indexes/courses-index/docs?api-version=2021-04-30-Preview&search=*&%24filter=rating_average%20gt%203%20and%20rating_count%20gt%20100&%24top=5

#Results
{ "@odata.context": "https://kbm-searchservice.search.windows.net/indexes('courses-index')/$metadata#docs(*)", "value": [ { "@search.score": 1, "PartitionKey": "company-moodle", "RowKey": "17b1eedc-0e96-4e5b-8199-83a484388efe", "Key": "Y29tcGFueS1tb29kbGUxN2IxZWVkYy0wZTk2LTRlNWItODE5OS04M2E0ODQzODhlZmU1", "description": "Learn our internal best practices for using the O365 suite including email signatures, file storage and other issues", "duration": 2, "instructor": "Gerald Dominguez", "level": "beginner", "product": "O365", "rating_average": 4.6, "rating_count": 510, "role": "all", "source": "Company Moodle", "title": "O365", "url": "https://www.example.com/course10", "keyphrases": [ "internal best practices", "O365 suite", "email signatures", "file storage", "other issues" ] }, { "@search.score": 1, "PartitionKey": "company-moodle", "RowKey": "278d299e-ef0e-47fb-8e98-5a31a073519c", "Key": "Y29tcGFueS1tb29kbGUyNzhkMjk5ZS1lZjBlLTQ3ZmItOGU5OC01YTMxYTA3MzUxOWM1", "description": "For developers, learn our best practices for securely connecting to databases", "duration": 2, "instructor": "Eileen Diaz", "level": "advanced", "product": "SQL", "rating_average": 4.8, "rating_count": 115, "role": "developer", "source": "Company Moodle", "title": "Security for database code", "url": "https://www.example.com/course7", "keyphrases": [ "best practices", "developers", "databases" ] }, { "@search.score": 1, "PartitionKey": "company-moodle", "RowKey": "30e3c6e5-9415-4d85-8229-c2133203c535", "Key": "Y29tcGFueS1tb29kbGUzMGUzYzZlNS05NDE1LTRkODUtODIyOS1jMjEzMzIwM2M1MzU1", "description": "Learn the policies related to the distribution and use of computers, phones, software, and other technology", "duration": 1, "instructor": "Mike Montoya", "level": "beginner", "product": "NA", "rating_average": 4.9, "rating_count": 550, "role": "all", "source": "Company Moodle", "title": "Onboarding - Technology Policies ", "url": "https://www.example.com/course2", "keyphrases": [ "other technology", "policies", "distribution", "use", "computers", "phones", "software" ] }, { "@search.score": 1, "PartitionKey": "company-moodle", "RowKey": "5b293283-81e6-4f89-a0ab-7053988d6f6a", "Key": "Y29tcGFueS1tb29kbGU1YjI5MzI4My04MWU2LTRmODktYTBhYi03MDUzOTg4ZDZmNmE1", "description": "Learn how to track billable and non-billable hours by assigning time to projects and other relevant time codes", "duration": 1, "instructor": "Mike Montoya", "level": "beginner", "product": "NA", "rating_average": 4.8, "rating_count": 540, "role": "all", "source": "Company Moodle", "title": "Onboarding - Time Tracking ", "url": "https://www.example.com/course1", "keyphrases": [ "other relevant time codes", "non-billable hours", "projects" ] }, { "@search.score": 1, "PartitionKey": "company-moodle", "RowKey": "9700e1dc-b293-4306-9e1b-0d345863db54", "Key": "Y29tcGFueS1tb29kbGU5NzAwZTFkYy1iMjkzLTQzMDYtOWUxYi0wZDM0NTg2M2RiNTQ1", "description": "This course will teach you the specific ways our company uses Git. You will learn details for comments, branching, pull requests, and other procsses", "duration": 3, "instructor": "Claudia Blackman", "level": "beginner", "product": "git", "rating_average": 4.5, "rating_count": 125, "role": "developer", "source": "Company Moodle", "title": "Git Workflow ", "url": "https://www.example.com/course3", "keyphrases": [ "specific ways", "other procsses", "course", "company", "Git", "details", "comments", "requests" ] } ] }




#Query String
*&$select=title,rating_average,instructor&$facet=rating_average&$filter=level eq 'advanced'

#Request URL
https://kbm-searchservice.search.windows.net/indexes/courses-index/docs?api-version=2021-04-30-Preview&search=*&%24filter=rating_average%20gt%203%20and%20rating_count%20gt%20100&%24top=5

#Results
{ "@odata.context": "https://kbm-searchservice.search.windows.net/indexes('courses-index')/$metadata#docs(*)", "value": [ { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.8, "title": "Security for database code" }, { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.3, "title": "Security for database admins" }, { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.2, "title": "Encryption and security" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "title": "Secure Cognitive Services" } ] }




#Query String
*&$select=title,rating_average,instructor,role&facet=role&$filter=instructor ne null

#Request URL
https://kbm-searchservice.search.windows.net/indexes/courses-index/docs?api-version=2021-04-30-Preview&search=*&%24select=title%2Crating_average%2Cinstructor%2Crole&facet=role&%24filter=instructor%20ne%20null

#Results
{ "@odata.context": "https://kbm-searchservice.search.windows.net/indexes('courses-index')/$metadata#docs(*)", "@search.facets": { "role": [ { "count": 174, "value": "developer" }, { "count": 130, "value": "solution-architect" }, { "count": 108, "value": "business-user" }, { "count": 106, "value": "devops-engineer" }, { "count": 105, "value": "administrator" }, { "count": 75, "value": "functional-consultant" }, { "count": 56, "value": "data-scientist" }, { "count": 56, "value": "maker" }, { "count": 56, "value": "student" }, { "count": 47, "value": "ai-engineer" } ] }, "value": [ { "@search.score": 1, "instructor": "Gerald Dominguez", "rating_average": 4.6, "role": "all", "title": "O365" }, { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.8, "role": "developer", "title": "Security for database code" }, { "@search.score": 1, "instructor": "Mike Montoya", "rating_average": 4.9, "role": "all", "title": "Onboarding - Technology Policies " }, { "@search.score": 1, "instructor": "Robert Gillis", "rating_average": 3.9, "role": "developer", "title": "Maps" }, { "@search.score": 1, "instructor": "Claudia Blackman", "rating_average": 4.9, "role": "admin", "title": "DevOps for Ops" }, { "@search.score": 1, "instructor": "Mike Montoya", "rating_average": 4.8, "role": "all", "title": "Onboarding - Time Tracking " }, { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.3, "role": "architect", "title": "Ethics in AI" }, { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.3, "role": "admin", "title": "Security for database admins" }, { "@search.score": 1, "instructor": "Claudia Blackman", "rating_average": 4.5, "role": "developer", "title": "Git Workflow " }, { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.2, "role": "architect", "title": "Encryption and security" }, { "@search.score": 1, "instructor": "Claudia Blackman", "rating_average": 3.8, "role": "developer", "title": "DevOps for Dev" }, { "@search.score": 1, "instructor": "Gerald Dominguez", "rating_average": 4.7, "role": "all", "title": "Remote work" }, { "@search.score": 1, "instructor": "Mike Montoya", "rating_average": 4.6, "role": "all", "title": "Workplace Health" }, { "@search.score": 1, "instructor": "Eileen Diaz", "rating_average": 4.4, "role": "developer", "title": "Code security" }, { "@search.score": 1, "instructor": "", "rating_average": 4.73, "role": "solution-architect", "title": "Run quality tests in your build pipeline by using Azure Pipelines" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "role": "functional-consultant", "title": "Enable business users with key AI use cases" }, { "@search.score": 1, "instructor": "", "rating_average": 4.71, "role": "business-user", "title": "Define an AI strategy to create business value" }, { "@search.score": 1, "instructor": "", "rating_average": 4.77, "role": "developer", "title": "Manage your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "role": "ai-engineer", "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps" }, { "@search.score": 1, "instructor": "", "rating_average": 4.61, "role": "business-user", "title": "Get started with AI Builder Text recognition" }, { "@search.score": 1, "instructor": "", "rating_average": 4.67, "role": "ai-engineer", "title": "Add conversational intelligence to your apps by using Language Understanding Intelligent Service (LUIS)" }, { "@search.score": 1, "instructor": "", "rating_average": 4.77, "role": "solution-architect", "title": "Add basic conversational intelligence to your apps by using Language Understanding Intelligent Service (LUIS)" }, { "@search.score": 1, "instructor": "", "rating_average": 4.7, "role": "developer", "title": "Characterize DevOps Continuous Collaboration and Continuous Improvement" }, { "@search.score": 1, "instructor": "", "rating_average": 4.77, "role": "developer", "title": "Add basic conversational intelligence to your apps by using Language Understanding Intelligent Service (LUIS)" }, { "@search.score": 1, "instructor": "", "rating_average": 4.9, "role": "solution-architect", "title": "Automate Node.js deployments with Azure Pipelines" }, { "@search.score": 1, "instructor": "", "rating_average": 4.72, "role": "administrator", "title": "Manage release cadence in Azure Pipelines by using deployment patterns" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "role": "developer", "title": "Manage repository changes by using pull requests on GitHub" }, { "@search.score": 1, "instructor": "", "rating_average": 4.88, "role": "solution-architect", "title": "Contribute to an open-source project on GitHub" }, { "@search.score": 1, "instructor": "", "rating_average": 4.73, "role": "maker", "title": "Implement robotic process automation with Microsoft Power Automate, Teams, desktop flow, and AI Builder" }, { "@search.score": 1, "instructor": "", "rating_average": 5, "role": "administrator", "title": "Get started with Git and GitHub in Visual Studio" }, { "@search.score": 1, "instructor": "", "rating_average": 4.78, "role": "data-scientist", "title": "Get started with AI on Azure" }, { "@search.score": 1, "instructor": "", "rating_average": 4.82, "role": "developer", "title": "Introduction to GitHub in Visual Studio Code" }, { "@search.score": 1, "instructor": "", "rating_average": 4.65, "role": "developer", "title": "Build an AI web app by using Python and Flask" }, { "@search.score": 1, "instructor": "", "rating_average": 4.7, "role": "devops-engineer", "title": "Automate multi-container Kubernetes deployments with Azure Pipelines" }, { "@search.score": 1, "instructor": "", "rating_average": 4.69, "role": "business-user", "title": "Introduce the foundation pillars of DevOps: Culture and Lean Product" }, { "@search.score": 1, "instructor": "", "rating_average": 4.66, "role": "administrator", "title": "Run functional tests in Azure Pipelines" }, { "@search.score": 1, "instructor": "", "rating_average": 4.78, "role": "devops-engineer", "title": "Automate Python deployments with Azure Pipelines" }, { "@search.score": 1, "instructor": "", "rating_average": 4.75, "role": "devops-engineer", "title": "Manage an InnerSource program by using GitHub" }, { "@search.score": 1, "instructor": "", "rating_average": 4.74, "role": "functional-consultant", "title": "Understand the importance of building an AI-ready culture" }, { "@search.score": 1, "instructor": "", "rating_average": 4.73, "role": "ai-engineer", "title": "Analyze images with the Computer Vision service" }, { "@search.score": 1, "instructor": "", "rating_average": 4.7, "role": "business-user", "title": "Characterize DevOps Continuous Collaboration and Continuous Improvement" }, { "@search.score": 1, "instructor": "", "rating_average": 4.62, "role": "developer", "title": "Use Azure Pipelines for CI/CD with Business Central" }, { "@search.score": 1, "instructor": "", "rating_average": 4.71, "role": "administrator", "title": "Automate development tasks by using GitHub Actions" }, { "@search.score": 1, "instructor": "", "rating_average": 4.68, "role": "data-scientist", "title": "Track wild polar bears with AI" }, { "@search.score": 1, "instructor": "", "rating_average": 4.88, "role": "administrator", "title": "Contribute to an open-source project on GitHub" }, { "@search.score": 1, "instructor": "", "rating_average": 4.71, "role": "developer", "title": "Leverage GitHub Actions to publish to GitHub Packages" }, { "@search.score": 1, "instructor": "", "rating_average": 4.65, "role": "solution-architect", "title": "Manage database changes in Azure Pipelines" }, { "@search.score": 1, "instructor": "", "rating_average": 4.73, "role": "developer", "title": "Analyze DevOps Continuous Planning and Continuous Integration" }, { "@search.score": 1, "instructor": "", "rating_average": 4.5, "role": "solution-architect", "title": "Azure Kubernetes Service deployment pipeline and GitHub Actions" }, { "@search.score": 1, "instructor": "", "rating_average": 4.82, "role": "business-user", "title": "Discover Microsoft guidelines for responsible conversational AI development" } ], "@odata.nextLink": "https://kbm-searchservice.search.windows.net/indexes('courses-index')/docs?api-version=2021-04-30-Preview&search=%2A&$select=title%2Crating_average%2Cinstructor%2Crole&facet=role&$filter=instructor%20ne%20null&$skip=50" }




#Query String
*&$select=title,rating_average,instructor,role,level&facetrole&$filter=instructor eq 'Eileen Diaz'&$orderby=rating_average

#Request URL
https://kbm-searchservice.search.windows.net/indexes/courses-index/docs?api-version=2021-04-30-Preview&search=*&%24select=title%2Crating_average%2Cinstructor%2Crole%2Clevel&facetrole&%24filter=instructor%20eq%20'Eileen%20Diaz'&%24orderby=rating_average

#Results
{ "@odata.context": "https://kbm-searchservice.search.windows.net/indexes('courses-index')/$metadata#docs(*)", "value": [ { "@search.score": 1, "instructor": "Eileen Diaz", "level": "advanced", "rating_average": 4.2, "role": "architect", "title": "Encryption and security" }, { "@search.score": 1, "instructor": "Eileen Diaz", "level": "intermediate", "rating_average": 4.3, "role": "architect", "title": "Ethics in AI" }, { "@search.score": 1, "instructor": "Eileen Diaz", "level": "advanced", "rating_average": 4.3, "role": "admin", "title": "Security for database admins" }, { "@search.score": 1, "instructor": "Eileen Diaz", "level": "intermediate", "rating_average": 4.4, "role": "developer", "title": "Code security" }, { "@search.score": 1, "instructor": "Eileen Diaz", "level": "advanced", "rating_average": 4.8, "role": "developer", "title": "Security for database code" } ] }




#Query String
"machine learning"&facet=metadata_author&$top=5

#Request URL
https://kbm-searchservice.search.windows.net/indexes/papers-index/docs?api-version=2021-04-30-Preview&search=%22machine%20learning%22&facet=metadata_author&%24top=5

#Results
{ "@odata.context": "https://kbm-searchservice.search.windows.net/indexes('papers-index')/$metadata#docs(*)", "@search.facets": { "metadata_author": [ { "count": 1, "value": " Shun Kodate " }, { "count": 1, "value": "Administrator" }, { "count": 1, "value": "Alina Köchling " }, { "count": 1, "value": "Boping Zhang" }, { "count": 1, "value": "Ferdousi Sabera Rawnaque " }, { "count": 1, "value": "Haoliang Cui" }, { "count": 1, "value": "Iqbal H. Sarker " }, { "count": 1, "value": "Muhammad Taimoor Khan" }, { "count": 1, "value": "P. Ram Mohan Rao " }, { "count": 1, "value": "Rik Das" } ] }, "value": [ { "@search.score": 2.5234547, "content": "\nContext‑aware rule learning \nfrom smartphone data: survey, challenges \nand future directions\nIqbal H. Sarker1,2*\n\nIntroduction\nIn recent days, smartphones have become an essential part of our daily life and con-\nsidered as highly personal devices of individuals. These devices are also known as one \nof the most important IoT (Internet of Things) devices, because of their capabilities \nto interconnect their users with the Internet, and corresponding data processing [1]. \nSmartphones are also considered as “next generation, multifunctional cell phones that \nfacilitates data processing as well as enhanced wireless connectivity” [2]. The cellular net-\nwork coverage has reached 96.8% of the world population, and this number even reaches \n100% of the population in the developed countries [3]. In recent statistics, according to \nGoogle Trends [4] we have shown in Fig.  1, that users’ interest on “Mobile Phones” is \nmore and more than other platforms like “Desktop Computer”, “Laptop Computer” or \n\nAbstract \n\nSmartphones are considered as one of the most essential and highly personal devices \nof individuals in our current world. Due to the popularity of context-aware technol-\nogy and recent developments in smartphones, these devices can collect and process \nraw contextual data about users’ surrounding environment and their corresponding \nbehavioral activities with their phones. Thus, smartphone data analytics and building \ndata-driven context-aware systems have gained wide attention from both academia \nand industry in recent days. In order to build intelligent context-aware applications on \nsmartphones, effectively learning a set of context-aware rules from smartphone data \nis the key. This requires advanced data analytical techniques with high precision and \nintelligent decision making strategies based on contexts. In comparison to traditional \napproaches, machine learning based techniques provide more effective and efficient \nresults for smartphone data analytics and corresponding context-aware rule learning. \nThus, this article first makes a survey on previous work in the area of contextual smart-\nphone data analytics and then presents a discussion of challenges and future directions \nfor effectively learning context-aware rules from smartphone data, in order to build \nrule-based automated and intelligent systems.\n\nKeywords: Smartphone data, Machine learning, Data science, Clustering, \nClassification, Association, Rule learning, Personalization, Time-series, User behavior \nmodeling, Predictive analytics, Context-aware computing, Mobile and IoT services, \nIntelligent systems\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nSarker J Big Data (2019) 6:95 \nhttps://doi.org/10.1186/s40537‑019‑0258‑4\n\n*Correspondence: \nmsarker@swin.edu.au \n1 Swinburne University \nof Technology, \nMelbourne VIC-3122, \nAustralia\nFull list of author information \nis available at the end of the \narticle\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0258-4&domain=pdf\n\n\nPage 2 of 25Sarker J Big Data (2019) 6:95 \n\n“Tablet Computer” for the last 5 years from 2014 to 2019. Figure 1 represents timestamp \ninformation in terms of particular date in x-axis and corresponding search interests in \nthe range of 0 to 100 in terms of popularity relative to the highest point on the chart in \ny-axis. For instance, a value of 100 (maximum) in y-axis represents the peak popularity \nfor a particular term, while 0 (minimum) means the term was lowest in terms of popu-\nlarity [4].\n\nDue to the advanced features and recent developments in smartphones, these devices \ncan collect raw contextual data about users’ surrounding environment and their corre-\nsponding behavioral activities with their phones in a daily basis [5]. As a result, smart-\nphone data becomes a great source to understand users’ behavioral activity patterns in \ndifferent contexts, and to derive useful information, i.e., context-aware rules, for the pur-\npose of building rule-based intelligent context-aware systems. A context-aware rule has \ntwo parts, which follows “IF-THEN” logical structure to formulate [6]. The antecedent \npart represents users’ surrounding contextual information, e.g., temporal context, spa-\ntial context, social contexts, or others relevant contextual information and the conse-\nquent part represents their corresponding behavioral activities or usage. Let’s consider \nan example of a context-aware mobile notification management system for a smart-\nphone user Alice. A context-aware rule for such system could be “The user typically \ndismisses mobile notifications while at work; however, accepts the notifications in the \nevening from her family members, even though she is in work”. A set of such context-\naware behavioral rules including general and specific exceptions, may vary from user-to-\nuser according to their preferences. In addition to the personalized services mentioned \nabove, the relevant context-aware rules in different surrounding contexts could be appli-\ncable to other broad application areas, like context-aware  software and IoT services, \nintelligent eHealth services, and context-aware smart city services, intelligent cybersecu-\nrity services etc. utilizing the relevant contextual data of that particular domain. Overall, \nthis study is typically for those data science and machine learning researchers, and prac-\ntitioners who particularly want to work on data-driven intelligent context-aware systems \nand services based on machine learning rules.\n\nEffectively learning context-aware rules from smartphone data is challenging because \nof many reasons, ranging from understanding raw data to applications. A number of \nresearch [7–9] has been done on mining context-aware rules from smartphone data for \nvarious purposes. However, to effectively learn such rules for the purpose of building \n\nFig. 1 Users’ interest trends over time, where x-axis and y-axis represent a particular timestamp and \ncorresponding search interests in numeric values in terms of world-wide popularity respectively\n\n\n\nPage 3 of 25Sarker J Big Data (2019) 6:95 \n\nintelligent context-aware systems, a deeper analysis in contextual data patterns and \nlearning according to individuals’ usage is needed. Thus, advanced data analysis based \non machine learning techniques, can be used to make effective and efficient decision-\nmaking capabilities in different context-aware test cases for smartphones. Several \nmachine learning and data mining techniques, such as contextual data clustering, fea-\nture optimization and selection, rule-based classification and association analysis, incre-\nmental learning for dynamic updating and management, and corresponding rule-based \nprediction model can be designed to provide smartphone data analytic solutions. The \nreason is that such machine learning techniques can be more accurate, and more precise \nfor analyzing huge amount of contextual data. The aim of these advanced analytic tech-\nniques is to discover information, hidden patterns, and unknown correlations among the \ncontexts and eventually generate context-aware rules. For instance, a detailed analysis \nof time-series data and corresponding data clustering based on similar behavioral pat-\nterns, could lead to capture the diverse behaviors of an individual’s activities, thereby \nenabling more optimal time-based context-aware rules than the traditional approaches \n[10]. Thus, intelligent data-driven decisions using machine learning techniques can \nprofit better decision making capability over the traditional approaches while consider-\ning the multi-dimensional contexts.\n\nBased on our survey and analysis on existing research, little work has been done in \nterms of how machine learning techniques significantly impact on contextual smart-\nphone data and to learn corresponding context-aware rules. To address this short-\ncoming, this article first makes a survey on previous work in the area of contextual \nsmartphone data analytics in several perspectives involved in context-aware rules, such \nas time-series modeling that is also known as a discretization of temporal context, rule \ndiscovery techniques, and incremental learning and rule updation techniques, which has \nbeen highlighted in our earlier work [6]. After that this article presents a brief discussion \non challenges and future directions to overcome these issues. Based on our discussion, \nfinally we suggest a machine learning based context-aware rule learning framework for \nthe purpose of effectively learning context-aware rules from smartphone data, in order \nto build rule-based automated and intelligent systems.\n\nThe contributions of this paper are summarized as follows.\n\n• We first make a brief survey on previous work in the area of smartphone data analyt-\nics in several perspectives related to context-aware rule learning and summarize the \nshortcomings of these research.\n\n• We then present a brief discussion on the challenges and future directions to over-\ncome the issues to learn context-aware rules from smartphone data.\n\n• Finally, we suggest a machine learning based context-aware rule learning framework \nand briefly discuss the role of various layers associated with the framework, for the \npurpose of building rule-based intelligent context-aware systems.\n\nTo the best of our knowledge, this is the first article surveying context-aware rule learn-\ning strategies from smrtphone data. The remainder of the paper is organized as follows. \n“Background: contexts and smartphone data” section presents background information \non contexts and contextual smartphone data. “Context-aware rule learning strategies” \n\n\n\nPage 4 of 25Sarker J Big Data (2019) 6:95 \n\nsection  surveys previous work in various perspectives related to context-aware rule \nlearning. “Challenges and future directions” section briefly discusses the challenges and \nfuture directions of research regarding context-aware rule learning from smartphone \ndata. In “Suggested machine learning based framework” section we suggest a machine \nlearning based context-aware rule learning framework and discuss various layers with \ntheir roles while learning rules. Context-aware rule based applications section summa-\nrizes a number of real world applications based on context-aware rules. Finally, “Conclu-\nsion” section concludes this paper.\n\nBackground: contexts and smartphone data\nThis section reviews background information on the main characteristics of contexts \nand contextual smartphone data that address learning context-aware rules for the pur-\npose of building rule-based intelligent systems.\n\nCharacteristics of contexts\n\nThe term context can be used with a variety of different meanings in different purposes. \nThe notion of context has been used in numerous areas, including Pervasive and Ubiq-\nuitous Computing, Human Computer Interaction, Computer-Supported Collaborative \nWork, and Ambient Intelligence [11]. In this section, first we briefly review what is con-\ntext in the area of mobile and context-aware computing. In Ubiquitous and Pervasive \nComputing area, early works on context-awareness referred to context as primarily \nthe location of people and objects [12]. In recent works, context has been extended to \ninclude a broader collection of factors, such as physical and social aspects of an entity, \nas well as the activities of users [11]. Having examined the definitions and categories of \ncontext given by the pervasive and ubiquitous computing community, this section seeks \nto define our view of context within the scope of smartphone data analytics. As the defi-\nnitions of context to pervasive and ubiquitous computing area are also broad, this dis-\ncussion is intended to be illustrative rather than exhaustive.\n\nSeveral studies have attempted to define and represent the context from different \nperspectives. For instance, the user’s location information, the surrounding people and \nobjects around the user, and the changes to those objects are considered as contexts by \nSchilit et al. [12]. Brown et al. [13] also define contexts as user’s locational information, \ntemporal information, the surrounding people around the user, temperature, etc. Simi-\nlarly, the user’s locational information, environmental information, temporal informa-\ntion, user’s identity, are also taken into account as contexts by Ryan et  al. [14]. Other \ndefinitions of context have simply provided synonyms for context such as context as the \nenvironment or social situation. A number of researchers are taken into account the \ncontext as the environmental information of the user. For instance, in [15], the environ-\nmental information that the user’s computer knows about are taken into account as con-\ntext by Brown et al., whereas the social situation of the user is considered as a context \nin Franklin et al. [16]. On the other hand, a number of other researchers consider it to \nbe the environment related to the applications. For instance, Ward et al. [17] consider \nthe state of the surrounding information of the applications as contexts. Hull et al. [18] \ndefine context as the aspects of the current situation of the user and include the entire \n\n\n\nPage 5 of 25Sarker J Big Data (2019) 6:95 \n\nenvironment. The settings of applications are also treated as context in Rodden et  al. \n[19].\n\nAccording to Schilit et  al. [20] the important aspects of context are: (i) where you \nare, (ii) whom you are with, and (iii) what resources are nearby. The information of the \nchanging environment is taken into account as context in their definition. In addition to \nthe user environment (e.g., user location, nearby people around the user, and the cur-\nrent social situation of the user), they also include the computing environment and the \nphysical environment. For instance, connectivity, available processors, user input and \ndisplay, network capacity, and costs of computing can be the examples of the computing \nenvironment, while the noise level, temperature, the lighting level, can be the examples \nof the physical environment. Dey et al. [21] present a survey of alternative view of con-\ntext, which are largely imprecise and indirect, typically defining context by synonym or \nexample. Finally, they offer the following definition of context, which is perhaps now the \nmost widely accepted. According to Dey et al. [21] “Context is any information that can \nbe used to characterize the situation of an entity. An entity is person, place or object \nthat is considered relevant to the interaction between a user and an application, includ-\ning the user and the application themselves”. Thus, based on the definition of Dey et al. \n[21], we can define context in the scope of this work as “Context is any information that \ncan be used to characterize users’ day-to-day situations that have an influence on their \nsmartphone usage”. An example of relevant contexts could be temporal context, spatial \ncontext, or social context etc. that might have an influence to make individuals’ diverse \ndecisions on smartphone usage in their daily life activities.\n\nContextual smartphone data\n\nWe live in the age of data [22], where everything that surrounds us is linked to a data \nsource and everything in our lives is captured digitally. Mobile or cellular phones have \nbecome increasingly ubiquitous and powerful to log user diverse activities for under-\nstanding their preferences and phone usage behavior. For instance, smart mobile phones \nhave the ability to log various types of context data related to a user’s phone call activities \nabout when the user makes outgoing calls, or accepts, rejects, and misses the incoming \ncalls [23–26]. In addition to such call related meta data, other dimensions of contex-\ntual information such as user location [27], user’s day-to-day situation [28], the social \nrelationship between the caller an callee identified by the individual’s unique phone \ncontact number [29] are also recorded by the smart mobile phones. Thus, call log data \ncollected by the smart mobile phone can be used as a context source to modeling indi-\nvidual mobile phone user behavior in smart context-aware mobile communication sys-\ntems [30]. In addition to voice communication, short message service (SMS) is known \nas text communication service allows the exchange of short text messages of individual \nmobile phone users, using standardized communications rules or protocols. According \nto the International Telecommunication Union [31], short messages have become a mas-\nsive commercial industry, worth over 81 billion dollars globally. The numerous growth \nin the number of mobile phone users in the world has lead to a dramatic increasing of \nspam messages [32]. The SMS log contains all the message including the spam and non-\nspam text messages [32, 33], which can be used in the task of automatic spam filtering \n[25, 32], or predicting good time or bad time to deliver such messages [33].\n\n\n\nPage 6 of 25Sarker J Big Data (2019) 6:95 \n\nWith the rapid development of smartphones, people use these devices for using vari-\nous categories of apps such as Multimedia, Facebook, Gmail, Youtube, Skype, Game [9, \n34]. Thus, smartphone apps log contains these usage with relevant contextual informa-\ntion [8, 9, 35–37]. Such logs can be used for mining the contextual behavioral patterns of \nindividual mobile phone users that is, which app is preferred by a particular user under \na certain context to provide personalized context-aware recommendation. In the real \nworld, a variety of smart mobile applications use notifications in order to inform the \nusers about various kinds of events, news or just to send them reminders or alerts. For \ninstance, the notifications of inviting games on social networks, social or promotional \nemails, or a number of predictive suggestions by various smart phone applications, \ne.g., Twitter, Facebook, LinkedIN, WhatsApp, Viver, Skype, Youtube [7]. The extracted \ncontextual patterns from smartphone notification logs can be used to build intelligent \nmobile notification management systems according to their preferences.\n\nUser navigation in the web in another major activities of individual users. Thus, web \nlog contains the information about user mobile web navigation, web searching, e-mail, \nentertainment, chat, misc, news, TV, netting, travel, sport, banking, and related contex-\ntual information [38–40]. Mining contextual usage patterns from such log data, can be \nused to make accurate context-aware predictions about user navigation and to adapt the \nportal structure according to the needs of users. Similarly, game log contains the infor-\nmation about playing various types such games such as action, adventure, casual, puzzle, \nRPG, strategy, sports etc. of individual mobile phone users, and related contextual infor-\nmation [41]. The extracted contextual patterns from such logs data, can be used to build \npersonalized mobile game recommendation system for individual mobile phone users \naccording to their own preferences.\n\nThe ubiquity of smart mobile phones and their computing capabilities for various real \nlife purposes provide an opportunity of using these devices as a life-logging device, i.e., \npersonal e-memories [42]. In a more technical sense, life-logs sense and store individ-\nual’s contextual information from their surrounding environment through a variety of \nsensors available in their smart mobile phones, which are the core components of life-\nlogs such as user phone calls, SMS headers (no content), App use (e.g., Skype, What-\nsapp, Youtube etc.), physical activities form Google play API, and related contextual \ninformation such as WiFi and Bluetooth devices in user’s proximity, geographical loca-\ntion, temporal information [42]. The extracted contextual patterns or behavioral rules of \nindividual mobile phone users utilizing such life log data, can be used to improve user \nexperience in their daily life. In addition to these personalized log data, smartphones are \nalso capable for collecting and processing IoT data [1]. Based on such smartphone data \nhaving contextual information, in this paper, we briefly review the existing rule learn-\ning strategies and discuss the open challenges and opportunities by highlighting future \ndirections for context-aware rule learning.\n\nContext‑aware rule learning strategies\nIn this section, we review existing strategies related to learning rules based on contex-\ntual information in various perspectives. This includes time-series modeling that cre-\nates behavioral data clusters for generating temporal context based rules, contextual rule \n\n\n\nPage 7 of 25Sarker J Big Data (2019) 6:95 \n\ndiscovery by taking into account multi-dimensional contexts, such as temporal, spatial \nor social contexts, and incremental learning to dynamic updating of rules.\n\nModeling time‑series smartphone data\n\nTime is the most important context that impacts on mobile user behavior for making \ndecisions [38]. Individual’s behaviors vary over time in the real world and the mobile \nphones record the exact time of all diverse activities of the users with their mobile \nphones. A time series is a sequence of data points ordered in time [43]. However, to use \nsuch time-series data into behavioral rules, an effective modeling of temporal context \nis needed. Thus, time-series segmentation becomes one of the research focuses in this \nstudy as exact time in mobile phone data is not very informative to mine behavioral rules \nof individual mobile phone users. According to [44], time-based behavior modeling is an \nopen problem. Hence, we summarize the existing time-series segmentation approaches \n\nTable 1 Various types of static time segments used in different applications\n\nTime interval type Number \nof segments\n\nUsed time interval and segment details References\n\nEqual 3 Morning [7:00–12:00], afternoon [13:00–18:00] and \nevening [19:00–24:00]\n\nSong et al. [46]\n\nEqual 3 [0:00–7:59], [8:00–15:59] and [16:00–23:59] Rawassizadeh et al. [47]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nMukherji et al. [48]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nBayir et al. [49]\n\nEqual 4 Morning, afternoon, evening and night Paireekreng et al. [41]\n\nEqual 4 Morning [6:00–11:59], day [12:00–17:59], evening \n[18:00–23:59], overnight [0:00–5:59]\n\nJayarajah et al. [50]\n\nEqual 4 Night [0:00–6:00 a.m.], morning [6:00 a.m.–12:00 \np.m.], afternoon [12:00–6:00 p.m.], and evening \n[6:00 p.m.–0:00 a.m.]\n\nDo et al. [51]\n\nUnequal 3 Morning (beginning at 6:00 a.m. and ending at \nnoon), afternoon (ending at 6:00 p.m.), night (all \nremaining hours)\n\nXu et al. [52]\n\nUnequal 4 Morning [6:00–12:00], afternoon [12:00–16:00], \nevening [16:00–20:00] and night [20:00–24:00 \nand 0:00–6:00]\n\nMehrotra et al. [7]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00] and so on\n\nZhu et al. [9]\n\nUnequal 5 Morning, forenoon, afternoon, evening, and night Oulasvirta et al. [53]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00], evening [18:00–21:00], and \nnight [21:00–Next day 7:00]\n\nYu et al. [54]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nNaboulsi et al. [55]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nDashdorj et al. [56]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nShin et al. [57]\n\nUnequal 8 S1[0:00–7:00 a.m.], S2[7:00–9:00 a.m.], S3[9:00–\n11:00 a.m.], S4[11:00 a.m.–2:00 p.m.], S5[2:00–\n5:00 p.m.], S6[5:00–7:00 p.m.], S7[7:00–9:00 p.m.] \nand S8[9:00 p.m.–12:00 a.m.]\n\nFarrahi et al. [58]\n\n\n\nPage 8 of 25Sarker J Big Data (2019) 6:95 \n\ninto two broad categories; (i) static segmentation, and (ii) dynamic segmentation, that \nare used in various mobile applications.\n\nStatic segmentation\n\nA static segmentation is easy to understand and can be useful to analyze population \nbehavior comparing across the mobile phone users. In order to generate segments, \nrecently, most of the researchers (shown in Table 1) take into account only the temporal \ncoverage (24-h-a-day) and statically segment time into arbitrary categories (e.g., morn-\ning) or periods (e.g., 1 h). Such static segmentation of time mainly focuses on time inter-\nvals. According to [45], there are mainly two types of time intervals: one is equal and \nanother one is unequal. For instance, four different time segments, i.e., morning [6:00–\n12:00], afternoon [12:00–18:00], evening [18:00–24:00] and night [0:00–6:00] can be an \nexample of equal interval based segmentation because of their same interval length. On \nthe other hand, another four time slots such as morning [6:00–12:00], afternoon [12:00–\n16:00], evening [16:00–20:00] and night [20:00–24:00 and 0:00–6:00] can be an example \nof unequal interval based segmentation. For this example, different lengths of time inter-\nval are used to do the segmentation. In Table 1, we have summarized a number of works \nthat use static segmentation considering either equal or unequal time interval in various \npurposes.\n\nAlthough, various time intervals and corresponding segmentation summarized in \nTable 1 are used in different purposes, these approaches take into account a fixed num-\nber of segments for all users. However, while performing such segmentation users’ behav-\nioral evidence that differs from user-to-user over time in the real world, is not taken into \naccount. Thus, these static generation of segments may not suitable for producing high \nconfidence temporal rules for individual smartphone users. For instance, N1 number \nof segments might give meaningful results for one case, while N2 number of segments \ncould give better results for another case, where N1 = N2 . Therefore, a dynamic segmen-\ntation of time rather than statically generation could be able to reflect individuals’ behav-\nioral evidence over time and can play a role to produce high confidence rules according \nto their usage records.\n\nDynamic segmentation\n\nAs discussed above, a segmentation technique that generates variable number of seg-\nments would be more meaningful to model users’ behavior. Thus, dynamic segmenta-\ntion technique rather than static segmentation can be used in order to achieve the goal. \nIn a dynamic segmentation, the number of segments are not fixed and predefined; may \nchange depending on their behavioral characteristics, patterns or preferences. Several \ndynamic segmentation techniques in terms of generating variable number of segments \nexist for modeling users’ behavioral activities in temporal contexts. A number of authors \nsimply take into account a single parameter, e.g., interval length or base period, to gener-\nate the segments. The number of time segments varies according to this period. If Tmax \nrepresents the whole time period of 24-h-a-day and BP is a base period, then the num-\nber of segments will be Tmax/BP [10]. If the base period increases, the number of time \nsegments decreases and vice-versa. For instance, if the base period is 5 min, then the \nnumber of segments will be the division result of 24-h-a-day and 5. In this example, a \n\n\n\nPage 9 of 25Sarker J Big Data (2019) 6:95 \n\nbase period, e.g., 5 min, is assumed as the finest granularity to distinguish day-to-day \nactivities of an individual. If the base period incremented to 15 min, then the number \nof segments decreases, where 15 min can be assumed as the finest granularity. Thus the \nnumber of segments varies based on the base time period. Similarly, individuals’ calen-\ndar schedules and corresponding time boundaries can also be used to determine var-\niable length of time segments, in order to model users’ behavior in temporal context, \nwhich may vary according to users’ preferences [59]. For instance, one user may have a \nparticular event between 1 and 2 p.m., while another may have in another time bound-\nary between 1:30 and 2:30 p.m.. Thus, the time segmentation varies according to their \ndaily life activities scheduled in their personal calendars. Similarly, multiple thresholds, \nsliding window, data shape based approaches are used in several applications, shown \nin Table 2. In addition to these approaches, a number of authors use machine learning \ntechniques such as clustering, genetic algorithm etc. In Table  2, we have summarized \na number of works that use such type of dynamic segmentation techniques in various \npurposes.\n\nClustering highlighted in Table  2 is one of the important machine learning tech-\nniques in forming large time segments where certain user behavior patterns are taken \ninto account. Usually, clustering algorithms are designed with certain assumptions and \nfavor certain type of problems. In this sense, it is not accurate to say ‘best’ in the con-\ntext of clustering algorithms; it depends on specific application [75]. Among the cluster-\ning algorithms the K-means algorithm is the best-known squared error-based clustering \nalgorithm [76]. However, this algorithm needs to specify the initial partitions and fixed \nnumber of clusters K. The convergence centroids also vary with different initial points. \nSometimes this algorithm is influenced by outliers because of mean value calculation. \n\nTable 2 Various types of dynamic time segments used in different applications\n\nBase technique Description References\n\nSingle parameter A predefined value of time interval, e.g., 15 min \nis used to generate segments\n\nOzer et al. [60]\n\nA different value of time interval, e.g., 30 min is \nused for segmentation\n\nDo et al. [61], Farrahi et al. [62]\n\nA relatively large value of the parameter, e.g., \n2-h is used to generate time segments\n\nKaratzoglou et al. [63]\n\nAnother large value of time interval, e.g., 3-h is \nused for segmentation to make the number \nof segments small\n\nPhithakkitnukoon et al. [64]\n\nCalendar Various calendar schedules and corresponding \ntime boundaries are used to model users’ \nbehavior in temporal context\n\nKhail et al. [65], Dekel et al. [66], Zulkernain \net al. [67], Seo et al. [68], Sarker et al. [28, \n59]\n\nMulti-thresholds To identify the lower and upper boundary \nof a particular segment for the purpose of \nsegmenting time-series log data\n\nHalvey et al. [38]\n\nData shape A data shape based time-series data analysis Zhang et al. [45], Shokoohi et al. [69]\n\nSliding window A sliding window is used to analyze time-series \ndata\n\nHartono et al. [70], Keogh et al. [71]\n\nClustering A predefined number of clusters is used to \ndiscover rules from time-series data\n\nDas et al. [72]\n\nGenetic algorithm A genetic algorithm is used to analyze time-\nseries data\n\nLu et al. [73], Kandasamy et al. [74]\n\n\n\nPage 10 of 25Sarker J Big Data (2019) 6:95 \n\nMore importantly, the characteristic of this algorithm might not be directly applicable \nfor the purpose of learning  context-aware rules. The reason is that users’ behave dif-\nferently in different contexts, which also may vary from user-to-user in the real world. \nThus, it’s difficult to assume a number of clusters K to capture their diverse behaviors \neffectively. Another similar K-medoids method [77] is more robust than K-means algo-\nrithm in the presence of outliers because a medoid is less influenced by outliers than a \nmean. Though it minimizes the outlier problem but the other characteristic mismatches \nexist between K-means and the problem of time-series modeling.\n\nAs the size and number of time segments depend on the user’s behavior and it differs \nfrom user-to-user, a bottom-up hierarchical data processing can help to make behavioral \nclusters. Existing hierarchical algorithms are mainly classified as agglomerative methods \nand device methods. However, the device clustering method is not commonly used in \npractice [75]. The simplest and most popular agglomerative clustering is single linkage \n[78] and complete linkage [79]. Another method, nearest neighbor [75], is also similar to \nthe single linkage agglomerative clustering algorithm. All these hierarchical algorithms \nuse a proximity matrix which is generated by computing the distance between a new \ncluster and other clusters. Then according to the matrix value these algorithms succes-\nsivel", "metadata_storage_path": "aHR0cHM6Ly9rYm1zdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9wYXBlcnMvczQwNTM3LTAxOS0wMjU4LTQucGRm0", "metadata_author": "Iqbal H. Sarker ", "metadata_title": "Context-aware rule learning from smartphone data: survey, challenges and future directions", "metadata_creation_date": "2019-10-30T14:24:16Z", "people": [ "Iqbal H. Sarker", "Sarker J", "J", "larity", "Alice", "J Big", "Schilit", "Brown", "Simi", "Ryan", "Franklin", "Ward", "Hull", "Rodden", "Dey", "mation", "Song", "Rawassizadeh", "Mukherji", "Bayir", "Paireekreng", "Jayarajah", "Xu", "Mehrotra", "Zhu", "Oulasvirta", "Yu", "Naboulsi", "Dashdorj", "Shin", "Farrahi", "Ozer", "Do", "Karatzoglou", "Phithakkitnukoon", "Khail", "Dekel", "Zulkernain", "Seo", "Sarker", "Halvey", "Zhang", "Shokoohi", "Hartono", "Keogh", "Lu", "Kandasamy", "sivel" ], "organizations": [ "Google", "Commons", "Swinburne University", "Technology", "Ubiq", "International Telecommunication Union", "Facebook", "Twitter", "Youtube", "ual", "Skype", "Unequal 4", "Unequal", "Tmax" ], "locations": [ "Melbourne", "Australia", "Pervasive" ], "keyphrases": [ "Creative Commons Attribution 4.0 International License", "intelligent decision making strategies", "advanced data analytical techniques", "25Sarker J Big Data", "Context‑aware rule learning", "Intelligent systems Open Access", "machine learning based techniques", "Creative Commons license", "corresponding context-aware rule learning", "Iqbal H. Sarker", "User behavior modeling", "creat iveco mmons", "intelligent context-aware applications", "raw contextual data", "corresponding search interests", "data-driven context-aware systems", "phone data analytics", "original author(s", "corresponding data processing", "multifunctional cell phones", "users’ surrounding environment", "smartphone data", "Data science", "Predictive analytics", "context-aware rules", "Context-aware computing", "author information", "future directions", "recent days", "daily life", "important IoT", "next generation", "wireless connectivity", "work coverage", "developed countries", "recent statistics", "Google Trends", "users’ interest", "other platforms", "Desktop Computer", "Laptop Computer", "current world", "recent developments", "behavioral activities", "wide attention", "high precision", "traditional approaches", "efficient results", "previous work", "rule-based automated", "IoT services", "unrestricted use", "appropriate credit", "doi.org", "1 Swinburne University", "Full list", "Tablet Computer", "last 5 years", "timestamp information", "particular date", "highest point", "personal devices", "Things) devices", "essential part", "world population", "Mobile Phones", "particular term", "SURVEY PAPER", "peak popularity", "challenges", "Introduction", "smartphones", "individuals", "Internet", "capabilities", "number", "Fig.", "Abstract", "ogy", "academia", "industry", "order", "set", "key", "contexts", "comparison", "effective", "article", "area", "discussion", "Clustering", "Classification", "Association", "Personalization", "Time-series", "terms", "distribution", "reproduction", "medium", "source", "link", "changes", "Correspondence", "msarker", "Melbourne", "Australia", "creativecommons", "licenses", "crossmark", "Page", "Figure", "x-axis", "range", "chart", "instance", "value", "maximum", "y-axis", "minimum", "context-aware mobile notification management system", "other broad application areas", "corresponding rule-based prediction model", "different context-aware test cases", "data-driven intelligent context-aware systems", "optimal time-based context-aware rules", "rule-based intelligent context-aware systems", "smartphone data analytic solutions", "context-aware smart city services", "users’ behavioral activity patterns", "intelligent data-driven decisions", "THEN” logical structure", "corresponding data clustering", "corresponding behavioral activities", "Users’ interest trends", "intelligent eHealth services", "aware behavioral rules", "relevant context-aware rules", "relevant contextual data", "contextual data patterns", "contextual data clustering", "machine learning researchers", "machine learning techniques", "different surrounding contexts", "machine learning rules", "relevant contextual information", "data mining techniques", "advanced data analysis", "rule-based classification", "raw data", "different contexts", "mobile notifications", "context-aware  software", "hidden patterns", "data science", "time-series data", "advanced features", "mental learning", "personalized services", "rity services", "deeper analysis", "association analysis", "detailed analysis", "daily basis", "great source", "useful information", "two parts", "temporal context", "tial context", "social contexts", "family members", "specific exceptions", "particular domain", "prac- titioners", "many reasons", "various purposes", "particular timestamp", "numeric values", "world-wide popularity", "ture optimization", "dynamic updating", "The reason", "huge amount", "unknown correlations", "diverse behaviors", "quent part", "individuals’ usage", "phone user", "devices", "result", "antecedent", "others", "example", "Alice", "work", "evening", "general", "preferences", "addition", "cable", "study", "applications", "building", "Several", "selection", "aim", "machine learning based context-aware rule learning framework", "Suggested machine learning based framework", "Context-aware rule based applications", "Context-aware rule learning strategies", "smartphone data analyt- ics", "real world applications", "rule discovery techniques", "decision making capability", "rule-based intelligent systems", "Human Computer Interaction", "smartphone data analytics", "corresponding context-aware rules", "contextual smartphone data", "Pervasive Computing area", "incremental learning", "context-aware computing", "updation techniques", "smrtphone data", "uitous Computing", "several perspectives", "time-series modeling", "various layers", "various perspectives", "different meanings", "different purposes", "numerous areas", "Computer-Supported Collaborative", "Ambient Intelligence", "recent works", "broader collection", "social aspects", "little work", "earlier work", "brief discussion", "background information", "main characteristics", "existing research", "brief survey", "first article", "multi-dimensional contexts", "sion” section", "profit", "analysis", "discretization", "issues", "contributions", "paper", "shortcomings", "role", "knowledge", "remainder", "variety", "notion", "mobile", "Ubiquitous", "context-awareness", "location", "people", "objects", "factors", "physical", "entity", "activities", "users", "definitions", "categories", "daily life activities", "temporal informa- tion", "ubiquitous computing community", "ubiquitous computing area", "Contextual smartphone data", "user diverse activities", "rent social situation", "data source", "smartphone usage", "temporal information", "defi- nitions", "dis- cussion", "Several studies", "surrounding people", "Other definitions", "other hand", "current situation", "nearby people", "available processors", "network capacity", "noise level", "lighting level", "day situations", "cellular phones", "computing environment", "location information", "locational information", "environmental information", "surrounding information", "changing environment", "physical environment", "other researchers", "important aspects", "alternative view", "con- text", "social context", "following definition", "user location", "user input", "relevant contexts", "spatial context", "user environment", "pervasive", "section", "scope", "different", "perspectives", "Schilit", "Brown", "temperature", "Simi", "identity", "account", "Ryan", "synonyms", "computer", "Franklin", "Ward", "state", "Hull", "entire", "settings", "Rodden", "resources", "connectivity", "display", "costs", "examples", "Dey", "survey", "person", "place", "interaction", "influence", "decisions", "everything", "lives", "Mobile", "personalized mobile game recommendation system", "vidual mobile phone user behavior", "mobile notification management systems", "relevant contextual informa- tion", "related contextual infor- mation", "various smart phone applications", "individual mobile phone users", "personalized context-aware recommendation", "user mobile web navigation", "smart mobile applications", "smart mobile phone", "phone usage behavior", "standardized communications rules", "International Telecommunication Union", "sive commercial industry", "accurate context-aware predictions", "text communication service", "contextual behavioral patterns", "automatic spam filtering", "smartphone notification logs", "phone call activities", "short text messages", "contextual usage patterns", "short message service", "spam text messages", "contextual patterns", "unique phone", "individual users", "User navigation", "short messages", "game log", "voice communication", "major activities", "spam messages", "various types", "various kinds", "various real", "web log", "web searching", "particular user", "meta data", "log data", "outgoing calls", "incoming calls", "other dimensions", "day situation", "social relationship", "numerous growth", "dramatic increasing", "good time", "bad time", "rapid development", "smartphone apps", "Such logs", "social networks", "predictive suggestions", "portal structure", "computing capabilities", "life-logging device", "technical sense", "context data", "tual information", "context source", "SMS log", "real world", "life purposes", "contact number", "ability", "caller", "callee", "exchange", "protocols", "81 billion", "task", "Multimedia", "Facebook", "Gmail", "Youtube", "Skype", "notifications", "events", "news", "reminders", "alerts", "games", "promotional", "emails", "Twitter", "LinkedIN", "WhatsApp", "Viver", "intelligent", "entertainment", "chat", "misc", "TV", "netting", "travel", "sport", "banking", "needs", "action", "adventure", "puzzle", "RPG", "strategy", "ubiquity", "opportunity", "memories", "Context‑aware rule learning strategies", "Time interval type Number", "temporal context based rules", "existing time-series segmentation approaches", "time‑series smartphone data", "mobile phone data", "Google play API", "geographical loca- tion", "context-aware rule learning", "segment details References", "personalized log data", "user phone calls", "smart mobile phones", "life log data", "mobile user behavior", "behavioral data clusters", "time-based behavior modeling", "A time series", "related contextual information", "static time segments", "existing rule", "existing strategies", "important context", "contextual rule", "learning rules", "IoT data", "data points", "temporal, spatial", "behavioral rules", "exact time", "user experience", "surrounding environment", "core components", "life- logs", "SMS headers", "App use", "physical activities", "Bluetooth devices", "open challenges", "diverse activities", "effective modeling", "open problem", "Various types", "different applications", "remaining hours", "late morning", "Equal 3 Morning", "Equal 4 Morning", "Unequal 5 Morning", "Equal 4 Night", "6:00 a", "sensors", "content", "sapp", "WiFi", "proximity", "opportunities", "future", "directions", "discovery", "behaviors", "sequence", "research", "Table", "afternoon", "Song", "Rawassizadeh", "Mukherji", "Bayir", "Paireekreng", "day", "Jayarajah", "Do", "Xu", "Mehrotra", "Zhu", "forenoon", "Oulasvirta", "Next", "Yu", "midnight", "0:00", "dynamic segmenta- tion technique", "high confidence temporal rules", "unequal interval based segmentation", "high confidence rules", "four different time segments", "various mobile applications", "dynamic segmen- tation", "four time slots", "mobile phone users", "individual smartphone users", "same interval length", "two broad categories", "users’ behavioral activities", "dynamic segmentation techniques", "Such static segmentation", "various time intervals", "unequal time interval", "time segments decreases", "temporal coverage", "different lengths", "temporal contexts", "arbitrary categories", "two types", "behavioral characteristics", "corresponding segmentation", "population behavior", "ioral evidence", "usage records", "seg- ments", "single parameter", "division result", "base period", "time period", "static generation", "meaningful results", "variable number", "one case", "N1 number", "N2 number", "Naboulsi", "Dashdorj", "Shin", "11:00 a", "S5", "S8", "Farrahi", "ii", "researchers", "periods", "1 h", "works", "approaches", "goal", "change", "patterns", "authors", "Tmax", "24-h", "BP", "5 min", "2:00", "5:00", "7:00", "9:00", "important machine learning tech- niques", "time- series data Lu", "Base technique Description References", "time-series log data Halvey", "data shape based approaches", "squared error-based clustering algorithm", "time-series data analysis", "time-series data Hartono", "time-series data Das", "similar K-medoids method", "cluster- ing algorithms", "mean value calculation", "temporal context Khail", "different initial points", "base time period", "dynamic time segments", "Various calendar schedules", "corresponding time boundaries", "user behavior patterns", "large time segments", "large value", "initial partitions", "different value", "time segmentation", "time interval", "different contexts", "predefined value", "clustering algorithms", "finest granularity", "segments decreases", "iable length", "particular event", "personal calendars", "multiple thresholds", "sliding window", "several applications", "specific application", "convergence centroids", "segments Ozer", "segmentation Do", "upper boundary", "particular segment", "genetic algorithm", "users’ behavior", "users’ preferences", "one user", "users’ behave", "Single parameter", "K-means algorithm", "predefined number", "individual", "assumptions", "problems", "sense", "clusters", "K.", "outliers", "30 min", "Karatzoglou", "small", "Phithakkitnukoon", "Dekel", "Zulkernain", "Seo", "Multi-thresholds", "lower", "Zhang", "Shokoohi", "Keogh", "Kandasamy", "characteristic", "reason", "1", "2:30", "single linkage agglomerative clustering algorithm", "bottom-up hierarchical data processing", "popular agglomerative clustering", "other characteristic mismatches", "device clustering method", "Existing hierarchical algorithms", "agglomerative methods", "complete linkage", "device methods", "other clusters", "time segments", "behavioral clusters", "nearest neighbor", "proximity matrix", "new cluster", "matrix value", "outlier problem", "presence", "medoid", "K-means", "size", "user", "practice", "simplest", "distance", "sivel" ], "pii_entities": [ { "text": "Iqbal H. Sarker", "type": "Person", "subtype": null, "offset": 94, "length": 15, "score": 0.98 }, { "text": "daily", "type": "DateTime", "subtype": "Set", "offset": 193, "length": 5, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 410, "length": 5, "score": 0.9 }, { "text": "The Author", "type": "Organization", "subtype": null, "offset": 2631, "length": 10, "score": 0.68 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 2645, "length": 4, "score": 0.8 }, { "text": "author", "type": "PersonType", "subtype": null, "offset": 2941, "length": 6, "score": 0.89 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 3097, "length": 4, "score": 0.8 }, { "text": "https://doi.org/10.1186/s40537", "type": "URL", "subtype": null, "offset": 3110, "length": 30, "score": 0.8 }, { "text": "msarker@swin.edu.au", "type": "Email", "subtype": null, "offset": 3173, "length": 19, "score": 0.8 }, { "text": "Swinburne University", "type": "Organization", "subtype": null, "offset": 3196, "length": 20, "score": 0.95 }, { "text": "http://creativecommons.org/licenses/by/4.0/", "type": "URL", "subtype": null, "offset": 3339, "length": 43, "score": 0.8 }, { "text": "http://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0258-4&domain=pdf", "type": "URL", "subtype": null, "offset": 3383, "length": 78, "score": 0.8 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 3507, "length": 4, "score": 0.8 }, { "text": "last 5 years", "type": "DateTime", "subtype": "DateRange", "offset": 3546, "length": 12, "score": 0.8 }, { "text": "from 2014 to 2019", "type": "DateTime", "subtype": "DateRange", "offset": 3559, "length": 17, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 4099, "length": 5, "score": 0.63 }, { "text": "daily", "type": "DateTime", "subtype": "Set", "offset": 4201, "length": 5, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 4612, "length": 5, "score": 0.85 }, { "text": "Alice", "type": "Person", "subtype": null, "offset": 4954, "length": 5, "score": 0.99 }, { "text": "in the \nevening", "type": "DateTime", "subtype": "TimeRange", "offset": 5109, "length": 15, "score": 0.8 }, { "text": "family", "type": "PersonType", "subtype": null, "offset": 5134, "length": 6, "score": 0.54 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 5268, "length": 3, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 5291, "length": 4, "score": 0.82 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 5813, "length": 11, "score": 0.59 }, { "text": "Users", "type": "PersonType", "subtype": null, "offset": 6323, "length": 5, "score": 0.7 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 6561, "length": 4, "score": 0.8 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 10165, "length": 4, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 11838, "length": 5, "score": 0.94 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 12421, "length": 4, "score": 0.52 }, { "text": "Schilit", "type": "Person", "subtype": null, "offset": 12491, "length": 7, "score": 0.95 }, { "text": "Brown", "type": "Person", "subtype": null, "offset": 12512, "length": 5, "score": 0.94 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 12554, "length": 4, "score": 0.67 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 12642, "length": 4, "score": 0.93 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 12765, "length": 4, "score": 0.78 }, { "text": "Ryan", "type": "Person", "subtype": null, "offset": 12825, "length": 4, "score": 0.97 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 13073, "length": 4, "score": 0.89 }, { "text": "Brown", "type": "Person", "subtype": null, "offset": 13210, "length": 5, "score": 0.96 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 13260, "length": 4, "score": 0.5 }, { "text": "Franklin", "type": "Person", "subtype": null, "offset": 13296, "length": 8, "score": 0.96 }, { "text": "Ward", "type": "Person", "subtype": null, "offset": 13445, "length": 4, "score": 0.96 }, { "text": "Hull", "type": "Person", "subtype": null, "offset": 13546, "length": 4, "score": 0.96 }, { "text": "25Sarker", "type": "Person", "subtype": null, "offset": 13668, "length": 8, "score": 0.5 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 13701, "length": 4, "score": 0.8 }, { "text": "Rodden", "type": "Person", "subtype": null, "offset": 13787, "length": 6, "score": 0.95 }, { "text": "Schilit", "type": "Person", "subtype": null, "offset": 13823, "length": 7, "score": 0.97 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 14106, "length": 4, "score": 0.64 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 14146, "length": 4, "score": 0.86 }, { "text": "Dey", "type": "Person", "subtype": null, "offset": 14549, "length": 3, "score": 0.97 }, { "text": "now", "type": "DateTime", "subtype": null, "offset": 14783, "length": 3, "score": 0.8 }, { "text": "Dey", "type": "Person", "subtype": null, "offset": 14827, "length": 3, "score": 0.97 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 15028, "length": 4, "score": 0.82 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 15069, "length": 4, "score": 0.76 }, { "text": "Dey", "type": "Person", "subtype": null, "offset": 15140, "length": 3, "score": 0.96 }, { "text": "daily", "type": "DateTime", "subtype": "Set", "offset": 15550, "length": 5, "score": 0.8 }, { "text": "age", "type": "Quantity", "subtype": "Age", "offset": 15617, "length": 3, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 16067, "length": 4, "score": 0.87 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 16847, "length": 5, "score": 0.67 }, { "text": "International Telecommunication Union", "type": "Organization", "subtype": null, "offset": 16926, "length": 37, "score": 0.92 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 17474, "length": 4, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 18098, "length": 5, "score": 0.95 }, { "text": "Twitter", "type": "Organization", "subtype": null, "offset": 18366, "length": 7, "score": 0.8 }, { "text": "Facebook", "type": "Organization", "subtype": null, "offset": 18375, "length": 8, "score": 0.81 }, { "text": "LinkedIN", "type": "Organization", "subtype": null, "offset": 18385, "length": 8, "score": 0.63 }, { "text": "WhatsApp", "type": "Organization", "subtype": null, "offset": 18395, "length": 8, "score": 0.7 }, { "text": "Viver", "type": "Organization", "subtype": null, "offset": 18405, "length": 5, "score": 0.63 }, { "text": "Skype", "type": "Organization", "subtype": null, "offset": 18412, "length": 5, "score": 0.66 }, { "text": "Youtube", "type": "Organization", "subtype": null, "offset": 18419, "length": 7, "score": 0.69 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 18676, "length": 5, "score": 0.83 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 19089, "length": 5, "score": 0.95 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 19280, "length": 5, "score": 0.65 }, { "text": "Youtube", "type": "Organization", "subtype": null, "offset": 20058, "length": 7, "score": 0.51 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 20189, "length": 4, "score": 0.76 }, { "text": "daily", "type": "DateTime", "subtype": "Set", "offset": 20426, "length": 5, "score": 0.8 }, { "text": "25Sarker", "type": "Person", "subtype": null, "offset": 21131, "length": 8, "score": 0.55 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 21164, "length": 4, "score": 0.8 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 22345, "length": 7, "score": 0.8 }, { "text": "7:00–12:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22354, "length": 10, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 22367, "length": 9, "score": 0.8 }, { "text": "13:00–18:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22378, "length": 11, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 22396, "length": 7, "score": 0.8 }, { "text": "19:00–24:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22405, "length": 11, "score": 0.8 }, { "text": "Song", "type": "Person", "subtype": null, "offset": 22419, "length": 4, "score": 0.97 }, { "text": "0:00–7:59", "type": "DateTime", "subtype": "TimeRange", "offset": 22446, "length": 9, "score": 0.8 }, { "text": "8:00–15:59", "type": "DateTime", "subtype": "TimeRange", "offset": 22459, "length": 10, "score": 0.8 }, { "text": "16:00–23:59", "type": "DateTime", "subtype": "TimeRange", "offset": 22476, "length": 11, "score": 0.8 }, { "text": "Rawassizadeh", "type": "Person", "subtype": null, "offset": 22489, "length": 12, "score": 0.96 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 22523, "length": 7, "score": 0.8 }, { "text": "6:00–12:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22532, "length": 10, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 22545, "length": 9, "score": 0.8 }, { "text": "12:00–18:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22556, "length": 11, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 22571, "length": 7, "score": 0.8 }, { "text": "18:00–24:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22580, "length": 11, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 22597, "length": 5, "score": 0.8 }, { "text": "0:00–6:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22604, "length": 9, "score": 0.8 }, { "text": "Mukherji et al", "type": "Person", "subtype": null, "offset": 22616, "length": 14, "score": 0.71 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 22646, "length": 7, "score": 0.8 }, { "text": "6:00–12:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22655, "length": 10, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 22668, "length": 9, "score": 0.8 }, { "text": "12:00–18:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22679, "length": 11, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 22694, "length": 7, "score": 0.8 }, { "text": "18:00–24:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22703, "length": 11, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 22720, "length": 5, "score": 0.8 }, { "text": "0:00–6:00", "type": "DateTime", "subtype": "TimeRange", "offset": 22727, "length": 9, "score": 0.8 }, { "text": "Bayir", "type": "Person", "subtype": null, "offset": 22739, "length": 5, "score": 0.97 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 22766, "length": 7, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 22775, "length": 9, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 22786, "length": 7, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 22798, "length": 5, "score": 0.8 }, { "text": "Paireekreng", "type": "Person", "subtype": null, "offset": 22804, "length": 11, "score": 0.85 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 22837, "length": 7, "score": 0.8 }, { "text": "6:00–11:59", "type": "DateTime", "subtype": "TimeRange", "offset": 22846, "length": 10, "score": 0.8 }, { "text": "12:00–17:59", "type": "DateTime", "subtype": "TimeRange", "offset": 22864, "length": 11, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 22878, "length": 7, "score": 0.8 }, { "text": "18:00–23:59", "type": "DateTime", "subtype": "TimeRange", "offset": 22888, "length": 11, "score": 0.8 }, { "text": "0:00–5:59", "type": "DateTime", "subtype": "TimeRange", "offset": 22913, "length": 9, "score": 0.8 }, { "text": "Jayarajah", "type": "Person", "subtype": null, "offset": 22925, "length": 9, "score": 0.97 }, { "text": "4 Night", "type": "DateTime", "subtype": "Duration", "offset": 22954, "length": 7, "score": 0.8 }, { "text": "0:00–6:00 a.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 22963, "length": 14, "score": 0.8 }, { "text": "morning", "type": "DateTime", "subtype": "TimeRange", "offset": 22980, "length": 7, "score": 0.8 }, { "text": "6:00 a.m.–12:00 \np.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 22989, "length": 21, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 23013, "length": 9, "score": 0.8 }, { "text": "12:00–6:00 p.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 23024, "length": 15, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 23046, "length": 7, "score": 0.8 }, { "text": "6:00 p.m.–0:00 a.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 23056, "length": 19, "score": 0.8 }, { "text": "Do", "type": "Person", "subtype": null, "offset": 23078, "length": 2, "score": 0.9 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23104, "length": 7, "score": 0.8 }, { "text": "6:00 a.m.", "type": "DateTime", "subtype": "Time", "offset": 23126, "length": 9, "score": 0.8 }, { "text": "noon", "type": "DateTime", "subtype": "Time", "offset": 23151, "length": 4, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 23158, "length": 9, "score": 0.8 }, { "text": "6:00 p.m.", "type": "DateTime", "subtype": "Time", "offset": 23179, "length": 9, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 23191, "length": 5, "score": 0.8 }, { "text": "Xu", "type": "Person", "subtype": null, "offset": 23221, "length": 2, "score": 0.98 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23247, "length": 7, "score": 0.8 }, { "text": "6:00–12:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23256, "length": 10, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 23269, "length": 9, "score": 0.8 }, { "text": "12:00–16:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23280, "length": 11, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 23295, "length": 7, "score": 0.8 }, { "text": "16:00–20:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23304, "length": 11, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 23321, "length": 5, "score": 0.8 }, { "text": "20:00–24:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23328, "length": 11, "score": 0.8 }, { "text": "0:00–6:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23345, "length": 9, "score": 0.8 }, { "text": "Mehrotra", "type": "Person", "subtype": null, "offset": 23357, "length": 8, "score": 0.96 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23388, "length": 7, "score": 0.8 }, { "text": "7:00–11:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23397, "length": 10, "score": 0.8 }, { "text": "noon", "type": "DateTime", "subtype": "Time", "offset": 23410, "length": 4, "score": 0.8 }, { "text": "11:00–14:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23416, "length": 11, "score": 0.8 }, { "text": "noon", "type": "DateTime", "subtype": "Time", "offset": 23437, "length": 4, "score": 0.8 }, { "text": "14:00–18:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23443, "length": 11, "score": 0.8 }, { "text": "Zhu", "type": "Person", "subtype": null, "offset": 23467, "length": 3, "score": 0.96 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23493, "length": 7, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 23512, "length": 9, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 23523, "length": 7, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 23536, "length": 5, "score": 0.8 }, { "text": "Oulasvirta", "type": "Person", "subtype": null, "offset": 23542, "length": 10, "score": 0.83 }, { "text": "Morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23576, "length": 7, "score": 0.8 }, { "text": "7:00–11:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23585, "length": 10, "score": 0.8 }, { "text": "noon", "type": "DateTime", "subtype": "Time", "offset": 23598, "length": 4, "score": 0.8 }, { "text": "11:00–14:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23604, "length": 11, "score": 0.8 }, { "text": "noon", "type": "DateTime", "subtype": "Time", "offset": 23625, "length": 4, "score": 0.8 }, { "text": "14:00–18:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23631, "length": 11, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 23645, "length": 7, "score": 0.8 }, { "text": "18:00–21:00", "type": "DateTime", "subtype": "TimeRange", "offset": 23654, "length": 11, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 23673, "length": 5, "score": 0.8 }, { "text": "21:00–Next day 7:00", "type": "DateTime", "subtype": "DateTimeRange", "offset": 23680, "length": 19, "score": 0.8 }, { "text": "Yu", "type": "Person", "subtype": null, "offset": 23702, "length": 2, "score": 0.96 }, { "text": "> 5 Early morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23726, "length": 17, "score": 0.8 }, { "text": "morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23745, "length": 7, "score": 0.8 }, { "text": "late morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23754, "length": 12, "score": 0.8 }, { "text": "midnight", "type": "DateTime", "subtype": "Time", "offset": 23768, "length": 8, "score": 0.8 }, { "text": "Naboulsi", "type": "Person", "subtype": null, "offset": 23789, "length": 8, "score": 0.98 }, { "text": "> 5 Early morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23819, "length": 17, "score": 0.8 }, { "text": "morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23838, "length": 7, "score": 0.8 }, { "text": "late morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23847, "length": 12, "score": 0.8 }, { "text": "midnight", "type": "DateTime", "subtype": "Time", "offset": 23861, "length": 8, "score": 0.8 }, { "text": "Dashdorj", "type": "Person", "subtype": null, "offset": 23882, "length": 8, "score": 0.98 }, { "text": "> 5 Early morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23912, "length": 17, "score": 0.8 }, { "text": "morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23931, "length": 7, "score": 0.8 }, { "text": "late morning", "type": "DateTime", "subtype": "TimeRange", "offset": 23940, "length": 12, "score": 0.8 }, { "text": "midnight", "type": "DateTime", "subtype": "Time", "offset": 23954, "length": 8, "score": 0.8 }, { "text": "Shin", "type": "Person", "subtype": null, "offset": 23975, "length": 4, "score": 0.97 }, { "text": "Unequal", "type": "Organization", "subtype": null, "offset": 23993, "length": 7, "score": 0.61 }, { "text": "0:00–7:00 a.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 24006, "length": 14, "score": 0.8 }, { "text": "7:00–9:00 a.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 24026, "length": 14, "score": 0.8 }, { "text": "9:00–\n11:00 a.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 24046, "length": 16, "score": 0.8 }, { "text": "11:00 a.m.–2:00 p.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 24068, "length": 20, "score": 0.8 }, { "text": "2:00", "type": "DateTime", "subtype": "Time", "offset": 24094, "length": 4, "score": 0.8 }, { "text": "00 p.m.", "type": "DateTime", "subtype": "Time", "offset": 24102, "length": 7, "score": 0.8 }, { "text": "5:00–7:00 p.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 24115, "length": 14, "score": 0.8 }, { "text": "7:00–9:00 p.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 24135, "length": 14, "score": 0.8 }, { "text": "S8", "type": "Address", "subtype": null, "offset": 24156, "length": 2, "score": 0.53 }, { "text": "9:00 p.m.–12:00 a.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 24159, "length": 20, "score": 0.8 }, { "text": "Farrahi", "type": "Person", "subtype": null, "offset": 24182, "length": 7, "score": 0.98 }, { "text": "25Sarker", "type": "Person", "subtype": null, "offset": 24215, "length": 8, "score": 0.6 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 24248, "length": 4, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 24541, "length": 5, "score": 0.76 }, { "text": "recently", "type": "DateTime", "subtype": null, "offset": 24580, "length": 8, "score": 0.8 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 24602, "length": 11, "score": 0.51 }, { "text": "24-h", "type": "DateTime", "subtype": "Duration", "offset": 24680, "length": 4, "score": 0.8 }, { "text": "1 h", "type": "DateTime", "subtype": "Duration", "offset": 24782, "length": 3, "score": 0.8 }, { "text": "morning", "type": "DateTime", "subtype": "TimeRange", "offset": 25014, "length": 7, "score": 0.8 }, { "text": "6:00–\n12:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25023, "length": 11, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 25037, "length": 9, "score": 0.8 }, { "text": "12:00–18:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25048, "length": 11, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 25062, "length": 7, "score": 0.8 }, { "text": "18:00–24:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25071, "length": 11, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 25088, "length": 5, "score": 0.8 }, { "text": "0:00–6:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25095, "length": 9, "score": 0.8 }, { "text": "morning", "type": "DateTime", "subtype": "TimeRange", "offset": 25253, "length": 7, "score": 0.8 }, { "text": "6:00–12:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25262, "length": 10, "score": 0.8 }, { "text": "afternoon", "type": "DateTime", "subtype": "TimeRange", "offset": 25275, "length": 9, "score": 0.8 }, { "text": "12:00–\n16:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25286, "length": 12, "score": 0.8 }, { "text": "evening", "type": "DateTime", "subtype": "TimeRange", "offset": 25301, "length": 7, "score": 0.8 }, { "text": "16:00–20:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25310, "length": 11, "score": 0.8 }, { "text": "night", "type": "DateTime", "subtype": "TimeRange", "offset": 25327, "length": 5, "score": 0.8 }, { "text": "20:00–24:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25334, "length": 11, "score": 0.8 }, { "text": "0:00–6:00", "type": "DateTime", "subtype": "TimeRange", "offset": 25350, "length": 9, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 25851, "length": 5, "score": 0.86 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 26061, "length": 3, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 26150, "length": 5, "score": 0.64 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 26711, "length": 5, "score": 0.57 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 26922, "length": 3, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 27118, "length": 5, "score": 0.93 }, { "text": "24-h", "type": "DateTime", "subtype": "Duration", "offset": 27407, "length": 4, "score": 0.8 }, { "text": "5 min", "type": "DateTime", "subtype": "Duration", "offset": 27616, "length": 5, "score": 0.8 }, { "text": "24-h", "type": "DateTime", "subtype": "Duration", "offset": 27683, "length": 4, "score": 0.8 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 27767, "length": 4, "score": 0.8 }, { "text": "5 min", "type": "DateTime", "subtype": "Duration", "offset": 27799, "length": 5, "score": 0.8 }, { "text": "15 min", "type": "DateTime", "subtype": "Duration", "offset": 27933, "length": 6, "score": 0.8 }, { "text": "15 min", "type": "DateTime", "subtype": "Duration", "offset": 27987, "length": 6, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 28266, "length": 5, "score": 0.84 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 28310, "length": 3, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 28332, "length": 5, "score": 0.9 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 28375, "length": 4, "score": 0.52 }, { "text": "between 1 and 2 p.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 28409, "length": 20, "score": 0.8 }, { "text": "between 1:30 and 2:30 p.m.", "type": "DateTime", "subtype": "TimeRange", "offset": 28481, "length": 26, "score": 0.8 }, { "text": "daily", "type": "DateTime", "subtype": "Set", "offset": 28564, "length": 5, "score": 0.8 }, { "text": "authors", "type": "PersonType", "subtype": null, "offset": 28800, "length": 7, "score": 0.52 }, { "text": "15 min", "type": "DateTime", "subtype": "Duration", "offset": 29985, "length": 6, "score": 0.8 }, { "text": "Ozer", "type": "Person", "subtype": null, "offset": 30023, "length": 4, "score": 0.97 }, { "text": "30 min", "type": "DateTime", "subtype": "Duration", "offset": 30083, "length": 6, "score": 0.8 }, { "text": "Do et al.", "type": "Person", "subtype": null, "offset": 30117, "length": 9, "score": 0.75 }, { "text": "Farrahi et al", "type": "Person", "subtype": null, "offset": 30133, "length": 13, "score": 0.74 }, { "text": "2-h", "type": "DateTime", "subtype": "Duration", "offset": 30204, "length": 3, "score": 0.8 }, { "text": "Karatzoglou", "type": "Person", "subtype": null, "offset": 30243, "length": 11, "score": 0.98 }, { "text": "3-h", "type": "DateTime", "subtype": "Duration", "offset": 30312, "length": 3, "score": 0.8 }, { "text": "Phithakkitnukoon", "type": "Person", "subtype": null, "offset": 30381, "length": 16, "score": 0.96 }, { "text": "Khail et al.", "type": "Person", "subtype": null, "offset": 30538, "length": 12, "score": 0.72 }, { "text": "Dekel et al.", "type": "Person", "subtype": null, "offset": 30557, "length": 12, "score": 0.73 }, { "text": "Zulkernain", "type": "Person", "subtype": null, "offset": 30576, "length": 10, "score": 0.83 }, { "text": "Seo et", "type": "Person", "subtype": null, "offset": 30601, "length": 6, "score": 0.78 }, { "text": "Sarker", "type": "Person", "subtype": null, "offset": 30618, "length": 6, "score": 0.97 }, { "text": "Halvey", "type": "Person", "subtype": null, "offset": 30779, "length": 6, "score": 0.97 }, { "text": "Zhang", "type": "Person", "subtype": null, "offset": 30855, "length": 5, "score": 0.96 }, { "text": "Shokoohi", "type": "Person", "subtype": null, "offset": 30874, "length": 8, "score": 0.97 }, { "text": "Hartono et al", "type": "Person", "subtype": null, "offset": 30966, "length": 13, "score": 0.67 }, { "text": "Keogh et al", "type": "Person", "subtype": null, "offset": 30987, "length": 11, "score": 0.67 }, { "text": "Das", "type": "Person", "subtype": null, "offset": 31099, "length": 3, "score": 0.91 }, { "text": "Lu et al", "type": "Person", "subtype": null, "offset": 31192, "length": 8, "score": 0.7 }, { "text": "Kandasamy et al", "type": "Person", "subtype": null, "offset": 31208, "length": 15, "score": 0.69 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 31277, "length": 4, "score": 0.8 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 31510, "length": 3, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 31524, "length": 4, "score": 0.66 }, { "text": "sivel", "type": "Person", "subtype": null, "offset": 32763, "length": 5, "score": 0.52 } ] }, { "@search.score": 1.9883001, "content": "\nComputational Visual Media\nhttps://doi.org/10.1007/s41095-020-0189-1 Vol. 7, No. 2, June 2021, 159–167\n\nReview Article\n\nMachine learning for digital try-on: Challenges and progress\n\nJunbang Liang1 (�), Ming C. Lin1\n\nc© The Author(s) 2020.\n\nAbstract Digital try-on systems for e-commerce have\nthe potential to change people’s lives and provide notable\neconomic benefits. However, their development is limited\nby practical constraints, such as accurate sizing of the\nbody and realism of demonstrations. We enumerate three\nopen challenges remaining for a complete and easy-to-use\ntry-on system that recent advances in machine learning\nmake increasingly tractable. For each, we describe\nthe problem, introduce state-of-the-art approaches, and\nprovide future directions.\n\nKeywords machine learning; digital try-on; garment\nmodeling; human body estimation; material\nmodeling\n\n1 Introduction\nE-commerce has grown at a rapid pace in recent\nyears. Consumers today are more likely to shop\nonline than to visit a retail store. The situation is\nmuch more complicated, however, when it comes to\nbuying clothes. People need to know how a garment\nfits on them, how it looks, and how it feels. Digital\ntry-on systems can potentially satisfy these needs,\nproviding a direct visual impression, and possibly\ncustomized clothes sizing as well. Therefore, it has\ndrawn much attention as an attractive alternative to\nimprove the user experience and popularize online\nfashion shopping.\n\nHowever, the technology is still far from practical,\neasy-to-use, and adequate to replace physical try-on.\nCurrently, most try-on systems rely on either image-\nediting, copy-pasting, or template demonstrations,\n\n1 University of Maryland, College Park, MD 20785, USA.\nE-mail: J. Liang, liangjb@cs.umd.edu (�); M. C. Lin,\nlin@cs.umd.edu.\n\nManuscript received: 2020-06-24; accepted: 2020-07-21\n\nwhile the ultimate goal is a fast and realistic try-on\nsystem adaptive to each customer’s body. There is\nstill a substantial technological gap between modeling\nand demonstrating garment fitting in the digital and\nreal worlds, including fast and realistic demonstration,\naccurate modeling of human body and garments,\nfaithful modeling of garment material, and lossless\ntransformation of garments between virtual and\nphysical worlds.\n\nIn this paper, we present some open research issues\nthat contribute to this technological gap, including:\n1. accurate estimation of human shapes and sizes\n\nusing consumer devices,\n2. faithful recovery of garment materials via (online)\n\nimages, and\n3. ease of design and manipulation of sewing patterns\n\nand garment pieces by end-users.\nAlthough traditional methods have made important\n\nprogress on these under-constrained problems,\nlearning-based approaches have shown tremendous\npotential to make a notable impact. Compared to\ntraditional methods, machine-learning algorithms are\nusually much faster since training and optimization\nare performed offline. They are also good at\ngeneralizing to unseen images without the need for\ntedious data pre-processing. While extensive research\nexists on 2D image learning, machine learning of\nhighly variable 3D human body shapes is still far\nfrom mature, which is the reason why the open issues\ndescribed above remain elusive.\n\nFor each problem listed above, we motivate its\nimportance, provide a problem description, and\npresent state-of-the-art approaches with potential\nfor improvements. We believe that solutions to\nthese challenging problems will lead to significant\nadvances in digital try-on, as well as other areas of\ne-commerce.\n\n159\n\n\n\n160 J. Liang, M. C. Lin\n\n2 Open problems\nIn this section we first introduce three major\nchallenges that limit digital try-on technology from\nbeing widely adopted and accepted by shoppers.\nThere are several reasons why shoppers still prefer\nphysical try-on. Firstly, consumers are unsure if what\nthey buy online will fit them well. Although general\nsizing systems exist, their lack of consistency and\nstandardization across different brands and garment\nmaterials can often make it difficult to size clothes,\nespecially for persons with non-standard body shapes\nand proportion. Accurate estimation of human body\nshape is the key to successful digital try-on. Secondly,\nfabric is usually a key consideration when shopping\nfor clothes. Different fabric affects how garments\nlook and fit, how consumers would wear them, and\nwhether or not they would buy them. However, the\ncorrespondence between the actual material and its\ndigital representation are not well understood. It is\nalso challenging to acquire a full fabric digital model\nfrom real-world examples.\n\nFor the customers, appearance is as critical as other\nfactors. There are two approaches to displaying\ngarments: 2D image-based, and 3D mesh-based\nwith photo-realistic rendering. They have different\nadvantages and drawbacks, but both need a large\ngarment database for support. While creating a 3D\ngarment takes considerable effort, 2D images often\nsuffer from a lack of variation and are much more\ndifficult to customize. In either case, the try-on\nsystem needs a user-friendly design and manipulation\nbackend. Last, but not least, a fast and realistic\nanimation of the garments in motion along with\nbody movements greatly improves the user experience.\nAlthough it is not so critical as other factors, it\nwould effectively reduce the perceptual gap between\nthe real and digital worlds for online shopping.\nPrevious work has proposed using cloud computing\nto improve the animation speed, but there is still a\nnotable technology gap for high-quality, interactive\n3D animation of clothes.\n\n3 Human shape estimation\nAs noted, accurate human shape estimation is key to\nenabling digital try-on. Human body reconstruction,\nconsisting of pose and shape estimation, has been\nwidely studied in a variety of areas, including digital\n\nsurveillance, computer animation, special effects, and\nvirtual and augmented environments. Yet, it remains\na challenging and popular topic of interest. While\ndirect 3D body scanning can provide excellent and\naccurate results, its adoption is somewhat limited by\nthe required specialized hardware. RGB images are\nwidely available for input to digital try-on and can\nbe easily captured using commodity mobile devices.\nAlthough purely image-based try-on methods have\nbeen proposed [1], learning-based 3D body estimation\nis more widely applicable in that the 3D body can be\narticulated and so re-posed and re-targeted.\n\nWe define the human-body reconstruction problem\ninformally as, given one or more RGB images, to\nestimate the human body geometry and size, and\noutput (preferably) a 3D humanoid mesh. Traditional\nalgorithms often formulate it as an optimization\nproblem, in which the silhouette difference is a major\npart of the objective function [2]. Therefore, these\nmethods either require the human to wear tight\nclothes, or alternatively relax the target function\nto be unilateral on uncovered body parts [3], or\nto point correspondences [4]. The use of machine\nlearning methods in this problem has led to significant\nadvances. Firstly, it has moved the algorithm from\nonline to offline, significantly reducing response time.\nSecond, by using a parametric human model [5],\none can easily construct a regression network for\nthe parameters while the losses needed can also be\ninferred from them. While early works proposed\nnetwork models for only 2D/3D body skeletons [6–\n8], more recent works have introduced techniques to\nperform regression for the entire human body—either\nusing a parametric human model [9, 10] or a voxel-\nbased representation [11–13]. As annotations in most\nreal-world datasets contain only joint positions, the\nlearning process has been refined in various ways [14–\n17]. The current state of the art is the recent work\nby Ref. [18] �. It emphasizes shape learning, while\nmany other works often focus on body-joint losses,\nbut neglect the effect of body shapes.\n\nThe key contribution of Ref. [18] is a multi-view,\nmulti-stage framework to address ambiguity caused by\ncamera projection (see Fig. 1). Their model performs\nseveral stages of error correction. Each of the image\ninputs is passed on step by step; at each step, a shared-\n\n� Liang and Lin’s data and code are available at https://gamma.umd.edu/\nresearchdirections/virtualtryon/humanmultiview\n\n\n\nMachine learning for digital try-on: Challenges and progress 161\n\nFig. 1 Network structure from Ref. [18]. By using an iterative value correction structure, visual information from different views is effectively\nintegrated to provide a unified human shape. Reproduced with permission from Ref. [18], c© The Author(s) 2019.\n\nparameter prediction block computes the correction\nbased on the image feature and the input guesses.\nThe camera and the human body parameters are\nestimated at the same time, projecting the predicted\n3D joints back to 2D for loss computation. The\nestimated pose and shape parameters are shared\namong all views, while each view maintains its own\ncamera calibration and global orientation. Their\nproposed framework uses a recurrent structure,\nmaking it a universal model applicable to any number\nof views. At the same time, it couples shareable\ninformation across different views so that the human\nbody pose and shape are optimized using image\nfeatures from all views. Unlike static multi-view\nCNNs which have a fixed number of inputs, they\nmake use of the RNN-like structure in a cyclic form to\naccept any number of views, and prevent the gradient\nvanishing by predicting corrective values instead of\nupdating parameters in each regression block.\n\nExperiments have shown that, after training, this\nmodel can form a single view image, provide equally\ngood pose estimation as the state of the art, and\nprovide considerably improved pose estimation when\nusing multi-view inputs, leading to better shape\nestimation across all datasets. An example is\ndemonstrated in Fig. 2. Moreover, a physically-based\nsynthetic data generation pipeline is introduced to\nenrich the training data, which is very helpful for\n\nshape estimation and regularization in cases that\ntraditional datasets do not capture. While synthetic\ndata improves the diversity of human bodies with\nground-truth parameters, a larger garment dataset\nand a more convenient registration process are needed\nto minimize the performance gap between real-world\nimages and synthetic data. In addition, other\nvariables such as hair, skin color, and 3D backgrounds\nare subtle elements that can influence the perceived\nrealism of the synthetic data at the higher expense of\na more complex data generation pipeline. With the\nrecent progress in image style transfer using GAN, a\n\nFig. 2 Prediction results using the state of the art [18]. The model\ncaptures the shape of the human body by learning from synthetic\ndata. The recovered legs and chest are close to those of the person\nin the image. Reproduced with permission from Ref. [18], c© The\nAuthor(s) 2019.\n\n\n\n162 J. Liang, M. C. Lin\n\npromising direction is to transfer the synthetic result\nto more realistic images to further improve the result.\n\n4 Garment material modeling\n4.1 Introduction\nGarment material plays an important role in digital\ntry-on systems. Physical recreation of the fabric not\nonly gives a compelling visual simulation of the cloth,\nbut also affects how the garment feels and fits on\nthe body. However, fabric modeling is a challenging\ntask: the appearance and physical properties of\nthe garment are determined not only by the type\nof materials the clothes are made of, but also by\nsewing and weave. Thus, researchers often focus on\nthe physical behaviour, rather than the underlying\nsemantic primitives.\n\nHence, we state the garment material modeling\nproblem as follows. Given a sufficient amount of data,\nmodel the material’s physical behavior and physical\nproperties, so that visual effects the same as or similar\nto those of the real material can be reproduced by a\ncomputer. This has two implications: firstly, we need\nto define a physical model of the material, and then\nwe must estimate the parameters in the model.\n\nThere are many ways to model clothes, including\nspring–mass systems and finite elements. The latter is\nthe most popular model since it can produce realistic\nresults. While one can use isotropic properties such\nas Young’s modulus and Poisson ratio, an anisotropic\nmodel is a better choice since it can support different\nbehaviors caused by the weave of the material.\n\n4.2 Learning-based estimation\nWhile traditional optimization methods [19] often\ntake a long time to compute material parameters,\nmachine-learning methods can make predictions in\nreal time by a simple feed-forward operation, which\nis more useful in applications that need fast feedback,\nsuch as garment prototyping. The state-of-the-art\nmodel from Yang et al. [20] � uses CNNs combined\nwith LSTM to recover material parameters from\nvideos. To constrain both the input and solution\nspace, they choose one of the materials as a basis;\nthe material sub-space is constructed by multiplying\nthis material basis with a positive coefficient. To\nconstruct an optimal material parameter sub-space, a\n\n� Yang et al.’s data and code are available at http://gamma.cs.unc.edu/\nVideoCloth\n\nmaterial parameter sensitivity analysis is conducted\nto examine the sensitivity of the material parameters\nκ with respect to the amount of deformation D(κ).\nPhysically based cloth simulations are used to\ngenerate a much larger number of data samples within\nthese sub-spaces, which would otherwise be difficult\nor time-consuming to capture. The cloth meshes are\ngenerated through physically-based simulation, and\nthen rendered as 2D images with a randomly assigned\ntexture. Using the data samples, they combine the\nimage signal feature extraction method, a CNN, with\nthe temporal sequence learning method, LSTM, to\nlearn the mapping from visual appearance to material.\nAs shown in Fig. 3, the CNN layer is used to extract\nboth low- and high-level visual features, while the\nLSTM layer focuses on learning the mapping between\nthe material properties of the cloth and its consequent\nmovement.\n\nThey demonstrated the proposed framework with\nthe application of “material cloning”. With the\ntrained deep neural network model being able to\ncapture the cloth motion (Fig. 4), the material type\ncan be inferred from a video recording of the motion\nof the cloth in a fairly small amount of time. The\nrecovered material type can be “cloned” onto another\npiece of cloth or garment as shown in Fig. 5.\n\nIn this work, the videos contain only a single piece\nof cloth which does not interact with any other object.\nWhile this is not applicable to all real-world scenarios,\nthis method provides new insights into addressing this\nchallenging problem. A natural extension would be to\nlearn from videos of clothing directly interacting with\nthe human body, under varying lighting conditions\nand partial occlusion.\n\n4.3 Optimization using differentiable physics\nAnother approach to modeling the fabric is to measure\ngeometric differences directly during parameter\n\nFig. 3 Network model from Ref. [20]. The material is modeled\nby learning motion patterns of image features given by CNNs.\nReproduced with permission from Ref. [20], c© The Author(s) 2017.\n\n\n\nMachine learning for digital try-on: Challenges and progress 163\n\nFig. 4 Learned CNN conv5-layer activation visualization from\nRef. [20]. Experiments show that the trained model is able to capture\nmoving parts of the cloth even in an unseen video. Reproduced with\npermission from Ref. [20], c© The Author(s) 2017.\n\nFig. 5 Yang et al. [20] modeled clothes materials in input videos (left),\nand applied those materials to a simulated skirt (right). Reproduced\nwith permission from Ref. [20], c© The Author(s) 2017.\n\noptimization. Assuming that the environment is\nknown to the system, computation of the estimated\nmotion and its gradient with respect to the material\nparameters can be achieved using differentiable\nsimulation. A typical usage of differentiable\nsimulation is motion control (see Fig. 6), where the\ndifference to the target is measured and the loss\nbackpropagated to the network. Similar processes\ncan be applied to material parameter estimation as\nwell. By measuring the distance to the target as the\nloss and computing corresponding gradients, either in\npixel space or in 3D space, the material parameters\n\ncan be learned or optimized to achieve the desired\ncloth motion or visual effect. Recent differentiable\nphysics work covers rigid bodies [22, 23], cloth [24],\nand particle-grid systems [25, 26]. The state-of-\nthe-art is Ref. [24] �, which proposes a method for\ndifferentiable cloth simulation. It is the first work\nto tackle a high dimensional simulation problem\nand to propose a general differentiable collision\nhandling algorithm. Later, a follow-up work [21]\nextended the algorithm to be applicable to coupled\ndynamics with rigid bodies. Overall, they follow\nthe computational flow of the common approach\nto cloth simulation: discretization using the finite\nelement method, integration using an implicit Euler\nmethod, and collision response on impact zones. They\nuse implicit differentiation in the linear solver and\noptimization in order to compute the gradient with\nrespect to the input parameters. The discontinuity\nintroduced by collision response is negligible because\nthe discontinuous states constitute a zero-measure\nset. During backpropagation in the optimization,\ngradient values can be directly computed after QR\ndecomposition of the constraint matrix. Their\npipeline contains several techniques that can be\nemployed in other differentiable simulations.\n4.3.1 Derivatives of the physical solution\nIn modern simulation algorithms, an implicit Euler\nmethod is often used for stable integration results.\nThus the mass matrix M often includes the Jacobian\nof the forces, and is denoted as M̂ to indicate this\ndifference. A linear solver is needed to compute the\nacceleration since it is time-consuming to compute\nM̂−1. Implicit differentiation is used to compute the\ngradients of the linear solution. Given an equation\nM̂a = f with a solution z and propagated gradient\n∂L/∂a|a=z, where L is the task-specific loss function,\nimplicit differentiation is used to derive the gradients.\nWe refer readers to the original paper [24] for more\ndetails.\n4.3.2 Derivatives of the collision response\nA general approach using LCP to integrate collision\nconstraints into physics simulations has been\nproposed, but constructing a static LCP is often\nimpractical in cloth simulation due to the high\ndimensionality. Collisions and contacts which happen\nat each step are very sparse compared to the complete\n\n� Liang et al.’s data and code are available at https://gamma.umd.edu/\nresearchdirections/virtualtryon/differentiablecloth\n\n\n\n164 J. Liang, M. C. Lin\n\nFig. 6 Differentiable simulation embedding example from Ref. [21]. The loss can be backpropagated through the physics simulator to the\nneural network, enabling learning tasks such as material modeling and motion control.\n\ndata. Therefore, a dynamic approach is used that\nincorporates collision detection and response.\n\nCollision handling in their implementation is based\non impact zone optimization. It finds all colliding\ninstances using continuous collision detection and\nsets up the constraints for all collisions. In order\nto introduce minimum change to the original mesh\nstate, a QP problem is developed to determine the\nconstraints. Since the signed distance function is\nlinear in x, the optimization takes a quadratic form,\nas shown originally in Ref. [24]:\n\nminimize\nz\n\n1\n2\n\n(z − x)TW (z − x),\n\nsubject to Gz + h � 0\nwhere W is a constant diagonal weight matrix related\nto the mass of each vertex, and G and h are constraint\nparameters. The numbers of variables and constraints\nare n and m, i.e. x ∈ R\n\nn, h ∈ R\nm, and G ∈ R\n\nm×n.\nNote that this optimization problem has inputs x,\nG, and h, and output z. The goal here is to derive\n∂L/∂x, ∂L/∂G, and ∂L/∂h given ∂L/∂z, where L\nis the loss function.\n\nWhen computing the gradient using implicit\ndifferentiation, the dimensionality of the linear system\ncan be very high. Their key observation here is that\nn >> m > rank(G), since one contact often involves 4\nvertices (thus 12 variables) and some contacts may be\nlinearly dependent (e.g., multiple adjacent collision\n\npairs). They minimize the size of the linear equation\nbased on the QR decomposition of G, which is the key\nto accelerating backpropagation of high dimensional\nQP problems.\n\nOne of their experiments shows its ability to\noptimize material parameters from observation. The\nscene features a piece of cloth hanging under gravity\nand subjected to a constant wind force. The material\nmodel consists of three parts: density d, stretching\nstiffness S, and bending stiffness B. The stretching\nstiffness quantifies the reaction force when the cloth\nis stretched; the bending stiffness models how easily\nthe cloth can be bent and folded. Table 1 shows\nresults. They achieve a much smaller error in most\nmeasurements in comparison to the baselines; the\nlinear part of the stiffness matrix is modeled well.\nWith the computed gradient using their model, one\ncan effectively optimize the unknown parameters that\ndominate cloth movement to fit the observed data.\n\nIn follow-up work, Qiao et al. extended the\ndifferentiable simulation pipeline to couple with\nrigid body dynamics, formulated using generalized\ncoordinates:\n\nd\ndt\n\n⎛\n⎝ q\n\nq̇\n\n⎞\n⎠ =\n\n⎛\n⎝ q̇\n\nq̈\n\n⎞\n⎠ =\n\n⎛\n⎝ q̇\n\nM−1f(q, q̇)\n\n⎞\n⎠\n\nand update the optimization formulation for collision\nresponse accordingly (see Ref. [21] for details):\n\nTable 1 Material parameter estimation results from Ref. [24]. Their proposed method runs faster than L-BFGS. Values of material parameters\nare Frobenius norms of the difference normalized by the Frobenius norm of the target. Values of the simulated result are the average pairwise\nvertex distances normalized by the size of the cloth. The gradient-based method yields much smaller errors than the baselines\n\nMethod\nRuntime\n\n(sec/step/iter)\n\nDensity\n\nerror (%)\n\nLinear stretching\n\nstiffness error (%)\n\nBending stiffness\n\nerror (%)\n\nSimulation\n\nerror (%)\n\nBaseline — 68 ± 46 160 ± 119 70 ± 42 12 ± 3.0\n\nL-BFGS 2.89 ± 0.02 4.2 ± 5.6 72 ± 90 70 ± 43 4.9 ± 3.3\n\nLiang et al. [24] 2.03 ± 0.06 1.8 ± 2.0 45 ± 41 77 ± 36 1.6 ± 1.4\n\n\n\nMachine learning for digital try-on: Challenges and progress 165\n\nminimize\nq′\n\n1\n2\n\n(q − q′)TM̂(q − q′)\n\nsubject to Gf(q′) + h � 0\n\nDue to the inclusion of rigid bodies, the constraints\nused in the optimization are no longer linear. When\ncomputing gradients, they linearize the constraints\naround a neighborhood as an approximation to enable\nQR decomposition for acceleration as previously\nmentioned.\n\n5 Garment modeling and design\nRealistic apparel model generation has become\nincreasingly popular, due to the rapid changes in\nfashion trends and the growing need for garment\nmodels in different applications such as virtual try-\non. It is already used even for state-of-the-art\ninteractive apparel design systems [27]. Application\nrequirements mean that it is important to have a\ngeneral cloth model that can represent a diverse set\nof garments. However, there are many challenges\nin automatic garment model generation. Firstly,\ngarments usually have different types of topology,\nespecially for fashion apparel, that makes it difficult\nto design a universal pipeline. Moreover, it is often\nnot straightforward for general garments design to\nbe retargeted onto another body shape, making\ncustomization difficult.\n\nPrevious work has addressed this problem to some\nextent. Huang et al. [28] proposed a realistic 3D\ngarment generation algorithm based on front and\nback image sketches, but it cannot readily retarget\ngenerated garments to other body shapes. Wang et\nal. [29] proposed an algorithm which can conveniently\nperform retargeting, but permits limited topology\nlike T-shirts or skirts. There is no recent work that\naddresses these two problems at the same time.\n\nWe introduce a learning-based parametric\ngenerative model to overcome the above difficulties,\ngiven garment sewing patterns and human body\nshapes as input. One possible approach would be to\ncompute a displacement image on the U–V space\nof the human body as a unified representation of\nthe garment mesh. Different topology and sizes\nof the garment are represented by different values\nin the image. The 2D displacement image, as the\nrepresentation of the 3D garment mesh data, can\n\nthen be fed into a conditional generative adversarial\nnetwork (cGAN) for latent space learning. The 2D\nrepresentation for the garment mesh can transfer\nthe irregular 3D mesh data to regular image data\nwhere a traditional CNN can easily learn. It can also\nextract relative geometric information with respect\nto the human body, enabling garment retargeting to\na different person.\n\n6 Conclusions\nAlthough virtual reality and digital try-on have\nexcellent potential and are rapidly developing, there\nremain open problems before online try-on systems\ncan be widely adopted. We have listed three major\nchallenges, all of which can be addressed or further\nimproved using machine learning algorithms. For\ngarment material prediction, state-of-the-art methods\nare still limited in that the training data is highly\nconstrained: the scenario contains only a piece\nof cloth floating in the wind. To improve its\napplicability to daily tasks, it is necessary to focus\non solving the problem on a more diverse set of\ninputs. Predicting the material from a garment\non a fixed human body could be a good start,\nbefore generalizing to arbitrary human motions and\npredicting multiple garments on the same body. In\nthe area of human shape estimation, it would be\ninteresting to learn how external constraints could\nimprove estimation accuracy. For example, the shape\nand size of the garment are hard constraints to\nwhich the predicted body should conform. While\noptimization-based methods can integrate these\nconstraints fairly easily, doing so remains elusive\nfor learning-based approaches. One possibility is\nto jointly estimate body and garment together and\nintroduce an intersection loss. This approach would\nrequire a new solution to the open problem of unified\ndeep garment representation, if we do not want to\ntrain one model for every garment type, which could\nbe even more challenging. We believe that substantial\nbreakthroughs in digital try-on are achievable with\nmore investigation in these directions.\n\nAcknowledgements\nThis research was supported in part by the Iribe\nProfessorship and the National Science Foundation.\n\n\n\n166 J. Liang, M. C. Lin\n\nReferences\n\n[1] Zheng, Z. H.; Zhang, H. T.; Zhang, F. L.; Mu, T. J.\nImage-based clothes changing system. Computational\nVisual Media Vol. 3, No. 4, 337–347, 2017.\n\n[2] Dibra, E.; Jain, H.; Öztireli, C.; Ziegler, R.; Gross,\nM. HS-Nets: Estimating human body shape from\nsilhouettes with convolutional neural networks. In:\nProceedings of the 4th International Conference on\n3D Vision, 108–117, 2016.\n\n[3] Bălan, A. O.; Black, M. J. The naked truth: Estimating\nbody shape under clothing. In: Computer Vision –\nECCV 2008. Lecture Notes in Computer Science, Vol.\n5303. Forsyth, D.; Torr, P.; Zisserman, A. Eds. Springer\nBerlin, 15–29, 2008.\n\n[4] Lassner, C.; Romero, J.; Kiefel, M.; Bogo, F.; Black,\nM. J.; Gehler, P. V. Unite the people: Closing the\nloop between 3D and 2D human representations. In:\nProceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, 4704–4713, 2017.\n\n[5] Loper, M.; Mahmood, N.; Romero, J.; Pons-Moll, G.;\nBlack, M. J. SMPL: A skinned multi-person linear\nmodel. ACM Transactions on Graphics Vol. 34, No. 6,\nArticle No. 248, 2015.\n\n[6] Wei, S.-E.; Ramakrishna, V.; Kanade, T.; Sheikh, Y.\nConvolutional pose machines. In: Proceedings of the\nIEEE conference on Computer Vision and Pattern\nRecognition, 4724–4732, 2016.\n\n[7] Cao, Z.; Simon, T.; Wei, S.; Sheikh, Y. Realtime multi-\nperson 2D pose estimation using part affinity fields.\nIn: Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, 1302–1310, 2017.\n\n[8] Mehta, D.; Sridhar, S.; Sotnychenko, O.; Rhodin, H.;\nShafiei, M.; Seidel, H.-P.; Xu, W.; Casas, D.; Theobalt,\nC. VNect: Realtime 3D human pose estimation with\na single RGB camera. ACM Transactions on Graphics\nVol. 36, No. 4, Article No. 44, 2017.\n\n[9] Alldieck, T.; Magnor, M.; Xu, W.; Theobalt, C.; Pons-\nMoll, G. Video based reconstruction of 3D people\nmodels. In: Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition, 8387–8397,\n2018.\n\n[10] Kanazawa, A.; Black, M. J.; Jacobs, D. W.; Malik, J.\nEnd-to-end recovery of human shape and pose. In:\nProceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, 7122–7131, 2018.\n\n[11] Varol, G.; Ceylan, D.; Russell, B.; Yang, J.; Yumer,\nE.; Laptev, I. Bodynet: Volumetric inference of 3D\nhuman body shapes. In: Proceedings of the European\nConference on Computer Vision, 20–36, 2018.\n\n[12] Zheng, Z.; Yu, T.; Wei, Y.; Dai, Q.; Liu, Y. Deephuman:\n3D human reconstruction from a single image. In:\n\nProceedings of the IEEE International Conference on\nComputer Vision, 7739–7749, 2019.\n\n[13] Saito, S.; Huang, Z.; Natsume, R.; Morishima, S.;\nKanazawa, A.; Li, H. PIFu: Pixel-aligned implicit\nfunction for high-resolution clothed human digitization.\nIn: Proceedings of the IEEE International Conference\non Computer Vision, 2304–2314, 2019.\n\n[14] Xu, Y.; Zhu, S.-C.; Tung, T. Denserac: Joint 3D pose\nand shape estimation by dense render-and-compare. In:\nProceedings of the IEEE International Conference on\nComputer Vision, 7760–7770, 2019.\n\n[15] Smith, D.; Loper, M.; Hu, X.; Mavroidis, P.; Romero,\nJ. FACSIMILE: Fast and accurate scans from an image\nin less than a second. In: Proceedings of the IEEE\nInternational Conference on Computer Vision, 5329–\n5338, 2019.\n\n[16] Alldieck, T.; Magnor, M.; Bhatnagar, B. L.; Theobalt,\nC.; Pons-Moll, G. Learning to reconstruct people in\nclothing from a single RGB camera. In: Proceedings of\nthe IEEE Conference on Computer Vision and Pattern\nRecognition, 1175–1186, 2019.\n\n[17] Kolotouros, N.; Pavlakos, G.; Black, M. J.; Daniilidis,\nK. Learning to reconstruct 3D human pose and shape\nvia modelfitting in the loop. In: Proceedings of the\nIEEE International Conference on Computer Vision,\n2252–2261, 2019.\n\n[18] Liang, J.; Lin, M. C. Shape-aware human pose and\nshape reconstruction using multi-view images. In:\nProceedings of the IEEE International Conference on\nComputer Vision, 4352–4362, 2019.\n\n[19] Yang, S.; Pan, Z. R.; Amert, T.; Wang, K.; Yu, L.\nC.; Berg, T.; Lin, M. C. Physics-inspired garment\nrecovery from a single-view image. ACM Transactions\non Graphics Vol. 37, No. 5, Article No. 170, 2018.\n\n[20] Yang, S.; Liang, J.; Lin, M. C.; Learning-based cloth\nmaterial recovery from video. In: Proceedings of the\nIEEE International Conference on Computer Vision,\n4383–4393, 2017.\n\n[21] Qiao, Y. L.; Liang, J. B.; Koltun, V.; Lin, M. C.\nScalable differentiable physics for learning and control.\narXiv preprint arXiv:2007.02168, 2020.\n\n[22] De Avila Belbute-Peres, F.; Smith, K. A.; Allen, K.;\nTenenbaum, J.; Kolter, J. Z. End-to-end differentiable\nphysics for learning and control. In: Proceedings of the\nAdvances in Neural Information Processing Systems,\n2018.\n\n[23] Degrave, J.; Hermans, M.; Dambre, J.; Wyffels, F.\nA differentiable physics engine for deep learning in\nrobotics. Frontiers in Neurorobotics Vol. 13, 6, 2019.\n\n[24] Liang, J.; Lin, M.; Koltun, V. Differentiable cloth\nsimulation for inverse problems. In: Proceedings of\nthe 33rd Conference on Neural Information Processing\nSystems, 2019.\n\n\n\nMachine learning for digital try-on: Challenges and progress 167\n\n[25] Hu, Y.; Liu, J.; Spielberg, A.; Tenenbaum, J.\nB.; Freeman, W. T.; Wu, J.; Rus, D.; Matusik,\nW. ChainQueen: A real-time differentiable physical\nsimulator for soft robotics. In: Proceedings of the\nInternational Conference on Robotics and Automation,\n6265–6271, 2019.\n\n[26] Hu, Y. M.; Anderson, L.; Li, T. M.; Sun, Q.; Carr, N.;\nRagan-Kelley, J.; Durand, F. DiffTaichi: Differentiable\nprogramming for physical simulation. arXiv preprint\narXiv:1910.00935, 2019.\n\n[27] Liu, K. X.; Zeng, X. Y.; Bruniaux, P.; Tao, X. Y.; Yao,\nX. F.; Li, V.; Wang, J. 3D interactive garment pattern-\nmaking technology. Computer-Aided Design Vol. 104,\n113–124, 2018.\n\n[28] Huang, P.; Yao, J.; Zhao, H. Automatic realistic\n3D garment generation based on two images. In:\nProceedings of the International Conference on Virtual\nReality and Visualization, 250–257, 2016.\n\n[29] Wang, T. Y.; Ceylan, D.; Popović, J.; Mitra, N. J.\nLearning a shared shape space for multimodal garment\ndesign. ACM Transactions on Graphics Vol. 37, No. 6,\nArticle No. 203,", "metadata_storage_path": "aHR0cHM6Ly9rYm1zdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9wYXBlcnMvTGlhbmctTGluMjAyMV9BcnRpY2xlX01hY2hpbmVMZWFybmluZ0ZvckRpZ2l0YWxUcnktby5wZGY1", "metadata_author": "Administrator", "metadata_title": "01-CVM0189.pdf", "metadata_creation_date": "2021-04-14T08:29:06Z", "people": [ "Junbang Liang1", "Ming C. Lin1", "J. Liang", "M. C. Lin", "lin", "Liang", "Lin", "Yang", "Euler", "Qiao", "Frobenius", "Huang", "Wang", "Zheng, Z. H.", "Zhang, H. T.", "Zhang, F. L.", "Mu, T. J.", "Dibra, E.", "Jain, H.", "Öztireli, C.", "Ziegler, R", "Gross", "M. HS-Nets", "Bălan, A. O.", "Black, M. J.", "Forsyth, D.", "Torr, P", "Zisserman,", "Lassner, C.", "Romero, J.", "Kiefel, M", "Bogo, F.", "Black", "M. J.", "Gehler, P. V", "Loper, M", "Mahmood, N", "Pons-Moll, G.", "Wei, S", "Ramakrishna, V", "Kanade, T.", "Sheikh, Y", "Cao, Z", "Simon, T.", "Wei, S.", "Sheikh, Y.", "Mehta, D", "Sridhar, S.", "Sotnychenko,", "Rhodin, H.", "Shafiei, M", "Seidel", "Xu, W.", "Casas, D.", "Theobalt", "C. VNect", "Alldieck, T", "Magnor, M.", "Theobalt, C.", "Pons", "Moll, G", "Kanazawa, A.", "Jacobs, D. W.", "Malik, J.", "Varol, G.", "Ceylan, D.", "Russell, B.", "Yang, J.", "Yumer", "Laptev, I", "Zheng, Z.", "Yu, T.", "Wei, Y.", "Dai, Q", "Liu, Y. Deephuman", "Saito, S", "Huang, Z.", "Natsume, R.", "Morishima, S", "Li", "Xu, Y", "Zhu, S.-C.", "Tung", "T. Denserac", "Smith, D.", "Hu", "Mavroidis, P", "Romero", "Alldieck, T.", "Bhatnagar, B. L.", "Pons-Moll, G", "Kolotouros", "Pavlakos, G.", "Daniilidis", "K", "Liang, J.", "Lin, M. C.", "Yang, S.", "Pan, Z. R.", "Amert, T.", "Wang, K.", "Yu, L.", "Berg, T.", "Qiao, Y. L.", "Liang, J. B.", "Koltun", "De Avila Belbute-Peres, F.", "Smith, K. A.", "Allen, K.", "Tenenbaum, J.", "Kolter, J. Z.", "Degrave, J.", "Hermans, M.", "Dambre, J.", "Wyffels, F", "Lin, M.", "Hu, Y.", "Liu, J.", "Spielberg, A.", "Tenenbaum, J", "Freeman, W. T.", "Wu, J.", "Rus, D.", "Matusik", "W. ChainQueen", "Hu, Y. M.", "Anderson, L.", "Li, T. M.", "Sun, Q.", "Carr, N.", "Ragan-Kelley, J.", "Durand, F.", "Liu, K. X.", "Zeng, X. Y.", "Bruniaux, P", "Tao, X. Y.", "X. F", "Wang, J.", "Huang, P.", "Yao, J.", "Zhao, H.", "Wang, T. Y.", "Popović, J.", "Mitra, N. J." ], "organizations": [ "University of Maryland", "RNN", "VideoCloth", "CNN", "LSTM", "dt", "Iribe", "National Science Foundation", "ECCV", "Springer", "ACM", "IEEE", "arXiv", "Systems" ], "locations": [ "retail store", "USA", "neighborhood", "Berlin" ], "keyphrases": [ "variable 3D human body shapes", "Computational Visual Media", "Ming C. Lin1", "The Author(s", "direct visual impression", "M. C. Lin", "2D image learning", "substantial technological gap", "human body estimation", "open research issues", "three major challenges", "human shapes", "open issues", "accurate estimation", "extensive research", "open challenges", "2 Open problems", "Machine learning", "doi.org", "Review Article", "Junbang Liang1", "economic benefits", "practical constraints", "accurate sizing", "art approaches", "future directions", "rapid pace", "recent years", "retail store", "attractive alternative", "user experience", "fashion shopping", "physical try", "image- editing", "College Park", "J. Liang", "ultimate goal", "real worlds", "physical worlds", "consumer devices", "faithful recovery", "sewing patterns", "traditional methods", "constrained problems", "learning-based approaches", "machine-learning algorithms", "tedious data", "challenging problems", "other areas", "several reasons", "material modeling", "accurate modeling", "faithful modeling", "garment material", "garment pieces", "recent advances", "template demonstrations", "realistic demonstration", "notable impact", "unseen images", "garment modeling", "digital try", "Abstract Digital", "tremendous potential", "problem description", "sizing systems", "Vol.", "June", "progress", "commerce", "people", "lives", "development", "realism", "complete", "state", "Keywords", "1 Introduction", "Consumers", "situation", "clothes", "needs", "attention", "technology", "1 University", "Maryland", "USA", "mail", "liangjb", "umd", "Manuscript", "fast", "customer", "garments", "lossless", "transformation", "virtual", "paper", "sizes", "ease", "design", "manipulation", "end-users", "training", "optimization", "processing", "importance", "present", "improvements", "solutions", "significant", "section", "shoppers", "lack", "consistency", "direct 3D body scanning", "full fabric digital model", "accurate human shape estimation", "parametric human model", "commodity mobile devices", "uncovered body parts", "2D/3D body skeletons", "successful digital try", "Human body reconstruction", "human body geometry", "entire human body", "notable technology gap", "voxel- based representation", "3D humanoid mesh", "standard body shapes", "human-body reconstruction problem", "3 Human shape estimation", "many other works", "machine learning methods", "Accurate estimation", "digital representation", "shape learning", "body movements", "accurate results", "digital worlds", "digital surveillance", "perceptual gap", "3D mesh-based", "3D animation", "early works", "recent works", "learning process", "Different fabric", "actual material", "real-world examples", "two approaches", "2D image-based", "photo-realistic rendering", "considerable effort", "2D images", "user-friendly design", "realistic animation", "other factors", "Previous work", "cloud computing", "animation speed", "high-quality, interactive", "computer animation", "special effects", "augmented environments", "popular topic", "specialized hardware", "RGB images", "Traditional algorithms", "optimization problem", "silhouette difference", "objective function", "target function", "response time", "network models", "real-world datasets", "joint positions", "various ways", "current state", "different brands", "garment materials", "garment database", "key consideration", "online shopping", "regression network", "body-joint losses", "standardization", "persons", "proportion", "consumers", "correspondence", "customers", "appearance", "advantages", "drawbacks", "large", "support", "variation", "case", "system", "backend", "motion", "pose", "variety", "areas", "challenging", "interest", "excellent", "adoption", "input", "one", "size", "output", "major", "tight", "advances", "parameters", "techniques", "annotations", "most", "Ref.", "complex data generation pipeline", "iterative value correction structure", "synthetic data generation pipeline", "garment material modeling problem", "convenient registration process", "larger garment dataset", "compelling visual simulation", "parameter prediction block", "image style transfer", "4 Garment material modeling", "good pose estimation", "single view image", "unified human shape", "human body parameters", "Network structure", "recurrent structure", "RNN-like structure", "regression block", "Prediction results", "fabric modeling", "error correction", "visual effects", "estimated pose", "body pose", "human bodies", "training data", "key contribution", "several stages", "image feature", "input guesses", "same time", "3D joints", "loss computation", "global orientation", "static multi-view", "cyclic form", "corrective values", "ground-truth parameters", "performance gap", "real-world images", "other variables", "skin color", "3D backgrounds", "subtle elements", "higher expense", "promising direction", "realistic images", "important role", "Physical recreation", "challenging task", "physical properties", "physical behaviour", "semantic primitives", "sufficient amount", "physical behavior", "synthetic result", "visual information", "camera projection", "image inputs", "shape parameters", "camera calibration", "multi-view inputs", "shape estimation", "multi-stage framework", "traditional datasets", "recent progress", "162 J. Liang", "different views", "fixed number", "universal model", "ambiguity", "Fig.", "step", "code", "gamma", "researchdirections", "virtualtryon", "humanmultiview", "digital", "Challenges", "permission", "2D", "features", "CNNs", "use", "gradient", "Experiments", "art", "example", "regularization", "cases", "diversity", "addition", "hair", "GAN", "legs", "chest", "person", "Author", "Introduction", "systems", "cloth", "type", "materials", "sewing", "researchers", "underlying", "image signal feature extraction method", "temporal sequence learning method", "CNN conv5-layer activation visualization", "deep neural network model", "material parameter sensitivity analysis", "spring–mass systems", "simple feed-forward operation", "varying lighting conditions", "high-level visual features", "optimal material parameter", "traditional optimization methods", "image features", "machine-learning methods", "visual appearance", "CNN layer", "two implications", "physical model", "many ways", "finite elements", "popular model", "realistic results", "isotropic properties", "Poisson ratio", "anisotropic model", "different behaviors", "4.2 Learning-based estimation", "fast feedback", "art model", "solution space", "positive coefficient", "larger number", "based simulation", "consequent movement", "video recording", "other object", "real-world scenarios", "new insights", "challenging problem", "natural extension", "human body", "partial occlusion", "differentiable physics", "geometric differences", "unseen video", "real material", "material sub-space", "material properties", "material cloning", "material type", "material parameters", "long time", "real time", "data samples", "motion patterns", "garment prototyping", "small amount", "single piece", "material basis", "cloth simulations", "cloth meshes", "LSTM layer", "cloth motion", "clothes materials", "input videos", "computer", "Young", "modulus", "choice", "weave", "predictions", "applications", "Yang", "unc", "VideoCloth", "respect", "deformation", "sub-spaces", "texture", "mapping", "framework", "clothing", "approach", "fabric", "parts", "simulated", "skirt", "environment", "computation", "constant diagonal weight matrix", "high dimensional simulation problem", "finite element method", "modern simulation algorithms", "differentiablecloth 164 J. Liang", "material parameter estimation", "stable integration results", "other differentiable simulations", "Differentiable simulation embedding", "implicit Euler method", "continuous collision detection", "original mesh state", "general differentiable collision", "task-specific loss function", "impact zone optimization", "differentiable cloth simulation", "high dimensionality", "QP problem", "constraint matrix", "impact zones", "M̂a", "original paper", "general approach", "physics simulations", "complete � Liang", "implicit differentiation", "Collision handling", "mass matrix", "typical usage", "Similar processes", "pixel space", "3D space", "visual effect", "physics work", "rigid bodies", "particle-grid systems", "first work", "follow-up work", "computational flow", "common approach", "collision response", "linear solver", "input parameters", "discontinuous states", "several techniques", "physical solution", "linear solution", "solution z", "physics simulator", "dynamic approach", "minimum change", "distance function", "quadratic form", "constraint parameters", "motion control", "handling algorithm", "collision constraints", "static LCP", "neural network", "corresponding gradients", "gradient values", "difference", "target", "computing", "dynamics", "discretization", "order", "discontinuity", "zero-measure", "backpropagation", "QR", "decomposition", "pipeline", "Derivatives", "Jacobian", "forces", "acceleration", "equation", "readers", "details", "Collisions", "contacts", "data", "edu", "learning", "tasks", "implementation", "instances", "Gz", "vertex", "numbers", "variables", "3.1", "3.2", "multiple adjacent collision pairs", "interactive apparel design systems", "automatic garment model generation", "Material parameter estimation results", "Realistic apparel model generation", "garment generation algorithm", "other body shapes", "constant wind force", "rigid body dynamics", "differentiable simulation pipeline", "bending stiffness models", "baselines Method Runtime", "general cloth model", "fashion apparel", "material model", "garment models", "realistic 3D", "Garment modeling", "reaction force", "universal pipeline", "Simulation error", "L/∂z", "loss function", "linear system", "one contact", "linear equation", "QR decomposition", "high dimensional", "QP problems", "The scene", "three parts", "stiffness S", "stiffness B.", "most measurements", "linear part", "stiffness matrix", "unknown parameters", "generalized coordinates", "Frobenius norms", "simulated result", "vertex distances", "gradient-based method", "smaller errors", "computing gradients", "rapid changes", "fashion trends", "growing need", "different applications", "Application requirements", "diverse set", "different types", "image sketches", "general garments", "optimization formulation", "stiffness error", "cloth movement", "Linear stretching", "many challenges", "key observation", "inputs", "goal", "dimensionality", "rank", "4 vertices", "12 variables", "experiments", "ability", "piece", "gravity", "density", "Table 1", "comparison", "Qiao", "dt", "q̇", "response", "L-BFGS.", "Values", "average", "iter", "Liang", "Gf", "inclusion", "constraints", "neighborhood", "approximation", "topology", "customization", "extent", "Huang", "front", "Wang", "−", "5", "conditional generative adversarial network", "Image-based clothes changing system", "skinned multi-person linear model", "learning-based parametric generative model", "irregular 3D mesh data", "M. C. Lin References", "3D garment mesh data", "latent space learning", "relative geometric information", "machine learning algorithms", "convolutional neural networks", "Convolutional pose machines", "regular image data", "arbitrary human motions", "National Science Foundation", "4th International Conference", "A. Eds. Springer", "2D human representations", "garment sewing patterns", "U–V space", "2D displacement image", "Visual Media Vol.", "One possible approach", "The 2D representation", "human shape estimation", "deep garment representation", "garment material prediction", "M. J. SMPL", "human body shape", "one model", "3D Vision", "estimation accuracy", "A. O.", "Computer Science", "IEEE Conference", "One possibility", "M. HS-Nets", "limited topology", "recent work", "two problems", "Different topology", "different values", "traditional CNN", "different person", "virtual reality", "excellent potential", "open problems", "art methods", "daily tasks", "good start", "multiple garments", "optimization-based methods", "intersection loss", "new solution", "garment type", "substantial breakthroughs", "Iribe Professorship", "Öztireli", "naked truth", "Computer Vision", "Lecture Notes", "Pattern Recognition", "ACM Transactions", "Article No.", "S.-E.", "same body", "166 J. Liang", "unified representation", "external constraints", "hard constraints", "Z. H.", "T. J.", "F. L.", "P. V.", "H. T.", "al.", "retargeting", "T-shirts", "skirts", "difficulties", "shapes", "cGAN", "6 Conclusions", "scenario", "wind", "applicability", "area", "investigation", "directions", "Acknowledgements", "research", "part", "Zhang", "Computational", "Dibra", "Jain", "Ziegler", "R.", "Gross", "silhouettes", "Proceedings", "Black", "ECCV", "Forsyth", "D.", "Torr", "Zisserman", "Berlin", "Romero", "Kiefel", "Bogo", "Gehler", "loop", "Loper", "Mahmood", "N.", "Pons-Moll", "G.", "Graphics", "Wei", "Ramakrishna", "Kanade", "Sheikh", "Y.", "Y. Realtime multi- person 2D pose estimation", "Realtime 3D human pose estimation", "Neural Information Processing Systems", "V. Differentiable cloth simulation", "Joint 3D pose", "Shape-aware human pose", "part affinity fields", "human body shapes", "De Avila Belbute-Peres", "Scalable differentiable physics", "differentiable physics engine", "single RGB camera", "3D human reconstruction", "IEEE International Conference", "3D people models", "Video based reconstruction", "IEEE conference", "human digitization", "Learning-based cloth", "human shape", "European Conference", "33rd Conference", "shape reconstruction", "Y. Deephuman", "Y. L.", "single image", "Pons- Moll", "I. Bodynet", "Volumetric inference", "high-resolution clothed", "accurate scans", "multi-view images", "Physics-inspired garment", "arXiv preprint", "inverse problems", "B. L.", "H.-P.", "C. VNect", "end recovery", "H. PIFu", "L. C.", "single-view image", "material recovery", "deep learning", "a second", "J. FACSIMILE", "T. Denserac", "M. C.", "J. B.", "Graphics Vol.", "Z. R.", "M. J.", "J. Z.", "W. T.", "D. W.", "K. A.", "Cao", "Simon", "S.", "Mehta", "Sridhar", "Sotnychenko", "Rhodin", "Shafiei", "Seidel", "Xu", "Casas", "Theobalt", "Alldieck", "Magnor", "Kanazawa", "Jacobs", "Malik", "Varol", "Ceylan", "Russell", "Yumer", "E.", "Laptev", "Zheng", "Dai", "Q.", "Liu", "Saito", "Natsume", "Morishima", "Pixel-aligned", "function", "Zhu", "Tung", "Smith", "X.", "Mavroidis", "Fast", "less", "Bhatnagar", "Kolotouros", "Pavlakos", "Daniilidis", "modelfitting", "Lin", "Pan", "Amert", "Berg", "Koltun", "control", "F.", "Allen", "Tenenbaum", "Kolter", "Advances", "Degrave", "Hermans", "Dambre", "Wyffels", "robotics", "Frontiers", "Freeman", "Wu", "real-time differentiable physical simulator", "3D garment generation", "shared shape space", "multimodal garment design", "physical simulation", "Computer-Aided Design", "W. ChainQueen", "International Conference", "Y. M.", "T. M.", "F. DiffTaichi", "K. X.", "X. Y.", "X. F.", "H. Automatic", "two images", "Virtual Reality", "T. Y.", "soft robotics", "N. J.", "Rus", "Matusik", "Automation", "Hu", "Anderson", "Sun", "Carr", "Ragan-Kelley", "Durand", "programming", "Zeng", "Bruniaux", "P.", "Tao", "Yao", "V.", "Zhao", "Visualization", "Popović", "Mitra" ], "pii_entities": [ { "text": "https://doi.org/10.1007/s41095-020-0189-1", "type": "URL", "subtype": null, "offset": 28, "length": 41, "score": 0.8 }, { "text": "2, June 2021", "type": "DateTime", "subtype": "Date", "offset": 82, "length": 12, "score": 0.8 }, { "text": "Junbang Liang1", "type": "Person", "subtype": null, "offset": 183, "length": 14, "score": 0.99 }, { "text": "Ming C. Lin1", "type": "Person", "subtype": null, "offset": 203, "length": 12, "score": 0.99 }, { "text": "The Author", "type": "Organization", "subtype": null, "offset": 220, "length": 10, "score": 0.59 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 234, "length": 4, "score": 0.8 }, { "text": "today", "type": "DateTime", "subtype": "Date", "offset": 950, "length": 5, "score": 0.8 }, { "text": "College Park, MD 20785, USA", "type": "Address", "subtype": null, "offset": 1703, "length": 27, "score": 0.88 }, { "text": "J. Liang", "type": "Person", "subtype": null, "offset": 1740, "length": 8, "score": 0.98 }, { "text": "liangjb@cs.umd.edu", "type": "Email", "subtype": null, "offset": 1750, "length": 18, "score": 0.8 }, { "text": "M. C. Lin", "type": "Person", "subtype": null, "offset": 1774, "length": 9, "score": 0.97 }, { "text": "lin@cs.umd.edu", "type": "Email", "subtype": null, "offset": 1785, "length": 14, "score": 0.8 }, { "text": "2020-06-24", "type": "DateTime", "subtype": "Date", "offset": 1823, "length": 10, "score": 0.8 }, { "text": "2020-07-21", "type": "DateTime", "subtype": "Date", "offset": 1845, "length": 10, "score": 0.8 }, { "text": "customer", "type": "PersonType", "subtype": null, "offset": 1936, "length": 8, "score": 0.96 }, { "text": "end-users", "type": "PersonType", "subtype": null, "offset": 2615, "length": 9, "score": 0.76 }, { "text": "J. Liang", "type": "Person", "subtype": null, "offset": 3580, "length": 8, "score": 0.88 }, { "text": "M. C. Lin", "type": "Person", "subtype": null, "offset": 3590, "length": 9, "score": 0.97 }, { "text": "shoppers", "type": "PersonType", "subtype": null, "offset": 3754, "length": 8, "score": 0.96 }, { "text": "customers", "type": "PersonType", "subtype": null, "offset": 4640, "length": 9, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 5267, "length": 4, "score": 0.76 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 5592, "length": 2, "score": 0.8 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 6019, "length": 2, "score": 0.8 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 6635, "length": 2, "score": 0.8 }, { "text": "2D", "type": "DateTime", "subtype": "Duration", "offset": 7402, "length": 2, "score": 0.8 }, { "text": "Liang", "type": "Person", "subtype": null, "offset": 8212, "length": 5, "score": 0.96 }, { "text": "Lin", "type": "Person", "subtype": null, "offset": 8222, "length": 3, "score": 0.98 }, { "text": "https://gamma.umd.edu/", "type": "URL", "subtype": null, "offset": 8259, "length": 22, "score": 0.8 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 8649, "length": 4, "score": 0.8 }, { "text": "CNNs", "type": "Organization", "subtype": null, "offset": 9347, "length": 4, "score": 0.51 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 10451, "length": 2, "score": 0.8 }, { "text": "Author", "type": "PersonType", "subtype": null, "offset": 10943, "length": 6, "score": 0.65 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 10953, "length": 4, "score": 0.8 }, { "text": "J. Liang", "type": "Person", "subtype": null, "offset": 10966, "length": 8, "score": 0.9 }, { "text": "M. C. Lin", "type": "Person", "subtype": null, "offset": 10976, "length": 9, "score": 0.97 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 11580, "length": 11, "score": 0.8 }, { "text": "spring", "type": "DateTime", "subtype": "DateRange", "offset": 12146, "length": 6, "score": 0.8 }, { "text": "Young", "type": "Person", "subtype": null, "offset": 12311, "length": 5, "score": 0.87 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 12812, "length": 4, "score": 0.88 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 13158, "length": 4, "score": 0.95 }, { "text": "http://gamma.cs.unc.edu/", "type": "URL", "subtype": null, "offset": 13203, "length": 24, "score": 0.8 }, { "text": "2D", "type": "DateTime", "subtype": "Duration", "offset": 13669, "length": 2, "score": 0.8 }, { "text": "CNN", "type": "Organization", "subtype": null, "offset": 13796, "length": 3, "score": 0.87 }, { "text": "CNNs", "type": "Organization", "subtype": null, "offset": 15200, "length": 4, "score": 0.86 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 15266, "length": 4, "score": 0.8 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 15583, "length": 4, "score": 0.8 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 15597, "length": 4, "score": 0.84 }, { "text": "Author", "type": "Organization", "subtype": null, "offset": 15772, "length": 6, "score": 0.52 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 15782, "length": 4, "score": 0.8 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 16361, "length": 2, "score": 0.8 }, { "text": "Euler", "type": "Person", "subtype": null, "offset": 17752, "length": 5, "score": 0.59 }, { "text": "Liang", "type": "Person", "subtype": null, "offset": 18696, "length": 5, "score": 0.96 }, { "text": "https://gamma.umd.edu/", "type": "URL", "subtype": null, "offset": 18742, "length": 22, "score": 0.8 }, { "text": "J. Liang", "type": "Person", "subtype": null, "offset": 18824, "length": 8, "score": 0.98 }, { "text": "M. C. Lin", "type": "Person", "subtype": null, "offset": 18834, "length": 9, "score": 0.96 }, { "text": "thus 12", "type": "DateTime", "subtype": "Date", "offset": 20269, "length": 7, "score": 0.8 }, { "text": "Qiao", "type": "Person", "subtype": null, "offset": 21334, "length": 4, "score": 0.97 }, { "text": "Liang", "type": "Person", "subtype": null, "offset": 22299, "length": 5, "score": 0.97 }, { "text": "previously", "type": "DateTime", "subtype": null, "offset": 22746, "length": 10, "score": 0.8 }, { "text": "Huang", "type": "Person", "subtype": null, "offset": 23638, "length": 5, "score": 0.97 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 23677, "length": 2, "score": 0.8 }, { "text": "Wang", "type": "Person", "subtype": null, "offset": 23821, "length": 4, "score": 0.94 }, { "text": "CNN", "type": "Organization", "subtype": null, "offset": 24736, "length": 3, "score": 0.81 }, { "text": "daily", "type": "DateTime", "subtype": "Set", "offset": 25431, "length": 5, "score": 0.8 }, { "text": "Iribe", "type": "Organization", "subtype": null, "offset": 26571, "length": 5, "score": 0.87 }, { "text": "National Science Foundation", "type": "Organization", "subtype": null, "offset": 26599, "length": 27, "score": 0.95 }, { "text": "J. Liang", "type": "Person", "subtype": null, "offset": 26635, "length": 8, "score": 0.96 }, { "text": "M. C. Lin", "type": "Person", "subtype": null, "offset": 26645, "length": 9, "score": 0.97 }, { "text": "Zheng,", "type": "Person", "subtype": null, "offset": 26672, "length": 6, "score": 0.78 }, { "text": "Z. H.", "type": "Person", "subtype": null, "offset": 26679, "length": 5, "score": 0.79 }, { "text": "Zhang, H. T.", "type": "Person", "subtype": null, "offset": 26686, "length": 12, "score": 0.82 }, { "text": "Zhang, F. L.", "type": "Person", "subtype": null, "offset": 26700, "length": 12, "score": 0.82 }, { "text": "Mu, T. J.", "type": "Person", "subtype": null, "offset": 26714, "length": 9, "score": 0.78 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 26812, "length": 4, "score": 0.8 }, { "text": "Dibra, E.", "type": "Person", "subtype": null, "offset": 26823, "length": 9, "score": 0.79 }, { "text": "Jain, H.", "type": "Person", "subtype": null, "offset": 26834, "length": 8, "score": 0.83 }, { "text": "Öztireli, C.", "type": "Person", "subtype": null, "offset": 26844, "length": 12, "score": 0.84 }, { "text": "Ziegler, R.", "type": "Person", "subtype": null, "offset": 26858, "length": 11, "score": 0.83 }, { "text": "Gross", "type": "Person", "subtype": null, "offset": 26871, "length": 5, "score": 0.72 }, { "text": "M", "type": "Person", "subtype": null, "offset": 26878, "length": 1, "score": 0.74 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 27026, "length": 2, "score": 0.8 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 27046, "length": 4, "score": 0.8 }, { "text": "Bălan, A. O", "type": "Person", "subtype": null, "offset": 27057, "length": 11, "score": 0.85 }, { "text": "Black, M. J.", "type": "Person", "subtype": null, "offset": 27071, "length": 12, "score": 0.8 }, { "text": "ECCV", "type": "Organization", "subtype": null, "offset": 27161, "length": 4, "score": 0.62 }, { "text": "2008", "type": "DateTime", "subtype": "DateRange", "offset": 27166, "length": 4, "score": 0.8 }, { "text": "Forsyth, D.", "type": "Person", "subtype": null, "offset": 27218, "length": 11, "score": 0.84 }, { "text": "Torr, P.", "type": "Person", "subtype": null, "offset": 27231, "length": 8, "score": 0.75 }, { "text": "Zisserman", "type": "Person", "subtype": null, "offset": 27241, "length": 9, "score": 0.94 }, { "text": "A", "type": "Person", "subtype": null, "offset": 27252, "length": 1, "score": 0.6 }, { "text": "Springer", "type": "Organization", "subtype": null, "offset": 27260, "length": 8, "score": 0.76 }, { "text": "2008", "type": "DateTime", "subtype": "DateRange", "offset": 27284, "length": 4, "score": 0.8 }, { "text": "Lassner, C.", "type": "Person", "subtype": null, "offset": 27295, "length": 11, "score": 0.81 }, { "text": "Romero, J.", "type": "Person", "subtype": null, "offset": 27308, "length": 10, "score": 0.88 }, { "text": "Kiefel, M.", "type": "Person", "subtype": null, "offset": 27320, "length": 10, "score": 0.83 }, { "text": "Bogo, F.", "type": "Person", "subtype": null, "offset": 27332, "length": 8, "score": 0.76 }, { "text": "M. J", "type": "Person", "subtype": null, "offset": 27349, "length": 4, "score": 0.77 }, { "text": "Gehler, P. V", "type": "Person", "subtype": null, "offset": 27356, "length": 12, "score": 0.87 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 27540, "length": 4, "score": 0.8 }, { "text": "Loper, M.", "type": "Person", "subtype": null, "offset": 27551, "length": 9, "score": 0.76 }, { "text": "Mahmood, N.", "type": "Person", "subtype": null, "offset": 27562, "length": 11, "score": 0.8 }, { "text": "Romero, J.", "type": "Person", "subtype": null, "offset": 27575, "length": 10, "score": 0.88 }, { "text": "Pons-", "type": "Person", "subtype": null, "offset": 27587, "length": 5, "score": 0.66 }, { "text": "G.", "type": "Person", "subtype": null, "offset": 27598, "length": 2, "score": 0.6 }, { "text": "Black, M. J", "type": "Person", "subtype": null, "offset": 27602, "length": 11, "score": 0.8 }, { "text": "ACM", "type": "Organization", "subtype": null, "offset": 27658, "length": 3, "score": 0.71 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 27720, "length": 4, "score": 0.8 }, { "text": "Wei", "type": "Person", "subtype": null, "offset": 27731, "length": 3, "score": 0.9 }, { "text": "S.-E.", "type": "Person", "subtype": null, "offset": 27736, "length": 5, "score": 0.65 }, { "text": "Ramakrishna, V.", "type": "Person", "subtype": null, "offset": 27743, "length": 15, "score": 0.85 }, { "text": "Kanade, T.", "type": "Person", "subtype": null, "offset": 27760, "length": 10, "score": 0.75 }, { "text": "Sheikh, Y.", "type": "Person", "subtype": null, "offset": 27772, "length": 10, "score": 0.85 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 27835, "length": 4, "score": 0.85 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 27906, "length": 4, "score": 0.8 }, { "text": "Cao, Z.", "type": "Person", "subtype": null, "offset": 27917, "length": 7, "score": 0.79 }, { "text": "Simon, T.", "type": "Person", "subtype": null, "offset": 27926, "length": 9, "score": 0.69 }, { "text": "Wei, S.", "type": "Person", "subtype": null, "offset": 27937, "length": 7, "score": 0.78 }, { "text": "Sheikh, Y.", "type": "Person", "subtype": null, "offset": 27946, "length": 10, "score": 0.84 }, { "text": "2D", "type": "DateTime", "subtype": "Duration", "offset": 27980, "length": 2, "score": 0.8 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 28121, "length": 4, "score": 0.8 }, { "text": "Mehta, D.", "type": "Person", "subtype": null, "offset": 28132, "length": 9, "score": 0.79 }, { "text": "Sridhar, S.", "type": "Person", "subtype": null, "offset": 28143, "length": 11, "score": 0.76 }, { "text": "Sotnychenko, O.", "type": "Person", "subtype": null, "offset": 28156, "length": 15, "score": 0.85 }, { "text": "Rhodin, H.", "type": "Person", "subtype": null, "offset": 28173, "length": 10, "score": 0.8 }, { "text": "Shafiei, M.", "type": "Person", "subtype": null, "offset": 28185, "length": 11, "score": 0.86 }, { "text": "Seidel, H.-P.", "type": "Person", "subtype": null, "offset": 28198, "length": 13, "score": 0.76 }, { "text": "Xu, W.", "type": "Person", "subtype": null, "offset": 28213, "length": 6, "score": 0.85 }, { "text": "Casas, D.", "type": "Person", "subtype": null, "offset": 28221, "length": 9, "score": 0.64 }, { "text": "Theobalt", "type": "Person", "subtype": null, "offset": 28232, "length": 8, "score": 0.65 }, { "text": "C", "type": "Person", "subtype": null, "offset": 28242, "length": 1, "score": 0.63 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 28261, "length": 2, "score": 0.8 }, { "text": "ACM", "type": "Organization", "subtype": null, "offset": 28312, "length": 3, "score": 0.82 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 28373, "length": 4, "score": 0.8 }, { "text": "Alldieck, T.", "type": "Person", "subtype": null, "offset": 28384, "length": 12, "score": 0.86 }, { "text": "Magnor, M.", "type": "Person", "subtype": null, "offset": 28398, "length": 10, "score": 0.81 }, { "text": "Xu, W.", "type": "Person", "subtype": null, "offset": 28410, "length": 6, "score": 0.85 }, { "text": "Theobalt, C.", "type": "Person", "subtype": null, "offset": 28418, "length": 12, "score": 0.82 }, { "text": "Moll, G.", "type": "Person", "subtype": null, "offset": 28438, "length": 8, "score": 0.71 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 28477, "length": 2, "score": 0.8 }, { "text": "2018", "type": "DateTime", "subtype": "DateRange", "offset": 28589, "length": 4, "score": 0.8 }, { "text": "Kanazawa, A.", "type": "Person", "subtype": null, "offset": 28601, "length": 12, "score": 0.77 }, { "text": "Black, M. J.", "type": "Person", "subtype": null, "offset": 28615, "length": 12, "score": 0.8 }, { "text": "Jacobs, D. W.", "type": "Person", "subtype": null, "offset": 28629, "length": 13, "score": 0.81 }, { "text": "Malik, J.", "type": "Person", "subtype": null, "offset": 28644, "length": 9, "score": 0.86 }, { "text": "2018", "type": "DateTime", "subtype": "DateRange", "offset": 28793, "length": 4, "score": 0.8 }, { "text": "Varol, G.", "type": "Person", "subtype": null, "offset": 28805, "length": 9, "score": 0.82 }, { "text": "Ceylan, D.", "type": "Person", "subtype": null, "offset": 28816, "length": 10, "score": 0.76 }, { "text": "Russell, B.", "type": "Person", "subtype": null, "offset": 28828, "length": 11, "score": 0.71 }, { "text": "Yang, J.", "type": "Person", "subtype": null, "offset": 28841, "length": 8, "score": 0.84 }, { "text": "Yumer", "type": "Person", "subtype": null, "offset": 28851, "length": 5, "score": 0.84 }, { "text": "Laptev, I.", "type": "Person", "subtype": null, "offset": 28862, "length": 10, "score": 0.83 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 28906, "length": 2, "score": 0.8 }, { "text": "2018", "type": "DateTime", "subtype": "DateRange", "offset": 28998, "length": 4, "score": 0.8 }, { "text": "Zheng, Z.", "type": "Person", "subtype": null, "offset": 29010, "length": 9, "score": 0.81 }, { "text": "Yu, T.", "type": "Person", "subtype": null, "offset": 29021, "length": 6, "score": 0.73 }, { "text": "Wei, Y.", "type": "Person", "subtype": null, "offset": 29029, "length": 7, "score": 0.83 }, { "text": "Dai, Q.", "type": "Person", "subtype": null, "offset": 29038, "length": 7, "score": 0.68 }, { "text": "Liu, Y. Deephuman", "type": "Person", "subtype": null, "offset": 29047, "length": 17, "score": 0.79 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 29066, "length": 2, "score": 0.8 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 29135, "length": 4, "score": 0.5 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 29196, "length": 4, "score": 0.8 }, { "text": "Saito, S.", "type": "Person", "subtype": null, "offset": 29208, "length": 9, "score": 0.78 }, { "text": "Huang, Z.", "type": "Person", "subtype": null, "offset": 29219, "length": 9, "score": 0.77 }, { "text": "Natsume, R.", "type": "Person", "subtype": null, "offset": 29230, "length": 11, "score": 0.78 }, { "text": "Morishima, S.", "type": "Person", "subtype": null, "offset": 29243, "length": 13, "score": 0.77 }, { "text": "Kanazawa, A.", "type": "Person", "subtype": null, "offset": 29258, "length": 12, "score": 0.74 }, { "text": "Li, H. PIFu", "type": "Person", "subtype": null, "offset": 29272, "length": 11, "score": 0.7 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 29388, "length": 4, "score": 0.5 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 29449, "length": 4, "score": 0.8 }, { "text": "Xu, Y.", "type": "Person", "subtype": null, "offset": 29461, "length": 6, "score": 0.84 }, { "text": "Tung", "type": "Person", "subtype": null, "offset": 29481, "length": 4, "score": 0.93 }, { "text": "T. Denserac", "type": "Person", "subtype": null, "offset": 29487, "length": 11, "score": 0.78 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 29506, "length": 2, "score": 0.8 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 29587, "length": 4, "score": 0.5 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 29648, "length": 4, "score": 0.8 }, { "text": "Smith, D.", "type": "Person", "subtype": null, "offset": 29660, "length": 9, "score": 0.78 }, { "text": "Loper, M.", "type": "Person", "subtype": null, "offset": 29671, "length": 9, "score": 0.82 }, { "text": "Hu, X.", "type": "Person", "subtype": null, "offset": 29682, "length": 6, "score": 0.74 }, { "text": "Mavroidis, P.", "type": "Person", "subtype": null, "offset": 29690, "length": 13, "score": 0.73 }, { "text": "Romero", "type": "Person", "subtype": null, "offset": 29705, "length": 6, "score": 0.98 }, { "text": "J. FACSIMILE", "type": "Person", "subtype": null, "offset": 29713, "length": 12, "score": 0.89 }, { "text": "in less than a second", "type": "DateTime", "subtype": null, "offset": 29765, "length": 21, "score": 0.8 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 29811, "length": 4, "score": 0.83 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 29873, "length": 4, "score": 0.8 }, { "text": "Alldieck, T.", "type": "Person", "subtype": null, "offset": 29885, "length": 12, "score": 0.8 }, { "text": "Magnor, M.", "type": "Person", "subtype": null, "offset": 29899, "length": 10, "score": 0.81 }, { "text": "Bhatnagar, B. L.", "type": "Person", "subtype": null, "offset": 29911, "length": 16, "score": 0.72 }, { "text": "Theobalt", "type": "Person", "subtype": null, "offset": 29929, "length": 8, "score": 0.65 }, { "text": "Pons-Moll, G.", "type": "Person", "subtype": null, "offset": 29943, "length": 13, "score": 0.88 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 30120, "length": 4, "score": 0.8 }, { "text": "Kolotouros", "type": "Person", "subtype": null, "offset": 30132, "length": 10, "score": 0.95 }, { "text": "N.", "type": "Person", "subtype": null, "offset": 30144, "length": 2, "score": 0.6 }, { "text": "Pavlakos, G.", "type": "Person", "subtype": null, "offset": 30148, "length": 12, "score": 0.85 }, { "text": "Black, M. J.", "type": "Person", "subtype": null, "offset": 30162, "length": 12, "score": 0.8 }, { "text": "Daniilidis", "type": "Person", "subtype": null, "offset": 30176, "length": 10, "score": 0.94 }, { "text": "K", "type": "Person", "subtype": null, "offset": 30188, "length": 1, "score": 0.73 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 30215, "length": 2, "score": 0.8 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 30353, "length": 4, "score": 0.8 }, { "text": "Liang, J.", "type": "Person", "subtype": null, "offset": 30365, "length": 9, "score": 0.88 }, { "text": "Lin, M. C.", "type": "Person", "subtype": null, "offset": 30376, "length": 10, "score": 0.79 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 30483, "length": 4, "score": 0.5 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 30544, "length": 4, "score": 0.8 }, { "text": "Yang, S.", "type": "Person", "subtype": null, "offset": 30556, "length": 8, "score": 0.72 }, { "text": "Pan, Z. R.", "type": "Person", "subtype": null, "offset": 30566, "length": 10, "score": 0.72 }, { "text": "Amert, T.", "type": "Person", "subtype": null, "offset": 30578, "length": 9, "score": 0.76 }, { "text": "Wang, K.", "type": "Person", "subtype": null, "offset": 30589, "length": 8, "score": 0.78 }, { "text": "Yu, L.", "type": "Person", "subtype": null, "offset": 30599, "length": 6, "score": 0.72 }, { "text": "Berg, T.", "type": "Person", "subtype": null, "offset": 30610, "length": 8, "score": 0.66 }, { "text": "Lin, M. C", "type": "Person", "subtype": null, "offset": 30620, "length": 9, "score": 0.83 }, { "text": "ACM", "type": "Organization", "subtype": null, "offset": 30691, "length": 3, "score": 0.81 }, { "text": "2018", "type": "DateTime", "subtype": "DateRange", "offset": 30753, "length": 4, "score": 0.8 }, { "text": "Yang, S.", "type": "Person", "subtype": null, "offset": 30765, "length": 8, "score": 0.73 }, { "text": "Liang, J.", "type": "Person", "subtype": null, "offset": 30775, "length": 9, "score": 0.89 }, { "text": "Lin, M. C.", "type": "Person", "subtype": null, "offset": 30786, "length": 10, "score": 0.78 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 30933, "length": 4, "score": 0.8 }, { "text": "Qiao, Y. L.", "type": "Person", "subtype": null, "offset": 30945, "length": 11, "score": 0.85 }, { "text": "Liang, J. B.", "type": "Person", "subtype": null, "offset": 30958, "length": 12, "score": 0.86 }, { "text": "Koltun, V.", "type": "Person", "subtype": null, "offset": 30972, "length": 10, "score": 0.75 }, { "text": "Lin, M. C.", "type": "Person", "subtype": null, "offset": 30984, "length": 10, "score": 0.78 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 31086, "length": 4, "score": 0.8 }, { "text": "De Avila Belbute-Peres, F.", "type": "Person", "subtype": null, "offset": 31098, "length": 26, "score": 0.82 }, { "text": "Smith, K. A.", "type": "Person", "subtype": null, "offset": 31126, "length": 12, "score": 0.8 }, { "text": "Allen, K.", "type": "Person", "subtype": null, "offset": 31140, "length": 9, "score": 0.78 }, { "text": "Tenenbaum, J.", "type": "Person", "subtype": null, "offset": 31151, "length": 13, "score": 0.87 }, { "text": "Kolter, J. Z", "type": "Person", "subtype": null, "offset": 31166, "length": 12, "score": 0.84 }, { "text": "2018", "type": "DateTime", "subtype": "DateRange", "offset": 31314, "length": 4, "score": 0.8 }, { "text": "Degrave, J.", "type": "Person", "subtype": null, "offset": 31326, "length": 11, "score": 0.82 }, { "text": "Hermans, M.", "type": "Person", "subtype": null, "offset": 31339, "length": 11, "score": 0.79 }, { "text": "Dambre, J.", "type": "Person", "subtype": null, "offset": 31352, "length": 10, "score": 0.83 }, { "text": "Wyffels, F.", "type": "Person", "subtype": null, "offset": 31364, "length": 11, "score": 0.81 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 31478, "length": 4, "score": 0.8 }, { "text": "Liang, J.", "type": "Person", "subtype": null, "offset": 31490, "length": 9, "score": 0.87 }, { "text": "Lin, M.", "type": "Person", "subtype": null, "offset": 31501, "length": 7, "score": 0.78 }, { "text": "Koltun, V.", "type": "Person", "subtype": null, "offset": 31510, "length": 10, "score": 0.78 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 31656, "length": 4, "score": 0.8 }, { "text": "Hu, Y.", "type": "Person", "subtype": null, "offset": 31736, "length": 6, "score": 0.73 }, { "text": "Liu, J.", "type": "Person", "subtype": null, "offset": 31744, "length": 7, "score": 0.84 }, { "text": "Spielberg, A.", "type": "Person", "subtype": null, "offset": 31753, "length": 13, "score": 0.81 }, { "text": "Tenenbaum, J.", "type": "Person", "subtype": null, "offset": 31768, "length": 13, "score": 0.87 }, { "text": "Freeman, W. T.", "type": "Person", "subtype": null, "offset": 31786, "length": 14, "score": 0.83 }, { "text": "Wu, J.", "type": "Person", "subtype": null, "offset": 31802, "length": 6, "score": 0.81 }, { "text": "Rus, D.", "type": "Person", "subtype": null, "offset": 31810, "length": 7, "score": 0.66 }, { "text": "Matusik", "type": "Person", "subtype": null, "offset": 31819, "length": 7, "score": 0.79 }, { "text": "W. ChainQueen", "type": "Person", "subtype": null, "offset": 31828, "length": 13, "score": 0.9 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 31995, "length": 4, "score": 0.8 }, { "text": "Hu, Y. M.", "type": "Person", "subtype": null, "offset": 32007, "length": 9, "score": 0.73 }, { "text": "Anderson, L.", "type": "Person", "subtype": null, "offset": 32018, "length": 12, "score": 0.75 }, { "text": "Li, T. M.", "type": "Person", "subtype": null, "offset": 32032, "length": 9, "score": 0.71 }, { "text": "Sun, Q.", "type": "Person", "subtype": null, "offset": 32043, "length": 7, "score": 0.68 }, { "text": "Carr, N.", "type": "Person", "subtype": null, "offset": 32052, "length": 8, "score": 0.67 }, { "text": "Ragan-Kelley, J.", "type": "Person", "subtype": null, "offset": 32062, "length": 16, "score": 0.93 }, { "text": "Durand, F. DiffTaichi", "type": "Person", "subtype": null, "offset": 32080, "length": 21, "score": 0.81 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 32188, "length": 4, "score": 0.8 }, { "text": "Liu, K. X.", "type": "Person", "subtype": null, "offset": 32200, "length": 10, "score": 0.74 }, { "text": "Zeng, X. Y.", "type": "Person", "subtype": null, "offset": 32212, "length": 11, "score": 0.84 }, { "text": "Bruniaux, P.", "type": "Person", "subtype": null, "offset": 32225, "length": 12, "score": 0.83 }, { "text": "Tao, X. Y.", "type": "Person", "subtype": null, "offset": 32239, "length": 10, "score": 0.73 }, { "text": "Yao", "type": "Person", "subtype": null, "offset": 32251, "length": 3, "score": 0.86 }, { "text": "X", "type": "Person", "subtype": null, "offset": 32256, "length": 1, "score": 0.71 }, { "text": "Li, V.", "type": "Person", "subtype": null, "offset": 32263, "length": 6, "score": 0.68 }, { "text": "Wang, J.", "type": "Person", "subtype": null, "offset": 32271, "length": 8, "score": 0.76 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 32280, "length": 2, "score": 0.8 }, { "text": "2018", "type": "DateTime", "subtype": "DateRange", "offset": 32372, "length": 4, "score": 0.8 }, { "text": "Huang, P.", "type": "Person", "subtype": null, "offset": 32384, "length": 9, "score": 0.8 }, { "text": "Yao, J.", "type": "Person", "subtype": null, "offset": 32395, "length": 7, "score": 0.87 }, { "text": "Zhao, H.", "type": "Person", "subtype": null, "offset": 32404, "length": 8, "score": 0.74 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 32433, "length": 2, "score": 0.8 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 32571, "length": 4, "score": 0.8 }, { "text": "Wang, T. Y.", "type": "Person", "subtype": null, "offset": 32583, "length": 11, "score": 0.75 }, { "text": "Ceylan, D.", "type": "Person", "subtype": null, "offset": 32596, "length": 10, "score": 0.76 }, { "text": "Popović, J.", "type": "Person", "subtype": null, "offset": 32608, "length": 11, "score": 0.91 }, { "text": "Mitra, N. J", "type": "Person", "subtype": null, "offset": 32621, "length": 11, "score": 0.71 }, { "text": "ACM", "type": "Organization", "subtype": null, "offset": 32695, "length": 3, "score": 0.76 } ] }, { "@search.score": 1.7018158, "content": "\nRESEARCH Open Access\n\nA classification method for social\ninformation of sellers on social network\nHaoliang Cui1, Shuai Shao2* , Shaozhang Niu1, Chengjie Shi3 and Lingyu Zhou1\n\n* Correspondence: shaoshuaib@163.\ncom\n2China Information Technology\nSecurity Evaluation Center, Beijing\n100085, China\nFull list of author information is\navailable at the end of the article\n\nAbstract\n\nSocial e-commerce has been a hot topic in recent years, with the number of users\nincreasing year by year and the transaction money exploding. Unlike traditional e-\ncommerce, the main activities of social e-commerce are on social network apps. To\nclassify sellers by the merchandise, this article designs and implements a social\nnetwork seller classification scheme. We develop an app, which runs on the mobile\nphones of the sellers and provides the operating environment and automated\nassistance capabilities of social network applications. The app can collect social\ninformation published by the sellers during the assistance process, uploads to the\nserver to perform model training on the data. We collect 38,970 sellers’ information,\nextract the text information in the picture with the help of OCR, and establish a\ndeep learning model based on BERT to classify the merchandise of sellers. In the\nfinal experiment, we achieve an accuracy of more than 90%, which shows that the\nmodel can accurately classify sellers on a social network.\n\nKeywords: User model, Machine learning, Social e-commerce\n\n1 Introduction\nWith the continuous improvement of social network and mobile payment technology,\n\none kind of commodity trading based on social relations called social e-commerce is in\n\nrapid development. According to the 2019 China social e-commerce industry develop-\n\nment report released by the Internet society of China, the number of employees of so-\n\ncial e-commerce in China is expected to reach 48.01 million in 2019, up by 58.3\n\npercent year on year, and the market size is expected to reach 2060.58 billion yuan, up\n\nby 63.2% year on year. Social e-commerce has become a large scale, and the high\n\ngrowth cannot be ignored. Different from e-commerce platforms such as Taobao, so-\n\ncial e-commerce is at the end of online retail. It carries out trading activities through\n\nsocial software and uses social interaction, user generated content and other means to\n\nassist the purchase and sale of goods. At the same time, sellers on social network use\n\ndifferent social software without uniform registration, have no systematic classification\n\nof products for sale, and there are no standardized terms for product description.\n\nThese bring great difficulty to the accurate classification of user portrait. This paper\n\nproposes a method based on the NLP classification model, which can realize accurate\n\n© The Author(s). 2021 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the\noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or\nother third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit\nline to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a\ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n\nEURASIP Journal on Image\nand Video Processing\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 \nhttps://doi.org/10.1186/s13640-020-00545-z\n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s13640-020-00545-z&domain=pdf\nhttp://orcid.org/0000-0001-9638-0201\nmailto:shaoshuaib@163.com\nmailto:shaoshuaib@163.com\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nbusiness classification of social e-commerce based on social information of social e-\n\ncommerce. This method analyzes 38,970 sellers on social networks and establishes a\n\ndeep learning model based on BERT to accurately classify the merchandise of sellers.\n\nIn addition, we introduced the OCR algorithm to extract the text information in the\n\npicture and superimposed it on the social content data, which effectively improved the\n\nclassification accuracy. The final experiment shows that the measured accuracy is more\n\nthan 90%.\n\n2 Related work\n2.1 Natural language processing\n\nIn order to analyze e-commerce business classification based on social data of sellers on a\n\nsocial network, the text needs to be analyzed based on the NLP correlation algorithm.\n\nThe rapid development of NLP at the present stage is due to the neural network language\n\nmodel (NNLM) Bengio et al. [1] proposed in 2003. Researchers have been trying to realize\n\nthe end-to-end classification recognition by using a neural network as a classifier in the\n\ntext classification research based on word embedding. Kim first introduces the convolu-\n\ntional neural network (CNN) into the study of text classification. The network structure is\n\na dropout full connection layer and a softmax layer connected after one convolution layer\n\n[2]. Although this algorithm achieves good results in various benchmark tests, it cannot\n\nobtain long-distance text dependency due to the limitation of network structure. There-\n\nfore, Tencent AI Lab proposed DPCNN, which further enhanced the extraction capacity\n\nof long-distance text dependency by deepening CNN [3].\n\nSocial content data includes multimedia text data and picture data. With the help of\n\nOCR, we extract the text in the picture and convert the picture data into text data. Text\n\nis a kind of sequential data, and the classification of it by recurrent neural network\n\n(RNN) has been the focus of long-term research in academia [4]. As a variation of\n\nRNN, long short-term memory (LSTM) adds control units such as forgetting gate, in-\n\nput gate, and output gate on the original basis, which solves the problem of gradient\n\nexplosion and gradient disappearance in the long sequence training of RNN and pro-\n\nmotes the use of RNN [5]. By introducing the sharing information mechanism, Liu\n\net al. further improved the accuracy of the RNN algorithm in the text multi-\n\nclassification task and achieved good results in four benchmark text classifications [6].\n\nHowever, Word vectors cannot be constructed in Word embedding to solve the\n\nproblem of polysemy. Even though different semantic environments are considered\n\nduring training, the result of training is still one word corresponding to one row vector.\n\nConsidering the widespread phenomenon of polysemy, Peters et al. propose embed-\n\ndings from language model (ELMO) to address the impact of polysemy on natural lan-\n\nguage modeling [7]. ELMO uses a feature-based form of pre-training. First, two-way\n\nLSTM is used to pre-train the corpus, and then word embedding resulting from train-\n\ning is adjusted by double-layer two-way LSTM when processing downstream tasks to\n\nadd more grammatical and semantic information according to the context words.\n\nThe ability of ELMO to extract features is limited for choosing LSTM as the feature\n\nextractor instead of Transformer [8], and ELMO’s bidirectional splicing method is also\n\nweak in feature fusion. Therefore, Devlin et al. propose the BERT model, taking Trans-\n\nformer as a feature extractor to pre-train large-scale text corpus [9].\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 2 of 12\n\n\n\n2.2 User analysis of social networks\n\nUser analysis is an important part of social network analysis. Most existing studies use\n\nuser-generated content or social links between users to simulate users. Wu et al. mod-\n\neled users on the content curation social network (CCSN) in the unified framework by\n\nmining user-generated content and social links [10]. They proposed a potential Bayes-\n\nian model, multilevel LDA (MLLDA), that could represent users of potential interest\n\nfound in social links formed by text descriptions contributed by users and information\n\nsharing. In 2017, Wu et al. proposed a latent model [11], trying to explain how the so-\n\ncial network structure and users’ historical preferences change over time affect each\n\nuser’s future behavior and predict each user’s consumption preferences and social con-\n\nnections in the near future. Malli et al. proposed a new online social network user pro-\n\nfile rating model [12], which solved the problem of large and complicated user data. In\n\nterms of data analysis platform, Chen et al. [13] developed a big data platform for the\n\nstudy of the garlic industry chain. Garlic planting management, price control, and pre-\n\ndiction were realized through data collection, storage, and pretreatment. Ning et al.\n\n[14] designed a ga-bp hybrid algorithm based on the fuzzy theory and constructed an\n\nair quality evaluation model by combining the knowledge of BP neural network, genetic\n\nalgorithm, and fuzzy theory. Yin et al. [15] studied two methods of extracting supervis-\n\nory relations and applied them to the field of English news. One is the combination of\n\nsupport vector machine and principal component analysis, and the other is the combin-\n\nation of support vector machine and CNN, which can extract high-quality feature vec-\n\ntors from sentences of support vector machine. In the social apps, the data we obtain is\n\nmostly image data, so we introduced the OCR technology to identify text information\n\nin images.\n\n3 Data collection\nIn order to analyze the behavior patterns of social e-commerce, we developed an auxil-\n\niary tool for social e-commerce. In this tool, sellers on a social network are provided\n\nwith the independent running environment of social software and the automatic auxil-\n\niary ability, and the information acquisition module of the auxiliary process is used to\n\ncollect the social information published by sellers on a social network, which is\n\nuploaded to the background server for model training. We provided this tool to nearly\n\n10,000 sellers on a social network who participated in the experiment to obtain their\n\nsocial information in their e-commerce activities.\n\n3.1 Overall structure\n\nThe whole data collection scheme is mainly composed of two parts: intelligent space\n\napp and background server. The overall architecture is shown in Fig. 1. Intelligent\n\nspace app is deployed in the mobile phones of sellers on a social network and imple-\n\nmented based on the application layer of the Android platform, providing sellers on a\n\nsocial network with a secure container for the independent operation of social software.\n\nThe app contains the automatic assistant module, which provides the automatic assist-\n\nant capability of various business processes for seller, and collects the social informa-\n\ntion in the auxiliary process through the information grasping module. The collected\n\ninformation is cached and uploaded locally through the information collection service.\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 3 of 12\n\n\n\nThe background server is responsible for receiving the collected data uploaded by the\n\nintelligent space, preprocessing the data first, and then classifying the social e-\n\ncommerce through the data based on the machine learning classification model, and fi-\n\nnally storing the classification results.\n\n3.1.1 Security container\n\nThe security container is designed to allow social software to run independently with-\n\nout modifying the OS or gaining root privileges. The basic principle of its realization is\n\nto create an independent container process; load APK file of social software dynamic-\n\nally; monitor and intercept process communication interface such as Binder IPC\n\nthrough Libc hook, Java reflection, dynamic proxy, and other technical means; and col-\n\nlect social information through an automatic assistant module. The main part of the\n\ncontainer is composed of an application layer module and a service layer module.\n\nThe application layer module is responsible for the process startup and execution of\n\nsocial software, and its main functions include three parts.\n\n3.1.1.1 Interactive interception The application layer module intercepts the inter-\n\naction between the application process and the underlying system in the container and\n\nmodifies the calling logic. By hook or dynamic proxy of system library API and Binder\n\ncommunication interface, the application layer module blocks all interfaces that interact\n\nwith the system during the execution of social software and controls the process\n\nboundary of interaction between social applications and system services.\n\n3.1.1.2 Social information collection The loading of the automatic auxiliary module\n\nby social software is realized when initializing the process of social application.\n\nThe application layer module injects the corresponding plugins in the automatic\n\nassistant module into the social application process. The automatic assistance mod-\n\nule provides a number of e-commerce auxiliary functions for sellers on a social\n\nnetwork, including customer acquisition, social customer relationship management\n\nLinux Kernel\n\nBinder Mode\n\nIntelligent Space\n\nService Layer Mode\nAMS Proxy PMS Proxy\n\nApplication Layer Mode\nSocial App\n\nInteractive \ninterception\n\nautomatic \nassistance \nmodule\n\nInformation\nCollection \n\nBinder IPC\n\nBinder IPC\n\nBinder \nIPC Backgroud\n\n Server\n\nInternet\n\nFig. 1 The overall architecture diagram of the data acquisition scheme\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 4 of 12\n\n\n\n(SCRM), group management, sales assistance, and daily affairs. Sellers on social\n\nnetworks publish social information with commercial attributes through auxiliary\n\nfunctions, then the automatic auxiliary module will automatically collect the social\n\ninformation and send it to the information collection service for processing.\n\n3.1.1.3 Local processing of social information When the information collection ser-\n\nvice receives the social information collected by the automatic auxiliary module, the\n\ndata will be compressed and encrypted in the local cache. The service then uploads the\n\ncollected data to the background server periodically through the timer, and HTTPS is\n\nused to ensure data transmission security.\n\nThe main function of the service layer module is to take over the call logic modified\n\nby the application layer module by simulating the system service modify the parameters\n\nin the communication process and finally call the real system service. The service layer\n\nmodule exists in the container as an independent process. It focuses on the simulation\n\nof activity manager service (AMS) and package manager service (PMS) and realizes the\n\nsupport of system services in the process of launching and running social software.\n\n3.1.2 Background server\n\nThe background server mainly realizes the machine learning model processing of the\n\ncollected social data, including the functions of data preprocessing, data training, classi-\n\nfication, and result storage. The core processing logic will be described in chapter 5.\n\n3.2 Key processes\n\nThere are four key processes in the process of social information collection and pro-\n\ncessing. They are social software process initialization, social software process\n\nIntelligent \nSpace App \nlaunched\n\nProcess Boundaries\n\nUser Process\n\nSocial software process \ninitialization\n\nlaunching social \nsoftware\n\ninject automatic \nauxiliary\n\nSocial software process \nexecution\n\nRun the plug-in\n\nCollect social \ninformation\n\nProcess Boundaries\n\nUser Process\n\nLocal processing of \nsocial information\n\nBatch upload \nprocessed social \n\ninformation\n\nEncrypt, compress \nand store social \n\ninformation\n\nInternet\n\nInformation collecting \nservice process\n\nBackground processing \nof social information\n\nReceiving social \ninformation\n\nPreprocessing social \ninformation\n\nThe Server\n\nMachine learning \ncategorizes social \n\ninformation\n\nStore the \nclassification results\n\nFig. 2 Key flow chart of data acquisition scheme\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 5 of 12\n\n\n\nexecution, local processing of social information, and background processing of social\n\ninformation. The complete process is shown in Fig. 2.\n\n3.2.1 Social software process initialization\n\nWhen launching social software, the intelligent space will first intercept the callback\n\nfunction of the life cycle of all its components, then realize the process loading of the\n\nautomatic auxiliary module during the process initialization.\n\n3.2.2 Social software process execution\n\nThe process execution is completed by the application layer module and service layer\n\nmodule together. Sellers on a social network use automatic auxiliary modules to\n\ncomplete business activities, trigger information capture module to collect social infor-\n\nmation, and send it to the information collection service for subsequent processing.\n\n3.2.3 Local processing of social information\n\nThe local processing of social information is mainly completed by the information col-\n\nlection service. In order to ensure the safe storage and transmission of the collected so-\n\ncial information, the information collection service first adopts the encryption and\n\ncompression method to realize the local security cache and then adopts the HTTPS se-\n\ncure communication and transmission protocol to upload the data.\n\n3.2.4 Background processing of social information\n\nThe background processing of social information is completed by the background ser-\n\nver. The server first receives the social information uploaded by the intelligent space,\n\nnext decrypts and decompresses the social information, cleans the plaintext data, uses\n\nthird-party OCR technology to identify text information in images, and adds it to the\n\nuser’s social information after simple data processing. Then, the classification of sellers\n\non a social network is realized through the data based on machine learning modeling.\n\nFinally, the classification results are stored in the target database.\n\n4 Methods\nTo classify the business attributes of social e-commerce based on the information of\n\nsellers on a social network, traditional feature matching scheme and classification clus-\n\ntering scheme based on machine learning can be used to establish the model. In this\n\nchapter, we introduce the scheme based on term frequency-inverse document fre-\n\nquency (TF-IDF) clustering and the classification scheme based on BERT.\n\n4.1 Feature classification and TF-IDF clustering\n\n4.1.1 Feature classification\n\nWe randomly select 5000 sellers on a social network from the data collected by the\n\nbackground server and extracted the text data of their social information for analysis.\n\nEach social e-commerce user contains an average of 50 social text data. Based on the\n\ncontent, we manually classify social e-commerce into 11 categories. With the help of e-\n\ncommerce platforms like JD.COM, 50–100 keywords are sorted out for each category,\n\nand these keywords are screened and expanded according to the language habits of\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 6 of 12\n\n\n\nsellers on a social network. On this basis, we collect all the social information of each\n\nsocial network seller, cut and remove word segmentation, and match the results with\n\nthe keywords of the selected 11 categories. The number of keywords that are matched\n\nis counted as the matching degree. According to the situation of different classification,\n\nthe threshold of matching degree is determined by manual screening of some results,\n\nand then all social e-commerce is classified according to the threshold. After\n\noptimization and verification, the accuracy of the classical feature matching scheme fi-\n\nnally reached 40%. However, due to the simplicity of the rules of the feature matching\n\nscheme, the small optimization space, the high misjudgment rate of the scheme, and\n\nthe large human intervention in the basic word segmentation process, it is difficult to\n\ncover various situations of social e-commerce due to the limitation of these basic key-\n\nwords, thus making it insensitive to the dynamic changes of new hot words of social e-\n\ncommerce.\n\n4.1.2 TF-IDF clustering\n\nTo achieve the goal of accurate classification of social e-commerce, we designed a\n\nscheme based on TF-IDF clustering. Term frequency-inverse document frequency (TF-\n\nIDF) is a commonly used weighted technique for information retrieval and text mining\n\nto evaluate the importance of a single word to a document in a set of documents or a\n\ncorpus. In this scheme, the social information of each social e-commerce user is\n\nmapped as one file set of TF-IDF, and all texts of all sellers on a social network are\n\nmapped as the whole corpus. The words with the highest frequency used by each social\n\ne-commerce user are the most representative words in this document and become key-\n\nwords. Category labels can be generated to calculate the probability that a document\n\nbelongs to a certain category using the naive Bayes algorithm formula. The advantages\n\nof TF-IDF clustering to achieve the classification of sellers on the social network in-\n\nclude the following: (1) clear mapping; (2) emphasize the weight of keywords and lower\n\nthe weight of non-keywords; (3) compared with other machine learning algorithms, the\n\ncharacteristic dimension of the model is greatly reduced to avoid the dimension disas-\n\nter; and (4) while improving the efficiency of classification calculation, ensure that the\n\nclassification effect has a good accuracy and recall rate. The architecture of the entire\n\nsolution is shown in Fig. 3.\n\nIn the text preprocessing stage, the first thing to do is to format the social informa-\n\ntion, mainly including deleting the space, deleting the newline character, merging the\n\nsocial e-commerce text, and so on, and finally getting the text to be processed for word\n\nsegmentation. In this scheme, we choose Jieba’s simplified mode for word segmenta-\n\ntion, then filter out the noise by filtering the stop words (e.g., yes, ah, etc.).\n\nIn the stage of establishing the vector space model, the first step is to load the train-\n\ning set and take the pre-processed social information of each social e-commerce user\n\nas a document. The next step is to generate a dictionary, by adding every word that ap-\n\npears in the training set to it, using the complete dictionary to calculate the TF-IDF\n\nvalue of each document. In this scheme, CountVectorizer and TfidfTransformer in Py-\n\nthon’s Scikit-Learn library are used. CountVectorizer is used to convert words in the\n\ntext into word frequency matrix, TfidfTransformer is used to count the TF-IDF value\n\nof each word in each document, and the top20 words in each document are taken as\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 7 of 12\n\n\n\nkeywords of sellers on a social network. After this step, the keywords with a large TF-\n\nIDF value in each document are the most representative words in the document, which\n\nbecome the keyword set of the social e-commerce user. Finally, the naive Bayes method\n\nis used to generate the category label, and the document vectors belonging to the same\n\ncategory in the TF-IDF matrix are added to form a matrix of m*n, where m represents\n\nthe number of categories and n represents the number of documents. The weight of\n\neach word is divided by the total weight of all words of the class, to calculate the prob-\n\nability that a document belongs to a certain class.\n\nIn the model optimization stage, we optimize the whole scheme model by adjusting\n\nthe stop word set, adjusting parameters (including CountVectorizer, TfidfTransformer\n\nclass construction parameters), and adjusting the category label generation method.\n\nThe main idea of TFIDF is if a word or phrase appears in an article with a high fre-\n\nquency of TF, and rarely appears in other articles, it is considered that the word or\n\nphrase has a good classification ability and is suitable for classification. TFIDF is actu-\n\nally: TF * IDF, TF is term frequency and IDF is inverse document frequency.\n\nIn a given document, word frequency refers to the frequency of a given word in the\n\ndocument. This number is a normalization of the number of words to prevent it from\n\nbeing biased towards long documents. For the word ti in a particular document, its im-\n\nportance can be expressed as:\n\ntf i; j ¼\nj D j\n\nj j : ti∈d j\n� � j\n\namong them:\n\n|D|: The total number of files in the corpus\n\n∣{j : ti ∈ dj}∣: The number of documents containing the term ti (i.e., the number of\n\ndocuments in ni, j ≠ 0). If the term is not in the corpus, it will cause the dividend to be\n\nzero, so it is generally used 1 + ∣ {j : ti ∈ dj}∣.\n\nand then:\n\n Social e-\ncommerce data\n\nData preparation\n\nFormat processing\n\nFilter stop words\n\nText preprocessing\n\nGenerate directory\n\nBuild the vector space and \nTF-IDF\n\nGenerate category tags\n\nBayesian classifier\n\nText articiple\n\nLoad training set \n\nBuild tf matrix \n\nbuild vector\n\nbuild matrix \n\nConditional probability \nmatrix\n\nModel optimization\n\nFig. 3 TF-IDF scheme framework\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 8 of 12\n\n\n\ntfidf i; j ¼ tf i; j � idf i\n\nA high word frequency in a particular document and a low document frequency of\n\nthe word in the entire document collection can produce a high-weight TF-IDF. There-\n\nfore, TF-IDF tends to filter out common words and keep important words.\n\n4.2 Classification scheme based on BERT\n\n4.2.1 Data label\n\nWe manually classify and mark the data of sellers on a social network according to the\n\ncharacteristics of the products. Classified labels include 38,970 items and 17 categories\n\nof data, including 3c, dress, food, car, house, beauty, makeup, training, jewelry, promo-\n\ntion, medicine and health, phone charge recharge, finance, card category, cigarettes, es-\n\nsays, and others. The pre-processing phase removes emojis, numbers, and spaces from\n\nthe text through Unicode encoding.\n\n4.2.2 Classification scheme\n\nIn the BERT model, Transformer, as an encoder-decoder model based on attention\n\nmechanism, solves the problem that RNN cannot deal with long-distance dependence\n\nand the model cannot be parallel, improving the performance of the model without re-\n\nducing the accuracy. At the same time, BERT introduced the shading language model\n\n(MLM, masked language model) and context prediction method, further enhance the\n\ntwo-way training of the ability of feature extraction and text. MLM uses Transformer\n\nencoders and bilateral contexts to predict random masked tokens to pre-train two-way\n\ntransformers. This makes BERT different from the GPT model, which can only conduct\n\none-way training and can better extract context information through feature fusion.\n\nAnaphase prediction is more embodied in QA and NLI. Therefore, we choose the\n\nBERT model based on the bidirectional coding technology of pre-training and attention\n\nmechanism to classify sellers on a social network.\n\nWe chose the official Chinese pre-training model of Google as the pre-training model\n\nof the experiment: BERT-Base which is Chinese simplified and traditional, 12-layer,\n\n768-hidden, 12-head, 110M parameters [16]. This pre-training model is obtained by\n\nGoogle’s unsupervised pre-training on a large-scale Chinese corpus. On this basis, we\n\nwill carry out fine-tuning to realize the classification model of sellers on a social net-\n\nwork. When dividing the data set, we divided 38,970 pieces of data into training set\n\nand verification set according to the ratio of 6:4, that is, 23,382 pieces of training set\n\nand 15,588 pieces of verification set.\n\n5 Results and discussion\n5.1 TF-IDF clustering scheme\n\nThe computer used in the experiment is configured with AMD Ryzen R5-4600H CPU,\n\n16G memory, and windows10 64bit operating system. First, the default construction\n\nparameters are used, and the average accuracy of each classification is 45.7%. Next, the\n\nparameters are adjusted through a genetic algorithm, and 100 rounds of genetic algo-\n\nrithm optimization are performed, then the average accuracy reached the highest value\n\nof 52.5%. In the process of genetic algorithm, statistical estimation of algorithm time is\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 9 of 12\n\n\n\nalso carried out. On average, on this data set, the running time of each round of the\n\nTF-IDF model is about 28 s.\n\nExperiments show that the accuracy of the TF-IDF clustering scheme has been\n\nimproved after optimization, and it has a certain reference value for the classifica-\n\ntion of sellers on a social network, but there is still a big gap from the accurate\n\nclassification. We found three reasons after analyzing the experimental results. (1)\n\nCompared to the feature matching scheme, the TF-IDF-based model is improved\n\nto some extent. However, the input of the model is still the result of direct word\n\nsegmentation, and more information is lost in the word segmentation process, such\n\nas the semantic information of previous and later texts and the repetition fre-\n\nquency of corpus, which are relatively important in the process of natural language\n\nprocessing. (2) The classification problem of sellers on a social network is compli-\n\ncated. This model does not analyze the correlation between words and is essen-\n\ntially an upgraded version of word frequency statistics, which makes it difficult to\n\nimprove the accuracy after reaching a certain value. (3) For the optimization of the\n\nmodel, only the parameters of the intermediate function are adjusted, and the\n\nmethod is not upgraded. Therefore, the machine learning scheme based on TF-IDF\n\nclustering cannot solve the problem of accurate classification of sellers on a social\n\nnetwork. In the next chapter, we will introduce a scheme based on deep learning\n\nto achieve the goal of classifying sellers on a social network.\n\n5.2 Classification scheme based on BERT\n\nText classification fine-tuning is to serialize the preprocessed text information\n\ntoken and input BERT, and select the final hidden state of the first token [CLS] as\n\na sentence vector to output to the full connection layer, and then output the prob-\n\nability of obtaining various labels corresponding to the text through the softmax\n\nlayer. The experimental schematic diagram is shown in Figs. 4 and 5. The max-\n\nimum length of the sequence (ma_seq_length) is set to 256 according to the actual\n\ntext length of the social information data set of the sellers on a social network and\n\nFig. 4 Text message token serialization\n\nFig. 5 Text classification BERT fine-tuning model structure diagram\n\nCui et al. EURASIP Journal on Image and Video Processing (2021) 2021:4 Page 10 of 12\n\n\n\nthe batch_size and learning rate adopt the official recommended values of 32 and\n\n2e−5. In addition, we also adjust the super parameter num_train_epochs and in-\n\ncrease the number of training epochs (num_train_epochs) from 3 to 9 to improve\n\nthe recognition rate of the model (Table 1). The results are shown in Table 2.\n\nWe select an additional 9500 text data of sellers on social networks and test the\n\nmodel after the same preprocessing. The accuracy rate is 90.5%, which is lower than\n\nthat of the verification set (96.2%). The reason may be that the data of the test set con-\n\ntains a large number of commodity terms not included in the corpus and training set,\n\nand the text description of these commodities is too colloquial. Sellers on a social net-\n\nwork often use colloquial words in the industry to replace the standard product names\n\nwhen releasing product information, such as “Bobo” instead of “Botox,” which to some\n\nextent limits the accuracy of text-based classification in the social e-commerce market\n\nscene.\n\n6 Conclusion\nThe classification model proposes in this paper achieves an accuracy of 90.5% in the\n\ntest data. However, there are still some problems such as non-standard description text.\n\nA corpus with a high correlation with a social e-commerce environment will be estab-\n\nlished in order to further improve the accuracy of social e-commerce classification. At\n\nthe same time, we will use the knowledge distillation technology to compress and refine\n\nthe existing model, so as to improve the model recognition rate while simplifying the\n\nmodel and improving the operational performance [16]. In addition, in view of the high\n\nlabor cost and time cost of large-scale data marking, the next step will be trying to\n\nmake full use of semi-s", "metadata_storage_path": "aHR0cHM6Ly9rYm1zdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9wYXBlcnMvczEzNjQwLTAyMC0wMDU0NS16LnBkZg2", "metadata_author": "Haoliang Cui", "metadata_title": "A classification method for social information of sellers on social network", "metadata_creation_date": "2021-01-12T23:22:39Z", "people": [ "Haoliang Cui1,", "Shuai Shao2", "Shaozhang Niu1,", "Chengjie Shi3", "Lingyu Zhou1", "Bengio", "Kim", "Liu", "Peters", "Devlin", "Wu", "Bayes", "Malli", "Chen", "Ning", "Yin", "Binder", "Jieba", "thon" ], "organizations": [ "Security Evaluation Center", "BERT", "Taobao", "EURASIP Journal", "EURASIP", "Tencent AI Lab", "CNN", "RNN", "ELMO", "curation social network", "CCSN", "ule", "Intelligent Space", "AMS", "PMS", "Binder IPC", "SCRM", "activity manager service", "process", "JD", "JD.COM", "TF", "IDF", "TF-IDF", "Scikit-Learn", "TFIDF", "Unicode", "MLM", "Google" ], "locations": [ "Beijing", "China", "space", "house" ], "keyphrases": [ "2China Information Technology Security Evaluation Center", "Creative Commons Attribution 4.0 International License", "social network seller classification scheme", "other third party material", "2019 China social e-commerce industry", "mobile payment technology", "Creative Commons licence", "automated assistance capabilities", "social network apps", "social network applications", "original author(s", "RESEARCH Open Access", "different social software", "NLP classification model", "deep learning model", "Video Processing Cui", "social network use", "social information", "author information", "other means", "2021 Open Access", "systematic classification", "text information", "Haoliang Cui", "mobile phones", "assistance process", "Machine learning", "social relations", "social interaction", "The Author", "classification method", "accurate classification", "model training", "Shuai Shao2", "Shaozhang Niu", "Chengjie Shi3", "Lingyu Zhou1", "Full list", "hot topic", "recent years", "transaction money", "main activities", "operating environment", "final experiment", "continuous improvement", "one kind", "commodity trading", "rapid development", "ment report", "Internet society", "market size", "large scale", "high growth", "online retail", "trading activities", "same time", "uniform registration", "standardized terms", "product description", "great difficulty", "appropriate credit", "credit line", "intended use", "statutory regulation", "permitted use", "copyright holder", "EURASIP Journal", "User model", "38,970 sellers’ information", "user portrait", "doi.org", "orcid.org", "commerce platforms", "Correspondence", "shaoshuaib", "Beijing", "article", "Abstract", "number", "users", "traditional", "merchandise", "server", "data", "picture", "help", "OCR", "BERT", "accuracy", "Keywords", "1 Introduction", "employees", "percent", "billion", "Taobao", "content", "purchase", "sale", "goods", "products", "paper", "sharing", "adaptation", "distribution", "reproduction", "medium", "source", "link", "changes", "images", "permission", "creativecommons", "licenses", "crossmark", "dropout full connection layer", "four benchmark text classifications", "content curation social network", "neural network language model", "various benchmark tests", "Tencent AI Lab", "long short-term memory", "Most existing studies", "tional neural network", "recurrent neural network", "one convolution layer", "one row vector", "Natural language processing", "different semantic environments", "end classification recognition", "multi- classification task", "sharing information mechanism", "long-distance text dependency", "bidirectional splicing method", "social content data", "e-commerce business classification", "social network analysis", "multimedia text data", "long sequence training", "large-scale text corpus", "text classification research", "NLP correlation algorithm", "double-layer two-way LSTM", "softmax layer", "user-generated content", "social data", "network structure", "semantic information", "social networks", "long-term research", "Video Processing", "social links", "one word", "sequential data", "2.2 User analysis", "BERT model", "Related work", "present stage", "good results", "extraction capacity", "control units", "original basis", "widespread phenomenon", "guage modeling", "feature-based form", "train- ing", "downstream tasks", "context words", "feature extractor", "feature fusion", "important part", "unified framework", "picture data", "word embedding", "Word vectors", "classification accuracy", "OCR algorithm", "gradient disappearance", "output gate", "RNN algorithm", "38,970 sellers", "addition", "order", "NNLM", "Bengio", "Researchers", "classifier", "Kim", "CNN", "study", "limitation", "fore", "kind", "focus", "academia", "variation", "problem", "explosion", "Liu", "al.", "polysemy", "Peters", "dings", "ELMO", "impact", "grammatical", "ability", "features", "Transformer", "Devlin", "Cui", "Image", "Page", "Wu", "CCSN", "new online social network user", "air quality evaluation model", "machine learning classification model", "support vector machine", "mining user-generated content", "garlic industry chain", "Garlic planting management", "principal component analysis", "automatic assistant module", "various business processes", "independent running environment", "BP neural network", "ga-bp hybrid algorithm", "process communication interface", "file rating model", "social con- nections", "social informa- tion", "information acquisition module", "information grasping module", "cial network structure", "information collection service", "data analysis platform", "big data platform", "complicated user data", "data collection scheme", "independent container process", "users’ historical preferences", "Intelligent space app", "classification results", "ian model", "latent model", "Android platform", "independent operation", "consumption preferences", "genetic algorithm", "3 Data collection", "auxiliary process", "Overall structure", "APK file", "social apps", "social e-commerce", "social software", "information sharing", "secure container", "Security container", "multilevel LDA", "potential interest", "text descriptions", "future behavior", "near future", "price control", "fuzzy theory", "two methods", "ory relations", "English news", "combin- ation", "OCR technology", "behavior patterns", "iary ability", "background server", "two parts", "overall architecture", "application layer", "ant capability", "root privileges", "basic principle", "Binder IPC", "image data", "commerce activities", "iary tool", "MLLDA", "time", "Malli", "large", "terms", "Chen", "diction", "storage", "pretreatment", "knowledge", "Yin", "field", "combination", "tors", "sentences", "sellers", "experiment", "Fig.", "OS", "realization", "load", "ally", "intercept", "1.1", "interception automatic assistance module Information Collection Binder IPC Binder IPC Binder", "social customer relationship management Linux Kernel Binder Mode", "AMS Proxy PMS Proxy Application Layer Mode Social App Interactive", "Intelligent Space Service Layer Mode", "social information Process Boundaries User Process", "machine learning model processing", "Binder communication interface", "IPC Backgroud Server", "data acquisition scheme Cui", "social software process initialization", "Interactive interception", "application layer module", "Social software process execution", "Social information collection", "service layer module", "automatic auxiliary module", "Space App", "social application process", "other technical means", "overall architecture diagram", "activity manager service", "package manager service", "sales assistance", "data transmission security", "dynamic proxy", "system library API", "customer acquisition", "four key processes", "core processing logic", "group management", "communication process", "social applications", "social network", "3.2 Key processes", "process startup", "independent process", "system service", "calling logic", "Local processing", "call logic", "data preprocessing", "data training", "auxiliary functions", "Java reflection", "main part", "three parts", "inter- action", "underlying system", "corresponding plugins", "daily affairs", "commercial attributes", "local cache", "main function", "result storage", "Batch upload", "Libc hook", "container", "interfaces", "boundary", "interaction", "loading", "Internet", "SCRM", "timer", "HTTPS", "parameters", "real", "simulation", "support", "fication", "chapter", "Encrypt", "1.2", "Machine learning categorizes social information", "traditional feature matching scheme", "3.2.1 Social software process initialization", "machine learning modeling", "Key flow chart", "automatic auxiliary modules", "third-party OCR technology", "local security cache", "complete business activities", "information capture module", "social information Preprocessing", "social network seller", "simple data processing", "50 social text data", "social e-commerce user", "service process", "complete process", "service layer", "matching degree", "tering scheme", "process loading", "4.1 Feature classification", "4.1.1 Feature classification", "business attributes", "classification scheme", "local processing", "plaintext data", "Background processing", "subsequent processing", "intelligent space", "callback function", "life cycle", "safe storage", "compression method", "cure communication", "target database", "TF-IDF) clustering", "TF-IDF clustering", "JD.COM", "language habits", "word segmentation", "manual screening", "classification clus", "different classification", "The Server", "transmission protocol", "components", "Sellers", "encryption", "next", "4 Methods", "quency", "analysis", "average", "11 categories", "50–100 keywords", "category", "basis", "situation", "threshold", "3.2.2", "other machine learning algorithms", "naive Bayes algorithm formula", "classical feature matching scheme", "basic word segmentation process", "Term frequency-inverse document frequency", "naive Bayes method", "large human intervention", "high misjudgment rate", "basic key- words", "word segmenta- tion", "one file set", "new hot words", "small optimization space", "vector space model", "text preprocessing stage", "word frequency matrix", "model optimization stage", "social e-commerce text", "highest frequency", "recall rate", "single word", "various situations", "dynamic changes", "weighted technique", "information retrieval", "text mining", "clear mapping", "characteristic dimension", "entire solution", "first thing", "newline character", "simplified mode", "Scikit-Learn library", "keyword set", "m*n", "scheme model", "representative words", "stop words", "top20 words", "Category labels", "classification calculation", "classification effect", "same category", "4.1.2 TF-IDF clustering", "TF-IDF matrix", "first step", "next step", "good accuracy", "complete dictionary", "TF-IDF value", "document vectors", "total weight", "verification", "simplicity", "rules", "goal", "importance", "documents", "corpus", "texts", "probability", "advantages", "keywords", "lower", "efficiency", "architecture", "Jieba", "noise", "pears", "training", "CountVectorizer", "TfidfTransformer", "thon", "categories", "Conditional probability matrix Model optimization", "category label generation method", "3 TF-IDF scheme framework Cui", "official Chinese pre-training model", "phone charge recharge", "random masked tokens", "bidirectional coding technology", "vector build matrix", "context prediction method", "shading language model", "masked language model", "large-scale Chinese corpus", "entire document collection", "class construction parameters", "inverse document frequency", "low document frequency", "Load training set", "good classification ability", "high word frequency", "category tags", "4.2 Classification scheme", "card category", "4.2.2 Classification scheme", "Data label", "tf matrix", "vector space", "context information", "Anaphase prediction", "encoder-decoder model", "GPT model", "classification model", "particular document", "main idea", "other articles", "Format processing", "Bayesian classifier", "high-weight TF-IDF", "Classified labels", "promo- tion", "pre-processing phase", "Unicode encoding", "attention mechanism", "long-distance dependence", "feature extraction", "bilateral contexts", "two-way transformers", "traditional, 12-layer", "110M parameters", "data set", "two-way training", "one-way training", "term frequency", "commerce data", "Data preparation", "stop word", "Text preprocessing", "Text articiple", "common words", "important words", "long documents", "j � idf", "total number", "phrase", "normalization", "portance", "D|", "files", "dj", "dividend", "Filter", "directory", "characteristics", "38,970 items", "17 categories", "3c", "dress", "food", "house", "beauty", "makeup", "jewelry", "medicine", "health", "finance", "cigarettes", "others", "emojis", "numbers", "spaces", "RNN", "performance", "MLM", "encoders", "QA", "NLI", "Google", "BERT-Base", "hidden", "fine-tuning", "38,970 pieces", "4.2.1", "Text classification BERT fine-tuning model structure diagram Cui", "AMD Ryzen R5-4600H CPU", "windows10 64bit operating system", "Text message token serialization", "discussion 5.1 TF-IDF clustering scheme", "Text classification fine-tuning", "experimental schematic diagram", "direct word segmentation", "word frequency statistics", "final hidden state", "official recommended values", "feature matching scheme", "text information token", "full connection layer", "additional 9500 text data", "natural language processing", "machine learning scheme", "word segmentation process", "social information data", "5.2 Classification scheme", "text length", "text description", "input BERT", "first token", "TF-IDF model", "classification problem", "deep learning", "learning rate", "TF-IDF-based model", "training set", "16G memory", "default construction", "genetic algo", "statistical estimation", "classifica- tion", "big gap", "three reasons", "later texts", "upgraded version", "intermediate function", "next chapter", "sentence vector", "various labels", "imum length", "super parameter", "training epochs", "recognition rate", "same preprocessing", "test set", "commodity terms", "experimental results", "verification set", "highest value", "reference value", "average accuracy", "accuracy rate", "running time", "large number", "rithm optimization", "algorithm", "5 Results", "ratio", "23,382 pieces", "15,588 pieces", "computer", "100 rounds", "28 s", "Experiments", "extent", "previous", "correlation", "words", "method", "preprocessed", "Figs.", "sequence", "actual", "batch_size", "train_epochs", "Table", "commodities", "social e-commerce market", "standard description text", "social e-commerce environment", "knowledge distillation technology", "standard product names", "large-scale data marking", "social e-commerce classification", "model recognition rate", "product information", "test data", "text-based classification", "colloquial words", "existing model", "operational performance", "labor cost", "time cost", "full use", "high correlation", "work", "industry", "Bobo", "Botox", "scene", "6 Conclusion", "problems", "view", "semi" ], "pii_entities": [ { "text": "Haoliang Cui", "type": "Person", "subtype": null, "offset": 99, "length": 12, "score": 0.89 }, { "text": "Shuai Shao2", "type": "Person", "subtype": null, "offset": 114, "length": 11, "score": 0.94 }, { "text": "Shaozhang Niu", "type": "Person", "subtype": null, "offset": 129, "length": 13, "score": 0.93 }, { "text": "Chengjie Shi3", "type": "Person", "subtype": null, "offset": 145, "length": 13, "score": 0.93 }, { "text": "Lingyu Zhou1", "type": "Person", "subtype": null, "offset": 163, "length": 12, "score": 0.87 }, { "text": "2China Information Technology", "type": "Organization", "subtype": null, "offset": 215, "length": 29, "score": 0.55 }, { "text": "Security Evaluation Center", "type": "Organization", "subtype": null, "offset": 245, "length": 26, "score": 0.76 }, { "text": "100085", "type": "DateTime", "subtype": "Date", "offset": 281, "length": 6, "score": 0.8 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 974, "length": 7, "score": 0.78 }, { "text": "server", "type": "PersonType", "subtype": null, "offset": 1028, "length": 6, "score": 0.51 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 1092, "length": 7, "score": 0.8 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 1261, "length": 7, "score": 0.85 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 1387, "length": 7, "score": 0.94 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 1697, "length": 4, "score": 0.8 }, { "text": "2019", "type": "DateTime", "subtype": "DateRange", "offset": 1895, "length": 4, "score": 0.8 }, { "text": "Taobao", "type": "Organization", "subtype": null, "offset": 2153, "length": 6, "score": 0.76 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 2671, "length": 4, "score": 0.54 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 2800, "length": 4, "score": 0.8 }, { "text": "author", "type": "PersonType", "subtype": null, "offset": 3056, "length": 6, "score": 0.92 }, { "text": "copyright holder", "type": "PersonType", "subtype": null, "offset": 3555, "length": 16, "score": 0.65 }, { "text": "http://creativecommons.org/licenses/by/4.0/.", "type": "URL", "subtype": null, "offset": 3611, "length": 44, "score": 0.8 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 3657, "length": 7, "score": 0.72 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 3704, "length": 3, "score": 0.95 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 3715, "length": 7, "score": 0.54 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 3771, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 3779, "length": 4, "score": 0.8 }, { "text": "https://doi.org/10.1186/s13640-020-00545-z", "type": "URL", "subtype": null, "offset": 3785, "length": 42, "score": 0.8 }, { "text": "http://crossmark.crossref.org/dialog/?doi=10.1186/s13640-020-00545-z&domain=pdf", "type": "URL", "subtype": null, "offset": 3829, "length": 79, "score": 0.8 }, { "text": "http://orcid.org/0000-0001-9638-0201", "type": "URL", "subtype": null, "offset": 3909, "length": 36, "score": 0.8 }, { "text": "shaoshuaib@163.com", "type": "Email", "subtype": null, "offset": 3953, "length": 18, "score": 0.8 }, { "text": "shaoshuaib@163.com", "type": "Email", "subtype": null, "offset": 3979, "length": 18, "score": 0.8 }, { "text": "http://creativecommons.org/licenses/by/4.0/", "type": "URL", "subtype": null, "offset": 3998, "length": 43, "score": 0.8 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 4169, "length": 7, "score": 0.64 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 4291, "length": 7, "score": 0.77 }, { "text": "Bengio", "type": "Person", "subtype": null, "offset": 4903, "length": 6, "score": 0.93 }, { "text": "2003", "type": "DateTime", "subtype": "DateRange", "offset": 4933, "length": 4, "score": 0.8 }, { "text": "Kim", "type": "Person", "subtype": null, "offset": 5126, "length": 3, "score": 0.98 }, { "text": "Tencent AI Lab", "type": "Organization", "subtype": null, "offset": 5530, "length": 14, "score": 0.94 }, { "text": "CNN", "type": "Organization", "subtype": null, "offset": 5655, "length": 3, "score": 0.95 }, { "text": "RNN", "type": "Organization", "subtype": null, "offset": 5931, "length": 3, "score": 0.69 }, { "text": "Liu", "type": "Person", "subtype": null, "offset": 6344, "length": 3, "score": 0.97 }, { "text": "Peters", "type": "Person", "subtype": null, "offset": 6818, "length": 6, "score": 0.96 }, { "text": "ELMO", "type": "Organization", "subtype": null, "offset": 6952, "length": 4, "score": 0.77 }, { "text": "ELMO", "type": "Organization", "subtype": null, "offset": 7389, "length": 4, "score": 0.65 }, { "text": "Devlin", "type": "Person", "subtype": null, "offset": 7470, "length": 6, "score": 0.97 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 7596, "length": 3, "score": 0.96 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 7607, "length": 7, "score": 0.58 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 7663, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 7671, "length": 4, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 7867, "length": 5, "score": 0.91 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 7885, "length": 5, "score": 0.9 }, { "text": "Wu", "type": "Person", "subtype": null, "offset": 7892, "length": 2, "score": 0.96 }, { "text": "Bayes", "type": "Person", "subtype": null, "offset": 8073, "length": 5, "score": 0.81 }, { "text": "2017", "type": "DateTime", "subtype": "DateRange", "offset": 8266, "length": 4, "score": 0.8 }, { "text": "Wu", "type": "Person", "subtype": null, "offset": 8272, "length": 2, "score": 0.96 }, { "text": "Malli", "type": "Person", "subtype": null, "offset": 8547, "length": 5, "score": 0.95 }, { "text": "Chen", "type": "Person", "subtype": null, "offset": 8730, "length": 4, "score": 0.96 }, { "text": "Ning", "type": "Person", "subtype": null, "offset": 8949, "length": 4, "score": 0.96 }, { "text": "Yin", "type": "Person", "subtype": null, "offset": 9163, "length": 3, "score": 0.97 }, { "text": "seller", "type": "PersonType", "subtype": null, "offset": 10944, "length": 6, "score": 0.51 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 11160, "length": 3, "score": 0.97 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 11171, "length": 7, "score": 0.58 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 11227, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 11235, "length": 4, "score": 0.8 }, { "text": "3.1.1.1", "type": "IPAddress", "subtype": null, "offset": 12334, "length": 7, "score": 0.8 }, { "text": "3.1.1.2", "type": "IPAddress", "subtype": null, "offset": 12840, "length": 7, "score": 0.8 }, { "text": "Binder Mode", "type": "Organization", "subtype": null, "offset": 13353, "length": 11, "score": 0.59 }, { "text": "Binder", "type": "Person", "subtype": null, "offset": 13568, "length": 6, "score": 0.74 }, { "text": "IPC Backgroud", "type": "Organization", "subtype": null, "offset": 13576, "length": 13, "score": 0.6 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 13682, "length": 3, "score": 0.96 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 13693, "length": 7, "score": 0.58 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 13749, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 13757, "length": 4, "score": 0.8 }, { "text": "daily", "type": "DateTime", "subtype": "Set", "offset": 13826, "length": 5, "score": 0.8 }, { "text": "Sellers", "type": "Person", "subtype": null, "offset": 13841, "length": 7, "score": 0.51 }, { "text": "3.1.1.3", "type": "IPAddress", "subtype": null, "offset": 14107, "length": 7, "score": 0.8 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 16234, "length": 3, "score": 0.97 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 16245, "length": 7, "score": 0.55 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 16301, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 16309, "length": 4, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 18012, "length": 4, "score": 0.87 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 18964, "length": 4, "score": 0.6 }, { "text": "JD", "type": "Organization", "subtype": null, "offset": 19140, "length": 2, "score": 0.52 }, { "text": "JD.COM", "type": "Organization", "subtype": null, "offset": 19140, "length": 6, "score": 0.9 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 19281, "length": 3, "score": 0.96 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 19292, "length": 7, "score": 0.64 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 19348, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 19356, "length": 4, "score": 0.8 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 19377, "length": 7, "score": 0.85 }, { "text": "Bayes", "type": "Person", "subtype": null, "offset": 21270, "length": 5, "score": 0.88 }, { "text": "Jieba", "type": "Person", "subtype": null, "offset": 22182, "length": 5, "score": 0.83 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 23003, "length": 3, "score": 0.95 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 23014, "length": 7, "score": 0.55 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 23070, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 23078, "length": 4, "score": 0.8 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 23111, "length": 7, "score": 0.92 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 23321, "length": 4, "score": 0.73 }, { "text": "Bayes", "type": "Person", "subtype": null, "offset": 23346, "length": 5, "score": 0.95 }, { "text": "TFIDF", "type": "Organization", "subtype": null, "offset": 24263, "length": 5, "score": 0.84 }, { "text": "TF-IDF", "type": "Organization", "subtype": null, "offset": 25132, "length": 6, "score": 0.65 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 25353, "length": 3, "score": 0.96 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 25364, "length": 7, "score": 0.65 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 25420, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 25428, "length": 4, "score": 0.8 }, { "text": "BERT", "type": "Organization", "subtype": null, "offset": 26574, "length": 4, "score": 0.89 }, { "text": "MLM", "type": "Organization", "subtype": "Medical", "offset": 26763, "length": 3, "score": 0.68 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 27227, "length": 7, "score": 0.94 }, { "text": "Google", "type": "Organization", "subtype": null, "offset": 27309, "length": 6, "score": 0.95 }, { "text": "110M", "type": "DateTime", "subtype": "Duration", "offset": 27449, "length": 4, "score": 0.8 }, { "text": "Google", "type": "Organization", "subtype": null, "offset": 27511, "length": 6, "score": 0.95 }, { "text": "6:4", "type": "DateTime", "subtype": "Time", "offset": 27823, "length": 3, "score": 0.8 }, { "text": "4600H", "type": "DateTime", "subtype": "Duration", "offset": 28031, "length": 5, "score": 0.8 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 28481, "length": 3, "score": 0.96 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 28492, "length": 7, "score": 0.61 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 28548, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 28556, "length": 4, "score": 0.8 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 29484, "length": 7, "score": 0.77 }, { "text": "sellers", "type": "PersonType", "subtype": null, "offset": 30138, "length": 7, "score": 0.96 }, { "text": "Cui", "type": "Person", "subtype": null, "offset": 30904, "length": 3, "score": 0.94 }, { "text": "EURASIP", "type": "Organization", "subtype": null, "offset": 30915, "length": 7, "score": 0.69 }, { "text": "2021", "type": "DateTime", "subtype": "DateRange", "offset": 30971, "length": 4, "score": 0.8 }, { "text": "21:4", "type": "DateTime", "subtype": "Time", "offset": 30979, "length": 4, "score": 0.8 }, { "text": "Sellers", "type": "Person", "subtype": null, "offset": 31734, "length": 7, "score": 0.57 } ] }, { "@search.score": 1.4310136, "content": "\nSentiment analysis and the complex \nnatural language\nMuhammad Taimoor Khan1*, Mehr Durrani2, Armughan Ali2, Irum Inayat3, Shehzad Khalid1 and Kamran \nHabib Khan4\n\nIntroduction\nSentiment analysis (Pang and Lillian 2008) is a type of text classification that deals with \nsubjective statements. It is also known as opinion mining, since it processes opinions in \norder to learn about public perception. Sentiment analysis and opinion mining are the \nsame, and are used interchangeably throughout the document. It uses natural language \nprocessing (NLP) to collect and examine opinion or sentiment words. SA is explained \nas identifying the sentiments of people about a topic and its features (Pang and Lillian \n2008). The reason for the popularity of opinion mining is because people prefer to take \nadvice from others in order to invest sensibly. Determining subjective attitudes in big \nsocial data is a hotspot in the field of data mining and NLP (Hai et al. 2014).\n\nAbstract \n\nThere is huge amount of content produced online by amateur authors, covering a \nlarge variety of topics. Sentiment analysis (SA) extracts and aggregates users’ senti-\nments towards a target entity. Machine learning (ML) techniques are frequently used \nas the natural language data is in abundance and has definite patterns. ML techniques \nadapt to domain specific solution at high accuracy depending upon the feature set \nused. The lexicon-based techniques, using external dictionary, are independent of data \nto prevent overfitting but they miss context too in specialized domains. Corpus-based \nstatistical techniques require large data to stabilize. Complex network based tech-\nniques are highly resourceful, preserving order, proximity, context and relationships. \nRecent applications developed incorporate the platform specific structural information \ni.e. meta-data. New sub-domains are introduced as influence analysis, bias analysis, and \ndata leakage analysis. The nature of data is also evolving where transcribed customer-\nagent phone conversation are also used for sentiment analysis. This paper reviews \nsentiment analysis techniques and highlight the need to address natural language \nprocessing (NLP) specific open challenges. Without resolving the complex NLP chal-\nlenges, ML techniques cannot make considerable advancements. The open issues and \nchallenges in the area are discussed, stressing on the need of standard datasets and \nevaluation methodology. It also emphasized on the need of better language models \nthat could capture context and proximity.\n\nKeywords: Sentiment analysis, Machine learning, Sentiment orientation, Complex \nnetworks\n\nOpen Access\n\n© 2016 Khan et al. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://\ncreativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided \nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate \nif changes were made.\n\nREVIEW\n\nKhan et al. Complex Adapt Syst Model (2016) 4:2 \nDOI 10.1186/s40294-016-0016-9\n\n*Correspondence: \ntaimoor.muhammad@gmail.\ncom \n1 Bahria University, Shangrilla \nRoad, Sector E-8, Islamabad, \nPakistan\nFull list of author information \nis available at the end of the \narticle\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40294-016-0016-9&domain=pdf\n\n\nPage 2 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\nManufacturers are also interested to know which features of their products are more \npopular in public, in order to make profitable business decisions. There is a huge reposi-\ntory of opinion content available at various online sources in the form of blogs, forums, \nsocial media, review websites etc. They are growing, with more opinionated content \npoured in continuously. It is, therefore, beyond the control of manual techniques to \nanalyze millions of reviews and to aggregate them towards a rapid and efficient deci-\nsion. Sentiment analysis techniques perform this task through automated processes with \nminimal or no user support. The online datasets may also contain objective statements, \nwhich do not contribute effectively in sentiment analysis. Such statements are filtered at \npre-processing.\n\nOpinion mining deals with identifying opinion patterns and presenting them in a \nway that is easy to understand. The outcome of sentiment analysis can be in the form \nof binary classification, such as categorizing opinions as recommended or not recom-\nmended. It can be considered as a multi-class classification problem on a given scale of \nlikeness. Cambria et al. (2013) used common-sense knowledge to improve the results of \nsentiment analysis. The results can be presented in the form of a short summary gen-\nerated from the overall analysis. Sentiment analysis has various sub streams including \nemotion analysis, trend analysis, and bias analysis etc. Its applications has outgrown \nfrom business to social, political and geographical domains. Sentiment analysis is \napplied to emails for gender identification through emotion analysis (Mohammad and \nYang 2011). Emotion is applied to fairy tales to draw interesting patterns (Mohammad \n2011). Considering text a complex network of words that are associated to each other \nwith sentiments, graph based analysis techniques are used for NLP tasks.\n\nNatural language processing\n\nOpinion mining requires NLP, to extract semantics of opinion words and sentences. \nHowever, NLP has open challenges that are too complex to be handled accurately till \ndate. Since sentiment analysis makes extensive use of NLP, it has this complex behav-\nior reflected. The assumptions in NLP for text categorization do not work with opinion \nmining, as they are different in nature. Documents having high frequency of matching \nwords may not necessarily possess same sentiment polarity. It is because, a fact in text \ncategorization could be either correct or incorrect, and is well known to all. Unlike facts, \na variety of opinions can be correct about the same product, due to its subjective nature. \nAnother difference is that, opinion mining is sensitive to individual words, where a sin-\ngle word like NOT may change the whole context. The open challenges are negations \nwithout using NOT word, sarcastic and comparative sentences etc. The later section has \na detailed discussion on NLP issues that affect sentiment analysis.\n\nThe subjective content from the online sources have simple, compound or complex \nsentences. Simple sentences possess single opinion about a product, while compound \nsentences have multiple opinions expressed together. Complex sentences have implicit \nmeaning and are hard to evaluate. Regular opinions pertain to a single entity only, while \ncomparative opinions have an object or some of its aspects discussed in comparison to \nanother object. Comparative opinions can either be objective or subjective. An example \nof a subjective sentence having comparison is “The sound effects of game X are much \nbetter than that of game Y” whereas an example of objective sentence with comparison is \n\n\n\nPage 3 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\n“Game X has twice as many control options as that of Game Y”. Opinion mining expects \na variety of sentence types, since people follow different writing styles in order to express \nthemselves in a better way.\n\nSentiment analysis\n\nThe machine learning (ML) based techniques are supervised, semi supervised or unsu-\npervised. The supervised techniques require labeled data, while the semi supervised \ntechniques need manual tuning from domain experts. The unsupervised techniques \nmake use of statistical analysis on large volume of data. ML techniques has a large fea-\nture set using Bag-of-words (BOW). Results are improved by pruning repetitive and \nlow quality features. The opinion words are extracted to identify the polarity of opinion \nexpressed for a feature. The performance of a classifier is measured through its effective-\nness at the cost of efficiency. Effectiveness is calculated as precision/recall and F-meas-\nure, which are measurements of relevance.\n\nSentiment analysis can also be considered as a complex network. It consists of nodes \nand edges joining them. Many complex systems from a variety of domains are repre-\nsented as network including environmental modeling (Niazi et al. 2010), business sys-\ntems (Aoyama 2002), wireless sensors, and ad-hoc networks (Niazi and Hussain 2009). \nNetworks are rich in information, having a range of local and global properties. Text cor-\npora can be used with words as nodes and edges representing the structural or seman-\ntic association between them. The adjacent nodes sharing a link are closely associated \nand directly affect each other through the weight of the link they share. Representing \ntext as complex network, various properties like centrality, degree distribution, com-\nponents, communities, paths etc. can be used to explore the data thoroughly. Through \nmulti-partite graphs, nodes can be distributed among various clusters with inter-cluster \nedges only. It separates different types of entities discussed in comparison. Entities are \nlinked to their respective aspects/features and then to the sentiments associated. The \nsentiments can be linked with the reasons shared in support of those sentiments.\n\nData sources\n\nOpinion mining has diverse subjective data sources that are available online. They cover \na large number of topics and are up-to-date with current issues. Introduction of Web2.0 \nin the last decade has enabled people to post their thoughts and opinions on a range of \ntopics. The data produced online is growing all the time produced by people from differ-\nent backgrounds (Katz et al. 2015). Opinion mining makes use of this data generated by \nmillions of users all over the world. According to Business Week survey in 2009, 70 % of \nthe people consult online reviews and ratings to make a purchase. Comscore/The Kelsey \ngroup in 2007 reported that 97 % of the people who made purchases based on online \nreviews, found them to be honest.\n\nThe user generated subjective content is of value to be assessed and summarized for \nprospective customers. These online data sources are in the form of blogs, reviews and \nsocial media websites. The popularity of blogging is on the rise, where people from dif-\nferent walks of life express their opinions about various entities and events and get com-\nments on them. At times, it leads to a form of discussion among the author and various \nusers commenting on them. A detailed analysis on blogging styles of authors, as they \n\n\n\nPage 4 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\nfollow their own unique approaches for expressing their feelings is provided in (Chau \nand Xu 2007). Blogs contain opinions about various products, services, their features, \npackages and promotions. Most of the online studies on opinion extraction use blogs as \ndatasets (Qiang and Rob 2009) to perform detailed analysis.\n\nThere are professional review websites providing customers’ feedbacks, used for sen-\ntiment analysis. E-commerce websites allow customers to comment on their products. \nSocial media is another popular medium of sharing information among like-minded \npeople. Here, a variety of subjects are discussed where people express their opinions, \nbased on their own experience. Social media websites have a very complex struc-\nture for extracting information having user opinions. They allow users to express their \nviews through sharing articles and other media sources as an external link. Twitter, also \nreferred to as microblogging, has the problem of reviews being too short and at times \nmiss the context.\n\nThis review article is organized into the following divisions. Section 2 reviews the Sen-\ntiment analysis techniques and the NLP issues. Section 3 provides a discussion on the \nreview studied and Sect. 4 list the application areas for sentiment analysis. Section 5 has \nconcluded the study to important issues drawn from the study. Section 6 has distribu-\ntion of the work carried out by the authors.\n\nReview\nThe sentiment analysis techniques categorize reviews into positive and negative bins or \nmultiple degrees of it. The social data can be analyzed at three different levels i.e. user \ndata, relationship data and content (Tang et al. 2014). In survey (Guellil and Boukhalfa \n2015) these categories are further elaborated. Recommender systems are extended to \nsupport textual content using knowledge (Tang et al. 2013). In our previous work (Khan \nand Khalid 2015) sentiment analysis is highlighted to address health care problems from \nthe view point of a user. The issues faced in SA also depend on the data sources and \nnature of analysis required. An important aspect of social data analysis is the identifi-\ncation of sentiments and sentiment targets (Tuveri and Angioni 2014; Zhang and Liu \n2014). Opinion mining also consider the additional features of opinion holder and time. \nSentiment analysis techniques can be separated into three groups: supervised, semi-\nsupervised and unsupervised techniques.\n\nThe supervised techniques are the machine learning classifiers. They are more accu-\nrate, however, need to be trained on a relevant domain. The unsupervised statistical \ntechniques do not require training. They are efficient in dynamic environment but at the \ncost of accuracy. Sentiment analysis techniques analyze opinion datasets to generate a \ngeneral perception that people have about a product. The classification of sentiments in \na review document is performed through identifying and separating all the positive and \nnegative opinion words. Considering the strength of these words, along with their polar-\nity, helps in multi-class classification. Machine learning classifiers such as Naive-Bayes, \nk-nearest neighbor and centroid based classifier etc., are successfully used for this pur-\npose. Semantic orientation based techniques used for opinion mining are Lexicon based \nand statistical analysis. Lexicon based technique works with individual words while sta-\ntistical analysis incorporates words co-occurrence using point wise mutual information \n(PMI) and latent semantic analysis (LSA). Semi-supervised techniques start with a small \n\n\n\nPage 5 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\nset of opinion words from the given domain, and expand on it. More opinion words are \nexplored by querying the starting seeds. The newly found words are queried again to find \nmore words until no new words are returned. Orientation of the opinion word form the \nbasis for classification. Other attributes used are frequency of occurrence, location and \nco-occurrence with other words. The taxonomy of these approaches is shown in Fig. 1.\n\nSentiment classification\n\nThese are the machine learning classifiers used for sentiment analysis. They can be \napplied to text documents at three levels for analysis. A document level approach, \nwhich studies the whole document as a single entity is appropriate for text categoriza-\ntion. However, document level approach is not viable for sentiment analysis with docu-\nments having multiple opinions. Therefore, sentiment analysis is performed extensively \nat sentence or word level. Word level analysis is also known as sentiment level analysis. \nML techniques suits sentiment analysis as the data is in abundance and there is obvious \npresence of patterns (Schouten and Frasincar 2015). The classifiers are trained on label \ndataset having samples representing all classes. A test dataset is used to evaluate the per-\nformance of the classifiers for the given task. Let the set of documents as {D = d1,…,dn}, \nand set of classes labeled as {C = c1,…,cn}, then the task is to classify document di in D \nwith a label ci in C. This task can be performed using supervised classifiers. The more \nfrequently used classifiers for sentiment analysis are discussed below.\n\nNaïve Bayes\n\nNaive Bayes (NB) classifier is extensively used for text classification. It learns from a \ntraining dataset of annotated feature vectors, with labels as positive and negative (in case \nof binary classification). The probability of a feature vector is calculated with each label \nusing the annotated training dataset. The feature vector is assigned a label that has high-\nest probability for it. If this information is preserved, it can be used to show confidence \nin a label for a feature vector. In further modifications of NB a fuzzy region is defined \nin which feature vectors hold both labels with a certain level of confidence. Text data \nnormally have high dimensional feature vectors. Therefore, the process of calculating \nprobability is repeated for each feature vector, and then all the probabilities contribute \ntowards the final decision. The feature set is represented as F = f1, f2…fm}, where prob-\nability of a document belonging to a class shown as:\n\nFig. 1 Taxonomy of expository literature on sentiment analysis\n\n\n\nPage 6 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\nShows the probability of a document dj represented by its vector dj* belonging to a class \nci. It is the product of probabilities for all the features in the feature set. The document \nvector dj\n\n* is assigned to a class ci in order to maximize P\n(\n\nci\n\n∣\n\n∣\n\n∣\nd∗j\n\n)\n\n. The logarithm of prob-\nabilities are summed up to classify an opinion document. It is preferred over product of \nprobabilities to avoid underflow. It addresses the missing value problem as well. Slack \nvariables add smoothing effect against noisy data. Weights can also be assigned to fea-\ntures which define their contribution towards the classification. It is a biased approach, \nwhere prominent features are given high weights to play a major role in choose a senti-\nment label.\n\nNaive Bayes works on the assumption that all the sentences of a review document are \nopinion sentences. It also assumes that features of a document are independent of each \nother. Despite of this unrealistic assumption, Naïve Bayes is very successful and is used \nin various practical applications. The assumption of treating features as independent of \neach other makes Naive Bayes highly efficient (Dai et al. 2007). Although, Naive Bayes \nclassifier is simple, yet it is effective because of its robustness to irrelevant features. It \nperforms well in domains with many equally important features. It is considered to be \nmore reliable for text classification and sentiment analysis. The accuracy of the classifier \nimproves with pre-processing noise. It also used as transfer learning when trained on a \ndataset similar to the target dataset.\n\nNearest neighbor\n\nk-nearest neighbor classifier has been frequently used in literature for text classifica-\ntion. It considers the labels of k nearest neighbors to classify a test document. A special \ncase of the k-NN problem is typically referred to as classimbalance problem identified \nin (Yang and Liu 1999). Classes with more training data have higher influence to predict \nsame label for the new document. There are fewer chances of acquiring a class label if \nthat class has fewer training examples. (Li et al. 2003) catered this problem by using vari-\nable value of k for each class. Thus, the class having more training data will have higher \nvalue of k as compared to the one having few samples. This solution is helpful in online \nclassification, where there is time constraint on trying different values of k.\n\nA study on performance of k-NN using pre-processed dataset is conducted in (Shin \net al. 2006) claiming 10 % improvement when noise and outliers are filtered out. An opti-\nmum value is chosen as threshold to separate regular data from noise. Sentiment analy-\nsis is performed with a reduced set of feature vector in (Sreemathy and Balamurugan \n2012) to avoid the curse of dimensionality. Accuracy of the model improves as irrelevant \nfeatures were removed. Features are assigned weights to vary their contribution towards \ndecision making. Weights are extracted from probability of information in documents \nacross different categories. Tree-fast k-NN is introduced as fast kNN model (Soucy and \nMineau 2001). This tree based indexing of retrieval system improves the accuracy of \nk-NN in distance calculation. Its effective against large feature sets. The order of features \nand their thresholds are identified from within the training data. k-NN has promising \n\n(1)P(ci\n∣\n\n∣dj\n∗\n) =\n\np(ci)(\n∏m\n\ni=1 p(fi|ci) )\n\np(d∗j )\n\n\n\nPage 7 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\nresults in sentiment analysis; however, it is more susceptible to noise and high dimen-\nsional feature set. Therefore, more of the work in k-NN for text classification has focused \non feature selection and reduction techniques as they are the driving factors of k-NN’s \nperformance.\n\nCentroid based\n\nCentroid based (CB) classifier calculates centroid vector or prototype vector for each \nclass in the training dataset. Centroid vector is the central point of the class and may not \nrepresent an actual training data. The distance of each test document is calculated with \nthe prototype vector of the class and is classified based on similarity with it. Its perfor-\nmance depends on the chosen centroid vectors. It is efficient since time and space com-\nplexities are proportional to the number of classes rather than training documents. To \ndouble the training data reverse of reviews are generated in (Xia et al. 2015) by invert-\ning the sentiment terms and their labels. Using both sets of training data with Mutual \nInformation (MI) the results were improved when only selected reviews were inverted. \nExternal dictionary WordNet is used to generate inverse for sentiment terms, however, \npseudo-antonyms can be generated internally using the corpus.\n\nms, however, pseudo-antonyms can be generated internally using the corpus. A variety \nof approaches have been used for CB classifier. Rocchio algorithm calculates centroid \nto represent feature space of documents (Ana and Arlindo 2007; Tan 2007a, b). Cen-\ntroid is computed through average of positive examples in (Han and Karypis 2000) and \nsum of positive cases i.e. the related training examples (Chuang et al. 2000). Normalized \nsum of positive vectors used in (Lertnattee and Theeramunkong2004), cosine similar-\nity between the test document and the Centroid of a class (Hidayet and Tunga 2012). \nCentroid is used with inverse of class similarity as well improving the accuracy close to \n100 % on the given dataset when characters are chosen as features instead of n-grams.\n\nCentroid evaluation is sensitive to noise in the training dataset which affects the over-\nall performance of the classifier. This shortfall is exposed when Centroid classifier is \napplied to a slightly different domain. The reason for this drawback is that some opinion \nwords are domain dependent. They have different polarity or strength of polarity when \nused in a different domain. Smoothing techniques have being proposed in (Tan 2007a, b; \nLertnattee and Theeramunkong 2006; Guan 2009) that minimizes the effect of noise \nin the dataset. (Chizi et al. 2009) defined a weighting scheme giving higher weights to \nexplicit opinion words. Characters and special characters for feature selection are used \nin (Ozgur and Gungor 2009). The work in (Shankar and Karypis 2000; Tan et al. 2005) \nis focused on adjusting the value of centroid based with feedback looping, hypothesis \nmargin and weight-adjustment respectively. They try to rectify class Centroid, if it is not \ncalculated accurately. Centroid based classifier performs efficiently as it doesn’t consider \ntraining data each time to decide a test document.\n\nSupport vector machine\n\nSupport vector machine classifier is used for text classification in various studies. It finds \na separation among the data using the annotated training dataset. The margin of sep-\naration between classes, which is known as hyperplane, is used to classify the incom-\ning data. The hyperplane should give maximum separation between the classes. It is \n\n\n\nPage 8 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\napplicable even in the presence of high dimensional feature set representation. It classify \nbased o hyperplane among classes. Like centroid-based, SVM also consider the hyper-\nplane to classify a test document. (Brown et  al. 1997) has compared SVM with artifi-\ncial neural networks for text classification and has found it better. Since it has promising \nresults in text classification, it also performs well for opinion mining. They have also \nclaimed in (Brown et al. 1997) that SVM is better than Naive Bayes and decision trees \nclassification algorithms. However, SVM consumes more resources at the training \nstage. Although, it is efficient with large feature set, Feldman et al.(2011) has shown that \ndimensionality reduction in feature set further improves the performance of SVM. It \nexhibits linear complexity and can scale up to a large dataset.\n\nSVM has a limitation of over-reliance on selection of suitable kernel function. Kernel \nis calculated through Linear, Polynomial, Gaussian or sigmoid methods but they tend to \nbe domain specific. Kernel functions that perform well for one domain may not repeat it \nfor next. Its accuracy is also sensitive to number of training samples close to hyperplane. \nSlack variables are introduced to limit the impact of boundary samples by generalizing \nthe classifier, known as soft margin classification. They also help to avoid over-fitting the \ntraining data.\n\nUnsupervised techniques\n\nThe unsupervised sentiment analysis techniques do not require training data and rather \nrely on semantic orientation. They make use of lexicons to identify the positive or neg-\native semantics of opinion words. The meaning of the word, expressed by its use in a \ncontext is called lexicon. An online or off-line dictionary is consulted for this purpose. \nStatistical analysis techniques are also unsupervised, identifying the orientation of senti-\nment words through statistical evaluations. They require large volume of data for high \naccuracy.\n\nLanguages consists of lexicons that are the words used for a particular sense, and a \ngrammar that connect these lexicons. Part-of-speech rules are used to extract senti-\nment phrases from text document. Search engines are used to identify the orientation \nof sentiment words that are missing in the dictionary. Its polarity is identified through \nthe nearby words brought by search engines. They purely rely on external sources and \ntherefore cannot address the context. Lexicon based techniques perform well for general \ndomains while statistical techniques addresses the context and are useful in specialized \ndomains. The two types of approaches are discussed in detail.\n\nDictionary (Lexicon) based techniques\n\nLexicon based techniques extract opinion lexicons from the document and analyzes \nits orientation without the support of any training data. These techniques process the \nopinion words separately, ignoring the relationship between them. Lexicons refer to the \nsemantic orientation. Lexicons are independent of the source data and therefore it does \nnot fall for over-fitting. But context not addressed either in this approach (Katz et  al. \n2015; Cambria 2013). Search engines are used to find the meaning of unknown opinion \nlexicons. They are searched and the top N results are accepted to identify its orientation. \nThe semantics of lexicons can be categorized as positive or negative with weights rep-\nresenting their strength. This approach struggles with lexicons having domain specific \n\n\n\nPage 9 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\npolarity. For example, good has positive polarity in any type of domain but “heavy \nweight” has positive polarity for bike domain but negative for the domain of electronic \ndevices.\n\nIn its simplest form, sentiment words are split into positive and negative as binary \ndistribution. A more sophisticated approach has fuzzy lexicons, introducing a grey area \nbetween the two categories. These fuzzy lexicons exist in both the classes with a score \nassociated to it, representing the strength of each label. Various manual and semi-auto-\nmatic techniques can be used for building lexicons. Princeton University’s WordNet is \na popular lexicon source available for sentiment analysis. Dictionaries like WordNet, \nextracts synonyms and antonyms for the provided opinion words. Manual cleansing is \nemployed to rectify the lists generated for the unknown sentiment words. These opinion \nwords are used to classify a review as positive or negative.\n\nFixed syntactic patterns are also used for expressing opinions which are composed of \npart-of-speech (POS) tags. The basic idea of this technique is to identify the patterns in \nwhich words co-occur with each other and to exploit those patterns for understanding \nits semantic orientation. One example of such pattern is an adverb followed by an adjec-\ntive. A more sophisticated approach was proposed by (Mohammad and Yang 2011), \nwhich used a WordNet distance based method to determine the sentiment orientation. \nThe distance d(t1, t2) between terms t1 and t2 is the length of the shortest path that con-\nnects them in WordNet, as shown in Eq. 2. The semantic orientation (SO) of an adjective \nterm t is determined by its relative distance from two reference (or seed) terms good and \nbad. The polarity of opinion term t is resolved through eq.\n\nStatistics (Corpus) based techniques\n\nStatistical analysis of large corpus of text can also be used to determine the sentiment \norientation of words. Co-occurrence of words is evaluated without consulting any exter-\nnal support. Two methods are used for this purpose which are point wise mutual infor-\nmation (PMI) and latent semantic analysis (LSA). PMI method for co-occurrence is \ngiven as:\n\nwhere w1 and w2 refers to two words in a given sentence. The main concept behind PMI \nbased techniques is that the semantic orientation of a word has a tendency of being \nclosely related to that of its neighbors. Equation 3 gives the probability of words w1 and \nw2 to co-exist, based on the measure of degree of statistical dependence between the \ntwo. This approach is, however, implemented differently in LSA based techniques. In \nLSA, matrix factorization technique is used with singular value decomposition to dem-\nonstrate the statistical co-occurrence of words. More formally, this process can be speci-\nfied as:\n\n(2)SO(t) =\nd(t, bad)− d(t, good)\n\nd(bad, good)\n\n(3)p(w1,w2) =\np(w1,w2)\n\np(w1) p(w2)\n\n(4)LSA(w) = LSA(w, {+paradigms})− LSA(w, {−paradigms})\n\n\n\nPage 10 of 19Khan et al. Complex Adapt Syst Model (2016) 4:2 \n\nwhere a word w is passed to LSA with positive and negative paradigms. LSA based tech-\nniques develop a matrix having rows as words and columns as sentences or paragraphs. \nEach cell possesses a weight corresponding to the relation of the word in row with the \nsentence or paragraph in columns. This matrix is decomposed into three matrices using \nsingular value decomposition (SVD).\n\nComplex challenges\n\nOpinion mining is a relatively new area of research and there are open challenges that \nneed to be answered. Some of the challenges are common to opinion mining in general \nwhile others are related to their own sources and context depending upon the domain of \nthe dataset. These issues affect the performance of machine learning techniques, but it \nhas little control on them. Figure 2 gives NLP challenges faced in sentiment analysis, dis-\ntributing them into their logical groups. The groupings are based on the parsing level, at \nwhich these issues occur. The following sub section has detailed discussion on the NLP \nissues.\n\nDocument level\n\nDocument level NLP challenges are the ones that are faced at the document or review \nlevel. They deal in general with the review document or the reviewer style. It is common \nto find reviews that have the information about an object, given in an informal manner. \nCapitalization is over or under used. Spelling mistakes are ignored or words being short-\nened. It makes the analysis very difficult for the automatic techniques to identify features \nand associate them. The unknown words (shortened/miss spelled) are matched with \nsimilar words to identify the aspect or opinion words. Slang specific to a certain region \nare also occasionally used in reviews and discussions. Reviews having sarcastic expres-\nsions are the hardest to deal with. Even though they have the opinion words explicitly \nmen", "metadata_storage_path": "aHR0cHM6Ly9rYm1zdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9wYXBlcnMvczQwMjk0LTAxNi0wMDE2LTkucGRm0", "metadata_author": "Muhammad Taimoor Khan", "metadata_title": "Sentiment analysis and the complex natural language", "metadata_creation_date": "2016-02-02T06:54:52Z", "people": [ "Muhammad Taimoor Khan1", "Mehr Durrani", "Armughan Ali2,", "Irum Inayat3,", "Shehzad Khalid1", "Kamran", "Habib Khan4", "Pang", "Lillian", "Hai", "Khan", "taimoor", "Cambria", "Mohammad", "Yang", "Niazi", "Aoyama", "Hussain", "Katz", "Xu", "Qiang", "Rob", "Tang", "Guellil", "Boukhalfa", "Khalid", "Tuveri", "Angioni", "Zhang", "Liu", "Schouten", "Frasincar", "Bayes", "Naive Bayes", "Naïve Bayes", "Dai", "Li", "Sreemathy", "Balamurugan", "Soucy", "Mineau", "Xia", "Rocchio", "Ana", "Arlindo", "Han", "Karypis", "Chuang", "Lertnattee", "Theeramunkong2004", "Hidayet", "Tunga", "Tan", "Theeramunkong", "Guan", "Chizi", "Ozgur", "Gungor", "Shankar", "Brown", "Feldman" ], "organizations": [ "NLP", "Commons", "Bahria University", "sion", "Business Week", "Comscore", "The Kelsey", "Twitter", "k-NN", "Cen", "SVM", "Kernel", "Princeton University", "PMI", "LSA" ], "locations": [ "Shangrilla", "Islamabad", "Pakistan" ], "keyphrases": [ "Creative Commons Attribution 4.0 International License", "customer- agent phone conversation", "Complex networks Open Access", "Complex Adapt Syst Model", "Creative Commons license", "users’ senti- ments", "domain specific solution", "profitable business decisions", "various online sources", "Complex network based", "specific structural information", "original author(s", "natural language processing", "specific open challenges", "natural language data", "data leakage analysis", "Muhammad Taimoor Khan1", "sentiment analysis techniques", "open issues", "author information", "language models", "influence analysis", "bias analysis", "ML) techniques", "ML techniques", "lexicon-based techniques", "statistical techniques", "sentiment words", "Sentiment orientation", "Mehr Durrani", "Armughan Ali", "Irum Inayat", "Shehzad Khalid1", "Habib Khan4", "text classification", "subjective statements", "subjective attitudes", "social data", "huge amount", "amateur authors", "large variety", "target entity", "Machine learning", "definite patterns", "high accuracy", "feature set", "external dictionary", "specialized domains", "large data", "Recent applications", "New sub-domains", "considerable advancements", "standard datasets", "evaluation methodology", "unrestricted use", "appropriate credit", "1 Bahria University", "Shangrilla Road", "Sector E", "Full list", "social media", "data mining", "opinionated content", "public perception", "opinion mining", "opinion content", "REVIEW Khan", "Kamran", "Introduction", "Pang", "Lillian", "type", "opinions", "order", "document", "NLP", "sentiments", "people", "topic", "features", "reason", "popularity", "advice", "others", "big", "hotspot", "field", "Hai", "Abstract", "abundance", "overfitting", "context", "Corpus-based", "proximity", "relationships", "platform", "meta-data", "nature", "paper", "need", "area", "better", "Keywords", "article", "terms", "creativecommons", "licenses", "distribution", "reproduction", "medium", "link", "changes", "DOI", "Correspondence", "Islamabad", "Pakistan", "end", "crossmark", "org", "Page", "19Khan", "Manufacturers", "products", "tory", "blogs", "forums", "websites", "graph based analysis techniques", "various sub streams", "different writing styles", "multi-class classification problem", "ML) based techniques", "Natural language processing", "many control options", "same sentiment polarity", "Sentiment analysis techniques", "binary classification", "complex network", "manual techniques", "supervised techniques", "overall analysis", "trend analysis", "statistical analysis", "complex sentences", "automated processes", "user support", "online datasets", "objective statements", "Such statements", "common-sense knowledge", "geographical domains", "gender identification", "fairy tales", "interesting patterns", "open challenges", "high frequency", "same product", "later section", "detailed discussion", "subjective content", "online sources", "single entity", "subjective sentence", "sound effects", "game X", "game Y", "objective sentence", "sentence types", "machine learning", "manual tuning", "domain experts", "large volume", "Opinion mining", "opinion patterns", "single opinion", "emotion analysis", "text categorization", "comparative sentences", "multiple opinions", "Regular opinions", "comparative opinions", "extensive use", "subjective nature", "gle word", "individual words", "NLP tasks", "NLP issues", "opinion words", "Simple sentences", "millions", "reviews", "rapid", "minimal", "way", "outcome", "form", "scale", "likeness", "Cambria", "results", "applications", "business", "political", "emails", "Mohammad", "Yang", "semantics", "date", "ior", "assumptions", "Documents", "matching", "fact", "variety", "difference", "negations", "NOT", "sarcastic", "compound", "implicit", "meaning", "aspects", "comparison", "example", "Bag", "BOW", "diverse subjective data sources", "seman- tic association", "Business Week survey", "Many complex systems", "complex struc- ture", "professional review websites", "other media sources", "social media websites", "The Kelsey group", "low quality features", "online data sources", "E-commerce websites", "online studies", "effective- ness", "Sentiment analysis", "environmental modeling", "wireless sensors", "global properties", "degree distribution", "multi-partite graphs", "different types", "large number", "current issues", "last decade", "ferent walks", "detailed analysis", "unique approaches", "popular medium", "various properties", "various clusters", "opinion extraction", "online reviews", "prospective customers", "customers’ feedbacks", "ad-hoc networks", "blogging styles", "external link", "various products", "adjacent nodes", "various entities", "user opinions", "Results", "repetitive", "polarity", "performance", "classifier", "cost", "efficiency", "Effectiveness", "precision/recall", "measurements", "relevance", "edges", "domains", "Niazi", "Aoyama", "Hussain", "information", "range", "local", "Text", "pora", "structural", "weight", "centrality", "ponents", "communities", "paths", "inter-cluster", "reasons", "support", "topics", "Web2.0", "thoughts", "backgrounds", "Katz", "users", "world", "ratings", "purchase", "Comscore", "value", "rise", "life", "events", "times", "discussion", "author", "feelings", "Chau", "Xu", "services", "packages", "promotions", "datasets", "Qiang", "Rob", "minded", "subjects", "experience", "articles", "Twitter", "point wise mutual information", "Semantic orientation based techniques", "centroid based classifier", "health care problems", "latent semantic analysis", "Lexicon based technique", "machine learning classifiers", "document level approach", "timent analysis techniques", "three different levels", "unsupervised statistical techniques", "text categoriza- tion", "Word level analysis", "sentiment level analysis", "social data analysis", "negative opinion words", "unsupervised techniques", "view point", "three levels", "sentiment analysis", "Semi-supervised techniques", "negative bins", "sentiment targets", "three groups", "opinion holder", "opinion datasets", "following divisions", "application areas", "multiple degrees", "relationship data", "Recommender systems", "data sources", "important aspect", "identifi- cation", "additional features", "dynamic environment", "general perception", "polar- ity", "k-nearest neighbor", "starting seeds", "Other attributes", "text documents", "docu- ments", "label dataset", "test dataset", "Sentiment classification", "review document", "new words", "other words", "important issues", "review article", "user data", "textual content", "previous work", "relevant domain", "multi-class classification", "Section 2", "Sect.", "Section 5", "study", "Section 6", "authors", "positive", "Tang", "survey", "Guellil", "Boukhalfa", "categories", "knowledge", "Khan", "Khalid", "SA", "Tuveri", "Angioni", "Zhang", "Liu", "rate", "training", "accuracy", "product", "strength", "Naive-Bayes", "pose", "occurrence", "PMI", "small", "More", "basis", "frequency", "location", "taxonomy", "approaches", "Fig.", "sentence", "presence", "patterns", "Schouten", "Frasincar", "classes", "formance", "task", "many equally important features", "high dimensional feature vectors", "various practical applications", "Naïve Bayes", "annotated feature vectors", "text classifica- tion", "k-nearest neighbor classifier", "fewer training examples", "senti- ment label", "k nearest neighbors", "missing value problem", "Naive Bayes classifier", "document vector dj", "high weights", "fewer chances", "Text data", "document dj", "training data", "fuzzy region", "final decision", "prob- abilities", "Slack variables", "smoothing effect", "noisy data", "fea- tures", "biased approach", "major role", "transfer learning", "classimbalance problem", "able value", "time constraint", "different values", "document di", "opinion document", "test document", "new document", "prominent features", "irrelevant features", "target dataset", "online classification", "processed dataset", "NB) classifier", "same label", "supervised classifiers", "expository literature", "opinion sentences", "pre-processing noise", "special case", "k-NN problem", "higher influence", "unrealistic assumption", "class ci", "class label", "k.", "C.", "labels", "probability", "confidence", "modifications", "level", "probabilities", "Taxonomy", "The", "logarithm", "underflow", "contribution", "Dai", "robustness", "samples", "solution", "Shin", "10 % improvement", "outliers", "opti", "External dictionary WordNet", "fast kNN model", "explicit opinion words", "related training examples", "sional feature set", "actual training data", "training data reverse", "large feature sets", "reduced set", "positive examples", "regular data", "feature vector", "feature selection", "decision making", "different categories", "retrieval system", "reduction techniques", "driving factors", "prototype vector", "central point", "Rocchio algorithm", "Cen- troid", "positive cases", "positive vectors", "different domain", "Smoothing techniques", "weighting scheme", "feedback looping", "hypothesis margin", "training dataset", "feature space", "sentiment terms", "training documents", "Centroid based", "centroid vector", "Centroid evaluation", "mum value", "distance calculation", "Mutual Information", "different polarity", "higher weights", "special characters", "Tree-fast k-NN", "Centroid classifier", "CB classifier", "class Centroid", "class similarity", "threshold", "noise", "Sreemathy", "Balamurugan", "curse", "dimensionality", "Accuracy", "Soucy", "Mineau", "indexing", "dj", "work", "plexities", "number", "Xia", "inverse", "pseudo-antonyms", "corpus", "Arlindo", "average", "Karypis", "sum", "Chuang", "Lertnattee", "Theeramunkong2004", "cosine", "Hidayet", "Tunga", "n-grams", "shortfall", "drawback", "Guan", "effect", "Chizi", "Ozgur", "Gungor", "Shankar", "∏", "high dimensional feature set representation", "decision trees classification algorithms", "Support vector machine classifier", "unsupervised sentiment analysis techniques", "large feature set", "cial neural networks", "Statistical analysis techniques", "suitable kernel function", "top N results", "incom- ing data", "soft margin classification", "Lexicon based techniques", "senti- ment words", "Centroid based classifier", "unknown opinion lexicons", "Unsupervised techniques", "ment phrases", "large dataset", "statistical evaluations", "various studies", "sep- aration", "Naive Bayes", "training stage", "dimensionality reduction", "sigmoid methods", "Kernel functions", "training samples", "boundary samples", "particular sense", "speech rules", "Search engines", "nearby words", "external sources", "two types", "source data", "text document", "maximum separation", "linear complexity", "one domain", "ative semantics", "general domains", "semantic orientation", "line dictionary", "hyperplane", "SVM", "Brown", "resources", "Feldman", "limitation", "over-reliance", "selection", "Polynomial", "Gaussian", "impact", "use", "online", "purpose", "Languages", "grammar", "detail", "relationship", "negative", "weights", "WordNet distance based method", "popular lexicon source", "singular value decomposition", "machine learning techniques", "Fixed syntactic patterns", "LSA based techniques", "matrix factorization technique", "unknown sentiment words", "Complex challenges", "relative distance", "PMI method", "Statistical analysis", "electronic devices", "simplest form", "grey area", "two categories", "Various manual", "Princeton University", "Manual cleansing", "POS) tags", "basic idea", "shortest path", "adjective term", "two reference", "nal support", "Two methods", "main concept", "statistical dependence", "three matrices", "new area", "little control", "sentiment orientation", "NLP challenges", "opinion term", "sophisticated approach", "fuzzy lexicons", "One example", "eq. Statistics", "large corpus", "statistical co-occurrence", "two words", "domain specific", "bike domain", "negative paradigms", "positive polarity", "good", "score", "label", "Dictionaries", "synonyms", "antonyms", "lists", "review", "speech", "understanding", "adverb", "t2", "length", "seed", "text", "mation", "w1", "w2", "tendency", "neighbors", "Equation", "measure", "degree", "process", "rows", "columns", "paragraphs", "cell", "relation", "SVD", "research", "general", "sources", "dataset", "issues", "Figure 2", "Document level NLP challenges", "following sub section", "parsing level", "review level", "logical groups", "reviewer style", "informal manner", "Spelling mistakes", "automatic techniques", "unknown words", "similar words", "groupings", "object", "Capitalization", "analysis", "aspect", "Slang", "region", "discussions" ], "pii_entities": [ { "text": "Muhammad Taimoor Khan1", "type": "Person", "subtype": null, "offset": 54, "length": 22, "score": 0.99 }, { "text": "Mehr Durrani", "type": "Person", "subtype": null, "offset": 79, "length": 12, "score": 0.96 }, { "text": "Armughan Ali", "type": "Person", "subtype": null, "offset": 94, "length": 12, "score": 0.98 }, { "text": "Irum Inayat", "type": "Person", "subtype": null, "offset": 109, "length": 11, "score": 0.96 }, { "text": "Shehzad Khalid1", "type": "Person", "subtype": null, "offset": 123, "length": 15, "score": 0.97 }, { "text": "Kamran", "type": "Person", "subtype": null, "offset": 143, "length": 6, "score": 0.95 }, { "text": "Habib Khan4", "type": "Person", "subtype": null, "offset": 151, "length": 11, "score": 0.98 }, { "text": "Pang", "type": "Person", "subtype": null, "offset": 197, "length": 4, "score": 0.95 }, { "text": "Lillian", "type": "Person", "subtype": null, "offset": 206, "length": 7, "score": 0.66 }, { "text": "2008", "type": "DateTime", "subtype": "DateRange", "offset": 214, "length": 4, "score": 0.8 }, { "text": "Pang", "type": "Person", "subtype": null, "offset": 691, "length": 4, "score": 0.94 }, { "text": "Lillian", "type": "Person", "subtype": null, "offset": 700, "length": 7, "score": 0.94 }, { "text": "2008", "type": "DateTime", "subtype": "DateRange", "offset": 709, "length": 4, "score": 0.8 }, { "text": "Hai", "type": "Person", "subtype": null, "offset": 949, "length": 3, "score": 0.94 }, { "text": "2014", "type": "DateTime", "subtype": "DateRange", "offset": 960, "length": 4, "score": 0.8 }, { "text": "authors", "type": "PersonType", "subtype": null, "offset": 1038, "length": 7, "score": 0.58 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 1132, "length": 5, "score": 0.85 }, { "text": "niques", "type": "PersonType", "subtype": null, "offset": 1660, "length": 6, "score": 0.59 }, { "text": "agent", "type": "PersonType", "subtype": null, "offset": 2013, "length": 5, "score": 0.79 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 2659, "length": 4, "score": 0.8 }, { "text": "Khan", "type": "Person", "subtype": null, "offset": 2664, "length": 4, "score": 0.96 }, { "text": "creativecommons.org/licenses/by/4.0/", "type": "URL", "subtype": null, "offset": 2791, "length": 36, "score": 0.8 }, { "text": "author", "type": "PersonType", "subtype": null, "offset": 2962, "length": 6, "score": 0.91 }, { "text": "Khan", "type": "Person", "subtype": null, "offset": 3081, "length": 4, "score": 0.97 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 3120, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 3126, "length": 3, "score": 0.8 }, { "text": "Bahria University", "type": "Organization", "subtype": null, "offset": 3213, "length": 17, "score": 0.8 }, { "text": "Road", "type": "Address", "subtype": null, "offset": 3244, "length": 4, "score": 0.63 }, { "text": "Sector E-8", "type": "Address", "subtype": null, "offset": 3250, "length": 10, "score": 0.71 }, { "text": "http://creativecommons.org/licenses/by/4.0/", "type": "URL", "subtype": null, "offset": 3357, "length": 43, "score": 0.8 }, { "text": "http://creativecommons.org/licenses/by/4.0/", "type": "URL", "subtype": null, "offset": 3401, "length": 43, "score": 0.8 }, { "text": "http://crossmark.crossref.org/dialog/?doi=10.1186/s40294-016-0016-9&domain=pdf", "type": "URL", "subtype": null, "offset": 3445, "length": 78, "score": 0.8 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 3536, "length": 6, "score": 0.86 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 3577, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 3583, "length": 3, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 4214, "length": 4, "score": 0.61 }, { "text": "Cambria", "type": "Person", "subtype": null, "offset": 4749, "length": 7, "score": 0.95 }, { "text": "2013", "type": "DateTime", "subtype": "DateRange", "offset": 4765, "length": 4, "score": 0.8 }, { "text": "Mohammad", "type": "Person", "subtype": null, "offset": 5241, "length": 8, "score": 0.94 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 5255, "length": 4, "score": 0.76 }, { "text": "2011", "type": "DateTime", "subtype": "DateRange", "offset": 5260, "length": 4, "score": 0.8 }, { "text": "Mohammad", "type": "Person", "subtype": null, "offset": 5331, "length": 8, "score": 0.9 }, { "text": "2011", "type": "DateTime", "subtype": "DateRange", "offset": 5341, "length": 4, "score": 0.8 }, { "text": "till \ndate", "type": "DateTime", "subtype": "DateRange", "offset": 5692, "length": 10, "score": 0.8 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 5964, "length": 3, "score": 0.8 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 6342, "length": 3, "score": 0.8 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 7268, "length": 6, "score": 0.87 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 7309, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 7315, "length": 3, "score": 0.8 }, { "text": "experts", "type": "PersonType", "subtype": null, "offset": 7762, "length": 7, "score": 0.58 }, { "text": "Niazi", "type": "Person", "subtype": null, "offset": 8510, "length": 5, "score": 0.94 }, { "text": "2010", "type": "DateTime", "subtype": "DateRange", "offset": 8524, "length": 4, "score": 0.8 }, { "text": "Aoyama", "type": "Person", "subtype": null, "offset": 8551, "length": 6, "score": 0.91 }, { "text": "2002", "type": "DateTime", "subtype": "DateRange", "offset": 8558, "length": 4, "score": 0.8 }, { "text": "Niazi", "type": "Person", "subtype": null, "offset": 8604, "length": 5, "score": 0.94 }, { "text": "Hussain", "type": "Person", "subtype": null, "offset": 8614, "length": 7, "score": 0.89 }, { "text": "2009", "type": "DateTime", "subtype": "DateRange", "offset": 8622, "length": 4, "score": 0.8 }, { "text": "the last decade", "type": "DateTime", "subtype": "DateRange", "offset": 9703, "length": 15, "score": 0.8 }, { "text": "Katz", "type": "Person", "subtype": null, "offset": 9895, "length": 4, "score": 0.92 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 9907, "length": 4, "score": 0.8 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 9978, "length": 5, "score": 0.93 }, { "text": "Business Week", "type": "Organization", "subtype": null, "offset": 10017, "length": 13, "score": 0.58 }, { "text": "2009", "type": "DateTime", "subtype": "DateRange", "offset": 10041, "length": 4, "score": 0.8 }, { "text": "Comscore", "type": "Organization", "subtype": null, "offset": 10122, "length": 8, "score": 0.93 }, { "text": "The Kelsey", "type": "Organization", "subtype": null, "offset": 10131, "length": 10, "score": 0.67 }, { "text": "2007", "type": "DateTime", "subtype": "DateRange", "offset": 10152, "length": 4, "score": 0.8 }, { "text": "customers", "type": "PersonType", "subtype": null, "offset": 10358, "length": 9, "score": 0.88 }, { "text": "users", "type": "PersonType", "subtype": null, "offset": 10702, "length": 5, "score": 0.92 }, { "text": "authors", "type": "PersonType", "subtype": null, "offset": 10770, "length": 7, "score": 0.93 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 10801, "length": 6, "score": 0.85 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 10842, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 10848, "length": 3, "score": 0.8 }, { "text": "Xu", "type": "Person", "subtype": null, "offset": 10945, "length": 2, "score": 0.81 }, { "text": "2007", "type": "DateTime", "subtype": "DateRange", "offset": 10948, "length": 4, "score": 0.8 }, { "text": "Qiang", "type": "Person", "subtype": null, "offset": 11127, "length": 5, "score": 0.97 }, { "text": "Rob", "type": "Person", "subtype": null, "offset": 11137, "length": 3, "score": 0.83 }, { "text": "2009", "type": "DateTime", "subtype": "DateRange", "offset": 11141, "length": 4, "score": 0.8 }, { "text": "customers", "type": "PersonType", "subtype": null, "offset": 11227, "length": 9, "score": 0.84 }, { "text": "customers", "type": "PersonType", "subtype": null, "offset": 11306, "length": 9, "score": 0.97 }, { "text": "Twitter", "type": "Organization", "subtype": null, "offset": 11761, "length": 7, "score": 0.6 }, { "text": "authors", "type": "PersonType", "subtype": null, "offset": 12274, "length": 7, "score": 0.95 }, { "text": "three", "type": "DateTime", "subtype": "Time", "offset": 12439, "length": 5, "score": 0.8 }, { "text": "Tang", "type": "Person", "subtype": null, "offset": 12510, "length": 4, "score": 0.94 }, { "text": "2014", "type": "DateTime", "subtype": "DateRange", "offset": 12523, "length": 4, "score": 0.8 }, { "text": "Guellil", "type": "Person", "subtype": null, "offset": 12541, "length": 7, "score": 0.75 }, { "text": "Boukhalfa", "type": "Person", "subtype": null, "offset": 12553, "length": 9, "score": 0.85 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 12564, "length": 4, "score": 0.8 }, { "text": "Tang", "type": "Person", "subtype": null, "offset": 12689, "length": 4, "score": 0.95 }, { "text": "2013", "type": "DateTime", "subtype": "DateRange", "offset": 12701, "length": 4, "score": 0.8 }, { "text": "Khalid", "type": "Person", "subtype": null, "offset": 12740, "length": 6, "score": 0.84 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 12747, "length": 4, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 12845, "length": 4, "score": 0.92 }, { "text": "Tuveri", "type": "Person", "subtype": null, "offset": 13045, "length": 6, "score": 0.95 }, { "text": "Angioni", "type": "Person", "subtype": null, "offset": 13056, "length": 7, "score": 0.89 }, { "text": "2014", "type": "DateTime", "subtype": "DateRange", "offset": 13064, "length": 4, "score": 0.8 }, { "text": "Zhang", "type": "Person", "subtype": null, "offset": 13070, "length": 5, "score": 0.98 }, { "text": "Liu", "type": "Person", "subtype": null, "offset": 13080, "length": 3, "score": 0.97 }, { "text": "2014", "type": "DateTime", "subtype": "DateRange", "offset": 13085, "length": 4, "score": 0.8 }, { "text": "opinion holder", "type": "PersonType", "subtype": null, "offset": 13148, "length": 14, "score": 0.65 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 14464, "length": 6, "score": 0.89 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 14505, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 14511, "length": 3, "score": 0.8 }, { "text": "three", "type": "DateTime", "subtype": "Time", "offset": 15096, "length": 5, "score": 0.8 }, { "text": "Schouten", "type": "Person", "subtype": null, "offset": 15616, "length": 8, "score": 0.94 }, { "text": "Frasincar", "type": "Person", "subtype": null, "offset": 15629, "length": 9, "score": 0.72 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 15639, "length": 4, "score": 0.8 }, { "text": "Naïve Bayes", "type": "Person", "subtype": null, "offset": 16123, "length": 11, "score": 0.97 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 17179, "length": 6, "score": 0.9 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 17220, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 17226, "length": 3, "score": 0.8 }, { "text": "Naive Bayes", "type": "Person", "subtype": null, "offset": 17987, "length": 11, "score": 0.83 }, { "text": "Dai", "type": "Person", "subtype": null, "offset": 18388, "length": 3, "score": 0.93 }, { "text": "2007", "type": "DateTime", "subtype": "DateRange", "offset": 18399, "length": 4, "score": 0.8 }, { "text": "Naive Bayes", "type": "Person", "subtype": null, "offset": 18416, "length": 11, "score": 0.84 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 19128, "length": 4, "score": 0.93 }, { "text": "Liu", "type": "Person", "subtype": null, "offset": 19137, "length": 3, "score": 0.56 }, { "text": "1999", "type": "DateTime", "subtype": "DateRange", "offset": 19141, "length": 4, "score": 0.8 }, { "text": "Li", "type": "Person", "subtype": null, "offset": 19343, "length": 2, "score": 0.83 }, { "text": "2003", "type": "DateTime", "subtype": "DateRange", "offset": 19353, "length": 4, "score": 0.8 }, { "text": "2006", "type": "DateTime", "subtype": "DateRange", "offset": 19747, "length": 4, "score": 0.8 }, { "text": "2012", "type": "DateTime", "subtype": "DateRange", "offset": 20002, "length": 4, "score": 0.8 }, { "text": "Soucy", "type": "Person", "subtype": null, "offset": 20343, "length": 5, "score": 0.67 }, { "text": "Mineau", "type": "Person", "subtype": null, "offset": 20354, "length": 6, "score": 0.82 }, { "text": "2001", "type": "DateTime", "subtype": "DateRange", "offset": 20361, "length": 4, "score": 0.8 }, { "text": "=1 p", "type": "DateTime", "subtype": "Time", "offset": 20656, "length": 4, "score": 0.8 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 20692, "length": 6, "score": 0.89 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 20733, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 20739, "length": 3, "score": 0.8 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 21218, "length": 3, "score": 0.8 }, { "text": "Xia", "type": "Person", "subtype": null, "offset": 21648, "length": 3, "score": 0.93 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 21659, "length": 4, "score": 0.8 }, { "text": "Mutual", "type": "Organization", "subtype": "Sports", "offset": 21756, "length": 6, "score": 0.56 }, { "text": "Rocchio", "type": "Person", "subtype": null, "offset": 22134, "length": 7, "score": 0.51 }, { "text": "Ana", "type": "Person", "subtype": null, "offset": 22214, "length": 3, "score": 0.95 }, { "text": "Arlindo", "type": "Person", "subtype": null, "offset": 22222, "length": 7, "score": 0.89 }, { "text": "2007", "type": "DateTime", "subtype": "DateRange", "offset": 22230, "length": 4, "score": 0.8 }, { "text": "Han", "type": "Person", "subtype": null, "offset": 22315, "length": 3, "score": 0.96 }, { "text": "Karypis", "type": "Person", "subtype": null, "offset": 22323, "length": 7, "score": 0.93 }, { "text": "2000", "type": "DateTime", "subtype": "DateRange", "offset": 22331, "length": 4, "score": 0.8 }, { "text": "Chuang", "type": "Person", "subtype": null, "offset": 22400, "length": 6, "score": 0.97 }, { "text": "2000", "type": "DateTime", "subtype": "DateRange", "offset": 22414, "length": 4, "score": 0.8 }, { "text": "Lertnattee", "type": "Person", "subtype": null, "offset": 22466, "length": 10, "score": 0.83 }, { "text": "Theeramunkong2004", "type": "Person", "subtype": null, "offset": 22481, "length": 17, "score": 0.8 }, { "text": "Hidayet", "type": "Person", "subtype": null, "offset": 22576, "length": 7, "score": 0.95 }, { "text": "Tunga", "type": "Person", "subtype": null, "offset": 22588, "length": 5, "score": 0.84 }, { "text": "2012", "type": "DateTime", "subtype": "DateRange", "offset": 22594, "length": 4, "score": 0.8 }, { "text": "Tan", "type": "Person", "subtype": null, "offset": 23211, "length": 3, "score": 0.59 }, { "text": "2006", "type": "DateTime", "subtype": "DateRange", "offset": 23256, "length": 4, "score": 0.8 }, { "text": "Guan", "type": "Person", "subtype": null, "offset": 23262, "length": 4, "score": 0.53 }, { "text": "2009", "type": "DateTime", "subtype": "DateRange", "offset": 23267, "length": 4, "score": 0.8 }, { "text": "Chizi", "type": "Person", "subtype": null, "offset": 23326, "length": 5, "score": 0.94 }, { "text": "2009", "type": "DateTime", "subtype": "DateRange", "offset": 23339, "length": 4, "score": 0.8 }, { "text": "Ozgur", "type": "Person", "subtype": null, "offset": 23492, "length": 5, "score": 0.94 }, { "text": "Gungor", "type": "Person", "subtype": null, "offset": 23502, "length": 6, "score": 0.84 }, { "text": "2009", "type": "DateTime", "subtype": "DateRange", "offset": 23509, "length": 4, "score": 0.8 }, { "text": "Shankar", "type": "Person", "subtype": null, "offset": 23529, "length": 7, "score": 0.92 }, { "text": "Karypis", "type": "Person", "subtype": null, "offset": 23541, "length": 7, "score": 0.85 }, { "text": "2000", "type": "DateTime", "subtype": "DateRange", "offset": 23549, "length": 4, "score": 0.8 }, { "text": "Tan", "type": "Person", "subtype": null, "offset": 23555, "length": 3, "score": 0.95 }, { "text": "2005", "type": "DateTime", "subtype": "DateRange", "offset": 23566, "length": 4, "score": 0.8 }, { "text": "sep", "type": "DateTime", "subtype": "DateRange", "offset": 24099, "length": 3, "score": 0.8 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 24287, "length": 6, "score": 0.9 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 24328, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 24334, "length": 3, "score": 0.8 }, { "text": "SVM", "type": "Organization", "subtype": "Sports", "offset": 24488, "length": 3, "score": 0.7 }, { "text": "Brown", "type": "Person", "subtype": null, "offset": 24553, "length": 5, "score": 0.93 }, { "text": "1997", "type": "DateTime", "subtype": "DateRange", "offset": 24567, "length": 4, "score": 0.8 }, { "text": "Brown", "type": "Person", "subtype": null, "offset": 24799, "length": 5, "score": 0.94 }, { "text": "1997", "type": "DateTime", "subtype": "DateRange", "offset": 24812, "length": 4, "score": 0.8 }, { "text": "SVM", "type": "Organization", "subtype": "Sports", "offset": 24910, "length": 3, "score": 0.8 }, { "text": "Feldman", "type": "Person", "subtype": null, "offset": 25012, "length": 7, "score": 0.97 }, { "text": "2011", "type": "DateTime", "subtype": "DateRange", "offset": 25027, "length": 4, "score": 0.8 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 25445, "length": 3, "score": 0.8 }, { "text": "fall", "type": "DateTime", "subtype": "DateRange", "offset": 27395, "length": 4, "score": 0.8 }, { "text": "Katz", "type": "Person", "subtype": null, "offset": 27469, "length": 4, "score": 0.96 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 27483, "length": 4, "score": 0.8 }, { "text": "2013", "type": "DateTime", "subtype": "DateRange", "offset": 27497, "length": 4, "score": 0.8 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 27849, "length": 6, "score": 0.88 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 27890, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 27896, "length": 3, "score": 0.8 }, { "text": "Princeton University", "type": "Organization", "subtype": null, "offset": 28490, "length": 20, "score": 0.91 }, { "text": "Mohammad", "type": "Person", "subtype": null, "offset": 29252, "length": 8, "score": 0.96 }, { "text": "2011", "type": "DateTime", "subtype": "DateRange", "offset": 29270, "length": 4, "score": 0.8 }, { "text": "neighbors", "type": "PersonType", "subtype": null, "offset": 30292, "length": 9, "score": 0.75 }, { "text": "19Khan", "type": "Person", "subtype": null, "offset": 30865, "length": 6, "score": 0.87 }, { "text": "2016", "type": "DateTime", "subtype": "DateRange", "offset": 30906, "length": 4, "score": 0.8 }, { "text": "4:2", "type": "DateTime", "subtype": "Time", "offset": 30912, "length": 3, "score": 0.8 }, { "text": "reviewer", "type": "PersonType", "subtype": null, "offset": 32114, "length": 8, "score": 0.85 } ] }, { "@search.score": 1.2920933, "content": "\nRawnaque et al. Brain Inf. (2020) 7:10 \nhttps://doi.org/10.1186/s40708-020-00109-x\n\nREVIEW\n\nTechnological advancements \nand opportunities in Neuromarketing: \na systematic review\nFerdousi Sabera Rawnaque1*, Khandoker Mahmudur Rahman2, Syed Ferhat Anwar3, Ravi Vaidyanathan4, \nTom Chau5, Farhana Sarker6 and Khondaker Abdullah Al Mamun1,7\n\nAbstract \n\nNeuromarketing has become an academic and commercial area of interest, as the advancements in neural record-\ning techniques and interpreting algorithms have made it an effective tool for recognizing the unspoken response \nof consumers to the marketing stimuli. This article presents the very first systematic review of the technological \nadvancements in Neuromarketing field over the last 5 years. For this purpose, authors have selected and reviewed a \ntotal of 57 relevant literatures from valid databases which directly contribute to the Neuromarketing field with basic \nor empirical research findings. This review finds consumer goods as the prevalent marketing stimuli used in both \nproduct and promotion forms in these selected literatures. A trend of analyzing frontal and prefrontal alpha band sig-\nnals is observed among the consumer emotion recognition-based experiments, which corresponds to frontal alpha \nasymmetry theory. The use of electroencephalogram (EEG) is found favorable by many researchers over functional \nmagnetic resonance imaging (fMRI) in video advertisement-based Neuromarketing experiments, apparently due to \nits low cost and high time resolution advantages. Physiological response measuring techniques such as eye tracking, \nskin conductance recording, heart rate monitoring, and facial mapping have also been found in these empirical stud-\nies exclusively or in parallel with brain recordings. Alongside traditional filtering methods, independent component \nanalysis (ICA) was found most commonly in artifact removal from neural signal. In consumer response prediction and \nclassification, Artificial Neural Network (ANN), Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) \nhave performed with the highest average accuracy among other machine learning algorithms used in these litera-\ntures. The authors hope, this review will assist the future researchers with vital information in the field of Neuromarket-\ning for making novel contributions.\n\nKeywords: Neuromarketing, Neural recording, Machine learning algorithm, Brain computer interface, Marketing\n\n© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material \nin this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material \nis not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the \npermitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat iveco \nmmons .org/licen ses/by/4.0/.\n\n1 Introduction\nNeuromarketing, an application of the non-invasive \nbrain–computer interface (BCI) technology, has emerged \nas an interdisciplinary bridge between neuroscience and \nmarketing that has changed the perception of market-\ning research. Marketing is the channel between prod-\nuct and consumers which determines the ultimate sale. \n\nWithout effective marketing, a good product fails to \ninform, engage and sustain its targeted audiences [1]. \nThe expanding economy with new businesses is continu-\nously evolving with changing consumer preferences. It \nis hard for the businesses to grow and sustain without \nhaving quantitative or qualitative assessment from their \nconsumers. Newly launched products need even more \neffective marketing to successfully enter into a com-\npetitive market. However, traditional marketing renders \nonly by posteriori analysis of consumer response. Con-\nventional market research depends on surveys, focus \n\nOpen Access\n\nBrain Informatics\n\n*Correspondence: frawnaque@umassd.edu\n1 Advanced Intelligent Multidisciplinary Systems Lab, Institute \nof Advanced Research, United International University, Dhaka, Bangladesh\nFull list of author information is available at the end of the article\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40708-020-00109-x&domain=pdf\n\n\nPage 2 of 19Rawnaque et al. Brain Inf. (2020) 7:10 \n\ngroup discussion, personal interviews, field trials and \nobservations for collecting consumer feedback [2]. These \napproaches have the limitations of time requirement, \nhigh cost and unreliable information, which can often \nproduce inaccurate results. In contrast to the traditional \nmarketing research techniques, Neuromarketing allows \ncapturing consumers’ unspoken cognitive and emotional \nresponse to various marketing stimuli and can forecast \nconsumers’ purchase decisions.\n\nNeuromarketing uses non-invasive brain signal record-\ning techniques to directly measure the response of a \ncustomer’s brain to the marketing stimuli, supersed-\ning the traditional survey methods [3]. Functional mag-\nnetic resonance (fMRI), electroencephalography (EEG), \nmagnetoencephalography (MEG), transcranial mag-\nnetic stimulator (TMS), positron emission tomography \n(PET), functional near-infrared spectroscopy (fNIRS) etc. \nare some examples of neural recording devices used in \nNeuromarketing research. By obtaining neuronal activ-\nity from the brain using these devices, one can explore \nthe cognitive and emotional responses (i.e., like/dislike, \napproach/withdrawal) of a customer. Different stimuli \ntrigger associated response in a human brain and the \nresponse can be tracked by monitoring the change in \nneuronal signals or brainwaves [4]. Further, the signal \nand image processing techniques and machine learning \nalgorithms have enabled the researchers to measure, ana-\nlyze and interpret the possible meanings of brainwaves. \nThis opens a new door to detect, analyze and predict \nthe buying behavior of customers in marketing research. \nNow with the help of brain–computer interface, the men-\ntal states of a customer, i.e., excitement, engagement, \nwithdrawal, stress, etc., while experiencing a market-\ning stimuli can be captured [5]. Besides these brain sig-\nnal recording techniques, Neuromarketing also utilizes \nphysiological signals, i.e., eye tracking, heart rate and \nskin conductance measurements to gather the insight of \naudience’s physiological responses due to encountering \nstimuli. These neurophysiological signals with advanced \nspectral analysis and machine learning algorithms can \nnow provide nearly accurate depiction of consumers’ \npreferences and likes/dislikes [6–8].\n\nEarly years of Neuromarketing generated a contro-\nversy between the academician and the marketers due \nto its high promises and lack of groundwork. From \nthe claim of peeping into the consumer mind to find-\ning the buy buttons of human brain, Neuromarketing \nhas long been under the scrutiny of the academicians \nand researchers [9, 10]. However, academic research in \nthis field has started to pile up and the scope of Neuro-\nmarketing to reveal and predict consumer behavior is \ngradually becoming evident. Neuromarketing Science \nand Business Association (NMSBA) was established \n\nin 2012 to bridge the gap between academicians and \nNeuromarketers, and it is promoting Neuromarket-\ning research across the world with its annual event of \nNeuromarketing World Forum [11, 12]. It may be pro-\nposed that further dialogue may continue under such a \nplatform for further industry–academia collaboration. \nEvidently, more than 150 consumer neuroscience com-\npanies are commercially operating across the globe and \nbig brands (Google, Microsoft, Unilever, etc.) are using \ntheir insights to impact their consumers in a tailored and \nefficient way. Academic research, especially the high ana-\nlytical accuracy from the engineering part of Neuromar-\nketing has garnered this breakthrough and acceptance \nover the world. Hence, reviewing the building blocks of \nNeuromarketing is essential to evaluate its scopes and \ncapacities, and to contribute new perspective in this \nfield. Numerous literature reviews have been published \nfocusing the theoretical aspect of consumer neurosci-\nence, such as marketing, business ethics, management, \npsychology, consumer behavior, etc. [13–15]. However, \nsystematic literature review from the engineering per-\nspective with a focus on neural recording tools and inter-\npretational methodologies used in this field is absent. In \nthis regard, our article sets its premises to answer the fol-\nlowing questions:\n\n– What are the types of marketing stimuli currently \nbeing used in Neuromarketing?\n\n– What are the brain regions activated by these mar-\nketing stimuli?\n\n– What is the best brain signal recording tool currently \nbeing used in Neuromarketing research?\n\n– How are these brain signals preprocessed for further \nanalysis?\n\n– And what are the current methods or techniques \nused to interpret these brain signals?\n\nThese questions will allow us to gain a comprehensive \nknowledge on the up-to-date research scopes and tech-\nniques in consumer neuroscience. After this brief intro-\nduction, our methodology of conducting this systematic \nreview will be presented, followed by the state-of-the-art \nfindings corresponding to the aforementioned questions \nand synthesis of the important results. We concluded this \nreview with relevant inference from synthesized result \nand a recommendation for future researchers.\n\n2 Methodology\nThe systematic literature review is a process in which \na body of literature is collected, screened, selected, \nreviewed and assessed with a pre-specified objective for \nthe purpose of unbiased evidence collection and to reach \nan impartial conclusion [16]. Systematic review has the \n\n\n\nPage 3 of 19Rawnaque et al. Brain Inf. (2020) 7:10 \n\nobligation to explicitly define its research question and to \naddress inclusion–exclusion criteria for setting the scope \nof the investigation. After exhaustive search of existing \nliteratures, articles should be selected based on their rel-\nevance, and the results of the selected studies must be \nsynthesized and assessed critically to achieve clear con-\nclusions [16].\n\nIn this systematic review, we would like to explore \nthe marketing stimuli used in Neuromarketing research \narticles over the last 5 years with their triggered brain \nregions. We would also like to focus on the technologi-\ncal tools used to capture brain signals from these regions, \nand finally deliberate on signal processing and analytical \nmethodologies used in these experiments.\n\nTherefore, the inclusion criteria defined here are  as \nfollows:\n\n– Literatures must be published in the field of Neuro-\nmarketing from 2015 to 2019.\n\n– Studies must use brain–computer interface and/or \nother physiological signal recording device in their \nNeuromarketing experiments.\n\n– Studies must have experimental findings from neu-\nral and/or biometric data used in Neuromarketing \nresearch.\n\nThe exclusion criteria for this review are set as:\n\n– Any other literature review on Neuromarketing are \nexcluded from this review.\n\n– Book chapters are excluded from this review. Since \nNeuromarketing is comparatively a new research \nfield, alongside relevant academic journal articles, \nbook chapters conducting empirical experiments \nusing BCI can only be included.\n\n– Literatures written/published in any language other \nthan English are excluded from this article.\n\nTo serve the purpose of this systematic literature \nreview, a total of 931 articles were found across the \n\ninternet by using the search item “Neuromarketing” \nand “Neuro-marketing” in valid databases. Among the \nscreened publications, Table  1 presents the database \nsource of selected 57 research articles including book \nchapters, which directly contribute to the Neuromarket-\ning field with basic or empirical research findings.\n\nAs for the aggregation of relevant existing literatures, \nthe researchers defined that the search for articles would \nbe performed in six databases—Science Direct, Emer-\nald Insight, Sage, IEEE Xplore, Wiley Online Library, \nand Taylor Francis Online. After the initial article accu-\nmulation, the articles were exhaustively screened by \nthe authors by reviewing their title, abstract, keywords \nand scope to match the objective of this research. Once \nthe studies met our aforementioned inclusion criteria, \nthey were selected for further review and critical analy-\nsis. Table 2 classifies the selected articles in terms of the \naforementioned dimensions.\n\nBy exploring the articles selected to develop this sys-\ntematic review, it was possible to successfully categorize \nthe trends and advancements in Neuromarketing field in \nfollowing dimensions:\n\n i. Marketing stimuli used in Neuromarketing \nresearch\n\n ii. Activation of the brain regions due to marketing \nstimuli\n\n iii. Neural response recording techniques\n iv. Brain signal processing in Neuromarketing\n v. Machine learning applications in Neuromarketing.\n\nSome of these Neuromarketing studies have used \neye tracking, heart rate, galvanic skin response, facial \naction coding, etc., with or without brain signal \nrecording techniques to gauge the consumer’s hidden \nresponse. As they are the response from autonomous \nnervous system (ANS), they have proven themselves \nas successful means of exploring consumer’s focus, \narousal, attention and withdrawal actions. Hence, this \nstudy includes articles those empirically used these \n\nTable 1 Number of articles found and selected\n\nName of the database Results: search “Neuromarketing” Results: search “Neuro-marketing” Articles selected\n\nScience direct 281 55 12\n\nWiley online 111 11 7\n\nEmerald insight 115 8 14\n\nIEEE 34 0 14\n\nSage 12 15 6\n\nTaylor Francis online 106 36 4\n\nTotal found: 806 Total found: 125 Total selected: 57\n\n\n\nPage 4 of 19Rawnaque et al. Brain Inf. (2020) 7:10 \n\ntools to answer Neuromarketing questions, since this \nstudy mainly focuses on the engineering perspective. \nInterpreting the neural data with only statistical analy-\nsis has been out of scope of this paper.\n\n3 Systematic review on the advancements \nof Neuromarketing\n\nNeuromarketing research utilizes marketing strategies in \nthe form of stimuli, and aims to invoke, capture and ana-\nlyze activities occurring in different brain regions while \n\nTable 2 Studies selected on the dimensions of this review\n\nDimensions Published articles\n\ni. Marketing stimuli used in Neuromarketing Product Chew et al. [17], Yadava et al. [18], Rojas et al. [19], Pozharliev [20], Touchette \nand Lee [21], Marques et al. [22], Shen et al. [23], Çakir et al. [24], Hubert \net al. [25], Hsu and Chen et al. [26], Hoefer et al. [27], Gurbuj and Toga [28], \nWriessnegger et al. [29], Wang et al. [30], Wolfe et al. [31], Bosshard et al. [32], \nFehse et al. [33].\n\nPrice Çakar et al. [34], Marques et al. [22], Çakir et al. [24], Gong et al. [35], Pilelienė \nand Grigaliūnaitė [36], Hsu and Chen [26], Boccia et al. [37], Venkatraman \net al. [38], Baldo et al. [39].\n\nPromotion Soria Morillo et al. [40], Yang et al. [41], Cherubino et al. [42], Soria Morillo \net al. [43], Vasiljević et al. [44], Yang et al. [45], Pilelienė and Grigaliūnaitė \n[36], Daugherty et al. [46], Royo et al. [47], Etzold et al. [48], Chen et al. \n[49], Casado-Aranda et al. [50], Randolph and Pierquet [51], Nomura and \nMitsukura [52], Ungureanu et al. [53], Goyal and Singh [54], Oon et al. [55], \nSingh et al. [56].\n\nii. Activation of brain region due to marketing stimuli Soria Morillo et al. [40], Chew et al. [17], Cherubino et al. [42], Soria Morillo \net al. [43], Çakar et al. [34], Boksem and Smitds [57], Bhardwaj et al. [58], Ven-\nkatraman et al. [38], Touchette and Lee [21], Yang et al. [45], Marques et al. \n[22], Gong et al. [35], Gordon et al. [59], Krampe et al. [60], Hubert et al. [25], \nÇakir et al. [24], Holst and Henseler [61], Hsu and Cheng [62], Hoefer et al. \n[27], Chen et al. [49], Casado-Aranda et al. [50], Wang et al. [30], Jain et al. \n[63], Wolfe et al. [31], Bosshard et al. [32], Fehse et al. [33].\n\niii. Neural response recording techniques EEG Soria Morillo et al. [40], Yang et al. [41], Chew et al. [17], Cherubino et al. [42], \nSoria Morillo et al. [43], Yadava et al. [18], Doborjeh et al. [64], Çakar et al. \n[34], Kaur et al. [65], Baldo et al. [19], Boksem and Smitds [57], Pozharliev \net al. [20], Venkatraman [38], Touchette and Lee [21], Yang et al. [45], Pilelienė \nand Grigaliūnaitė [36], Shen et al. [23], Daugherty et al. [46], Royo et al. [47], \nGong et al. [35], Gordon et al. [59], Hsu and Chen et al. [26], Hoefer et al. [27], \nRandolph and Pierquet [51], Nomura and Mitsukura [52], Bhardwaj et al. \n[58], Fan and Touyama [66], Rakshit and Lahiri [67], Jain et al. [63],Ogino and \nMitsukura [68], Oon et al. [55], Bosshard et al. [32].\n\nfMRI Venkatraman et al. [38], Marques et al. [22], Hubert et al. [25], Hsu and Cheng \n[62], Chen et al. [49], Casado-Aranda et al. [50], Wang et al. [30], Wolfe et al. \n[31], Fehse et al. [33].\n\nfNIRS Çakir et al. [24], Krampe et al. [60].\n\nEMG Missagila et al. [69]\n\nEye tracking Venkatraman [38], Rojas et al. [19], Pilelienė and Grigaliūnaitė [36], Çakar et al. \n[34], Ceravolo et al. [70], Ungureanu et al. [53]\n\nGalvanic skin \nresponse, \nheart rate\n\nCherubino et al. [42], Çakar et al. [34], Magdin et al. [71], Goyal and Singh [54], \nSingh et al. [56].\n\niv. Brain signal processing in Neuromarketing Cherubino et al. [42], Bhardwaj et al. [53], Venkatraman [38], Pozharliev et al. \n[20], Boksem and Smitds [57], Wriessnegger et al. [29], Fan and Touyama \n[66], Pilelienė and Grigaliūnaitė [36], Yadava et al. [18], Baldo et al. [19], \nClerico et al. [72], Chen et al. [49], Casado-Aranda et al. [50], Hsu and Cheng \n[62], Taqwa et al. [73], Bhardwaj et al. [58],Wang et al. [30], Rakshit and Lahiri \n[67], Goyal and Singh [54], Jain et al. [63], Oon et al. [55], Fehse et al. [33],\n\nv. Machine learning applications in Neuromarketing Soria Morillo et al. [40], Yang et al. [41], Chew et al. [17], Soria Morillo et al. [43], \nYadava et al. [18], Doborjeh et al. [64], Gordon [59], Gurbuj and Toga [28], \nWriessnegger et al. [29], Wang et al. [30], Taqwa et al. [73], Bhardwaj et al. \n[58], Randolph and Pierquet [51], Fan and Touyama [66], Rakshit and Lahiri \n[67], Goyal and Singh [54], Jain et al. [63], Ogino and Mitsukura [68], Oon \net al. [55], Singh et al. [56].\n\n\n\nPage 5 of 19Rawnaque et al. Brain Inf. (2020) 7:10 \n\nsubjects experience these stimuli. To conduct a system-\natic review on this matter, it is important to recall the \ninterconnection between brain functions with human \nbehavior and actions triggered by the  external stimuli. \nThe knowledge of brain anatomy and the physiologi-\ncal functions of brain areas as well as the physiological \nresponse due to external stimuli along with it, makes \nit possible to model brain activity and predict hidden \nresponse. For this purpose, current neural imaging sys-\ntems and neural recording systems have contributed \nmuch to capture the true essence of consumer prefer-\nences. This section will discuss the marketing stimuli, \ntheir targeted brain regions, neural and physiological \nsignal capturing technologies used over the last 5 years \nin Neuromarketing research. Comparing these signals \nwith their associated anatomical functionality some stud-\nies have already reached high accuracy. A number of the \nselected studies have used machine learning techniques \nto predict like/dislike and possible preference from the \ntest subjects.\n\nFor the purpose of Neuromarketing experiments, the \nfollowing literatures selected right-handed participants, \nwith normal or corrected-to-normal vision, free of cen-\ntral nervous system influencing medications and with no \nhistory of neuropathology.\n\n3.1 Marketing stimuli used in Neuromarketing\nAs Neuromarketing is a focus of marketers and consumer \nbehavior researchers, different strategies from market-\ning have been applied in Neuromarketing and they are \nbeing investigated for quantitative assessment from neu-\nrological data. Nemorin et al. asserts that Neuromarket-\ning differentiates from any other marketing models as \nit bypasses the thinking procedures of consumers and \ndirectly enters their brain [74]. Over the last 5  years, \nNeuromarketing stimuli has been mainly in two forms—\nproducts with/without price, and promotions. Product \ncan be defined as physical object or service that meets \nthe consumer demand. In Neuromarketing, product can \nbe physical such as tasting a beverage to conceptual like \na 3D (three dimensional) image of the product. Price in \nNeuromarketing experiments is mostly seen as a stimuli \nis most of the time intermingled with product or pro-\nmotion. However, it plays an important role that deter-\nmines the decision of test subjects to buy or not to buy \nthe product [75].\n\nConsumer response to a product has been recognized \nby either physically experiencing the product or by visu-\nalizing the image of  it. To understand the user esthetics \nof 3D shapes, Chew et  al. [17], used virtual 3D bracelet \nshapes in motion and recorded the brain response of \ntest subjects with EEG with motion. As 3D visualiza-\ntion of objects for preference recognition is a new area \n\nof research, the authors used mathematical model (Gie-\nlis superformula) to create 3D bracelet-like objects. \nTheir study displayed 3D shapes appear like bracelets as \nthe product to subjects. Using the 3D shapes gave the \nauthors an advantage to produce as many of 60 bracelet \nshapes to conduct the research on. Another new prod-\nuct was the E-commerce products presented to the test \nsubjects by Yadava et al. and Çakar et al. [18, 34]. Yadava \net  al. proposed a predictive modeling framework to \nunderstand consumer choice towards E-commerce prod-\nucts in terms of “likes” and “dislikes” by analyzing EEG \nsignals. In showing E-commerce product, they showed a \ntotal of 42 product images to the test participants. These \nproduct images were mainly of apparels and accessory \nitems such as shirts, sweaters, shoes, school bags, wrist \nwatches, etc. The test participants were asked to disclose \ntheir preference in terms of likes and dislikes after view-\ning the items  [18]. Çakar et  al. used both product and \nprice to explore the experience during product search of \nfirst-time buyers in E-commerce. To motivate the partici-\npants, this research provided each participants around \n73 USD as a gift card to use during the experiment. The \ntest participants were asked to search and select three \nproducts of their interest from an e-commerce website \nand reach the maximum of their gift card limit to acti-\nvate. Test subjects often experienced negative emotion \nwhile being unable to find necessary buttons such as “add \nto cart” or “sorting options” [34]. These Neuromarketing \nexperiments on E-commerce products may help develop-\ners to build better user experience. Retail businesses lose \nlarge amount of money when they invest in the wrong \nproduct. Among retail products, shoes have thousands \nof blueprints for manufacturing. Producing thousands \nof shoes of different designs to satisfy consumers can be \nlaborious and unprofitable since a large number of the \ndesigns turn out to be failures. Baldo et al. directly used \n30 existing image of shoe designs to show the test sub-\njects to and to choose from a mock shop showing on the \nscreen [39]. EEG signals were recorded during the whole \nshoe selection time and then subjects were asked to rate \nthe shoes in a rank of 1 to 5 of Likert scale. This experi-\nment helped realize brain response-based prediction can \nsupersede self-report-based methods, as the simulation \non sales data showed 12.1% profit growth for survey-\nbased prediction, and 36.4% profit growth for the brain \nresponse-based prediction.\n\nSimilar to the shoe experiment, Touchette and Lee [21] \nexperimented on the choice of apparel products among \nyoung adults, based on Davidson’s frontal asymmetry \ntheory. EEG signals were recorded while 34 college stu-\ndents viewed three attractive and three unattractive \napparel products on a high-resolution computer screen \nin a random order. Pozharliev et  al. [20] experimented \n\n\n\nPage 6 of 19Rawnaque et al. Brain Inf. (2020) 7:10 \n\non the emotion associated with visualizing luxury brand \nproducts vs. regular brand products. The experiment dis-\nplayed 60 luxury items and 60 basic brand items to 40 \nfemale undergraduate students to recognize the brain \nresponse of seeing high emotional value (luxury) prod-\nucts in social vs. alone atmosphere. The study found \nthat, luxury brand products invoked a higher emotional \nvalue in social atmosphere which could be utilized by the \nmarketers. Bosshard et al. and Fehse et al. experimented \non brand images and the comparison between the brain \nresponses associated with preferred and not preferred \nbrands [32, 33]. In the study performed by Bosshard et al., \nconsumer attitude towards established brand names were \nmeasured via electroencephalography. Subjects were \nshown 120 brand names in capital white letter in Tahoma \nfont on black background and without any logo while \ntheir brain responses were recorded. On the other hand, \nFehse et al. compared the brain response of test subjects \nwhile they visualized blocks of popular vs. organic food \nbrand logos. These experiments on brand image may help \nmarketers to recognize the implicit response of consum-\ners on different types of branding.\n\nAs price is mentioned as an important factor that \ndetermines the user’s interest on purchasing a product, \na number of Neuromarketing studies have used price \nalongside the products. In the aforementioned study \nby Çakar et  al. [34] price was displayed while recording \nbrain response during first-time e-commerce user expe-\nrience. Marques et al. [22], Çakir et al. [24], Gong et al. \n[35], Pilelienė and Grigaliūnaitė [36], Hsu and Chen [26], \nBoccia et al. [37], Venkatraman et al. [38], and Baldo et al. \n[39] have included price as a marketing stimuli with the \nproduct or promotional.\n\nAn interesting concept was tried by Boccia et  al. to \nrecognize the relation between corporate social respon-\nsibilities and consumer behavior. The author attempted \nto identify if consumers were willing to pay more for the \nproducts from socially or environmentally responsible \ncompany. Consumers were found to prefer the conven-\ntional companies over the socially responsible companies \ndue to lesser price. Marques et  al. [22] investigated the \ninfluence of price to compare national brand vs. own-\nlabeled branded products. In the experiment of Çakir \net  al, product then product and price were shown to \nthe subjects before decision-making time and the brain \nresponses were recorded through fNIRS [24]. Sometimes \nprice can play a passive role in the form of discounts or \ngifts in a promotional. Gong et al. innovatively designed \nan experiment to compare consumer brain response \nassociated with promotional using discount (25% off) vs. \ngift-giving (gift value equivalent to the discount) mar-\nketing strategies. Their study found that lower degree of \nambiguity (e.g., discounts) better motivates consumer \n\ndecision-making [35]. Hsu and Chen used price as a con-\ntrol variable in their wine tasting experiment. As price \nplays a pivotal role in purchase decision, two wines were \nselected of approximately equal price $15. Then the EEG \nsignals of test subjects were recorded during the wine \ntasting session [26].\n\nPromotion is the communication from the marketers’ \nend to influence the purchase decision of consumers [75]. \nIn Neuromarketing research, promotion is usually found \nas the TV commercials and short movies for advertise-\nment. One of the key focus of Neuromarketers is to \nevaluate the consumer engagement of advertisements. \nPredicting the engagement of advertisements before \nbroadcasting them on air, ensures higher rate of success-\nful promotions.\n\nIn 2015, Yang et al. used six smartphone commercials \nof different brands to compare among them in terms \nof extract cognitive neurophysiological indices such as \nhappiness, surprise, and attention as well as behavio-\nral indices (memory rate, preference, etc.) [41]. A com-\nmon experimental design procedure is found among the \npromotion-based Neuromarketing experiments, that is \nsubjects are first made comfortable in the experimental \nsetting, consecutive advertisements were placed at a time \ndistance no shorter than 10 s and consecutive advertise-\nments used neutral stimuli such as white screen, green \nscenario, blank in between them to stabilize the test \nparticipants.\n\nThe Neuromarketing experiments of Soria Morillo \net  al. [40, 43] tried to find out the electrical activity of \naudience brain while viewing advertisement relevant to \naudiences’ taste. They display used 14 TV commercials \ndisplayed to their 10 test subjects for their experiment \nand predicted like or dislike response from audience \nwith the help of advanced algorithms. Cherubino et  al. \n[42] investigated cognitive and emotional changes of \ncerebral activity during the observation of TV commer-\ncials among different aged population. Among seven TV \ncommercials displayed during the experiment, one com-\nmercial with strong images was analyzed for the adults’ \nand older adults’ reaction. Other than them, Vasiljević \net  al. [44] used Nestle advertisement to measure con-\nsumer attention though pulse analysis; Daugherty et  al. \n[46] replicated an experiment of Krugman (1971) using \nboth TV advertisements and print media advertise-\nments to recognize how consumers look and think; Royo \net  al. [47] focused on consumer response while viewing \nadvertisements of sustainable product designs. For their \nexperiment, an animated commercial was made contain-\ning verbal narrative of sustainable product and an exist-\ning commercial was used to convey the visual narrative \nof conventional product. Venkatraman  et al. focused \non measuring the success of TV advertisements using \n\n\n\nPage 7 of 19Rawnaque et al. Brain Inf. (2020) 7:10 \n\nneuroimaging and biometric data  [38]. Randolph and \nPierquet [51] showed super bowl commercials to under-\ngraduate students to compare the class rank of the com-\nmercials and the neural response from the test subjects. \nNomura and Mitsukura [52] identified emotional states \nof audiences while watching favorable vs. unfavorable TV \ncommercials. They selected 100 TV commercials among \nwhich 50 commercials were award winning which were \nlabeled as favorable advertisements. Singh et al. [56] used \npromotion in the form of static vs. video advertisements \nto predict the success of omnichannel marketing strate-\ngies. Ungureanu et al. [53] measured user attention and \narousal by eye tracking while surfing through web page \ncontaining static advertisements, while Goyal and Singh \n[54] utilized facial biometric sensors to model an auto-\nmated review systems for video advertisements. Oon \net al. [55] used merchandise product advertisement clips \nto recognize user preference. Singh et al. [56] used video \nadvertisements to measure visual attentions of audiences.\n\nMost of the TVC (television commercials) in these lit-\neratures had a standard time of 30 s. In Neuromarketing, \nthese TVCs were displayed in between other videos such \nas documentary film, gaming video, drama, etc., to cap-\nture the true response of consumers.\n\nSometimes Neuromarketing  is observed dealing with \nadvertisement of different purposes, such as social adver-\ntisements or gender-related advertisements. The appli-\ncation of Neuromarketing in social advertisement is to \npredict the success of these ads to reach its messages to \nthe targeted social groups [45, 49, 69]. Chen et  al. [49] \nexperimented on the neural response of adolescent audi-\nences while they are exposed to e-cigarette commercials. \nAnother social advertisement stimuli of smoking cessa-\ntion frames was used by Yang [45], to understand what \ntypes of frames (positive/negative) achieve better atten-\ntion from smokers and non-smokers. Gender plays a \nsubstantial role in advertisement industry from celebrity \nendorsement to gender-targeted marketing. Missaglia \net  al. [69] conducted a research o", "metadata_storage_path": "aHR0cHM6Ly9rYm1zdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9wYXBlcnMvczQwNzA4LTAyMC0wMDEwOS14LnBkZg2", "metadata_author": "Ferdousi Sabera Rawnaque ", "metadata_title": "Technological advancements and opportunities in Neuromarketing: a systematic review", "metadata_creation_date": "2020-09-18T02:02:41Z", "people": [ "Rawnaque", "Ferdousi Sabera Rawnaque1", "Khandoker Mahmudur Rahman", "Syed Ferhat Anwar", "Ravi Vaidyanathan", "Tom Chau", "Farhana Sarker6", "Khondaker Abdullah Al Mamun", "Taylor Francis", "Yadava", "Rojas", "Pozharliev", "Lee", "Marques", "Shen", "Çakir", "Hubert", "Hsu", "Chen", "Hoefer", "Gurbuj", "Toga", "Wriessnegger", "Wang", "Wolfe", "Bosshard", "Fehse", "Price Çakar", "Gong", "Pilelienė", "Grigaliūnaitė", "Boccia", "Venkatraman", "Baldo", "Yang", "Cherubino", "Vasiljević", "Daugherty", "Royo", "Etzold", "Casado-Aranda", "Randolph", "Pierquet", "Nomura", "Mitsukura", "Ungureanu", "Goyal", "Singh", "Oon", "Soria Morillo", "Chew", "Çakar", "Boksem", "Smitds", "Bhardwaj", "katraman", "Touchette", "Gordon", "Krampe", "Holst", "Henseler", "Cheng", "Jain", "Doborjeh", "Kaur", "Fan", "Touyama", "Rakshit", "Lahiri", "Ogino", "Missagila", "Ceravolo", "Magdin", "Clerico", "Taqwa", "Nemorin", "Davidson", "Krugman", "Missaglia" ], "organizations": [ "Creative Commons", "iveco", "Institute \nof Advanced Research", "United International University", "Functional mag", "and Business Association", "NMSBA", "Google", "Microsoft", "Unilever", "Neuromar", "Neuromarket", "Science Direct", "Emer", "IEEE", "Wiley Online Library", "Taylor Francis Online", "Science", "Wiley", "Soria Morillo", "Nestle" ], "locations": [ "Dhaka", "Bangladesh", "field", "mock shop", "college", "Tahoma" ], "keyphrases": [ "Creative Commons Attribution 4.0 International License", "Khondaker Abdullah Al Mamun", "high time resolution advantages", "Physiological response measuring techniques", "consumer emotion recognition-based experiments", "other third party material", "neural record- ing techniques", "video advertisement-based Neuromarketing experiments", "other machine learning algorithms", "Creative Commons licence", "Support Vector Machine", "Ferdousi Sabera Rawnaque1", "Khandoker Mahmudur Rahman", "Syed Ferhat Anwar", "empirical research findings", "magnetic resonance imaging", "heart rate monitoring", "traditional filtering methods", "independent component analysis", "Linear Discriminant Analysis", "highest average accuracy", "market- ing research", "consumer response prediction", "Artificial Neural Network", "prefrontal alpha band", "skin conductance recording", "Brain computer interface", "brain–computer interface", "prevalent marketing stimuli", "first systematic review", "Neural recording", "unspoken response", "Neuromarket- ing", "consumer goods", "neural signal", "consumer preferences", "Brain Inf.", "brain recordings", "doi.org", "Ravi Vaidyanathan", "Tom Chau", "Farhana Sarker6", "commercial area", "last 5 years", "valid databases", "promotion forms", "asymmetry theory", "many researchers", "low cost", "eye tracking", "facial mapping", "artifact removal", "future researchers", "vital information", "novel contributions", "The Author", "appropriate credit", "original author", "credit line", "statutory regulation", "copyright holder", "creat iveco", "BCI) technology", "interdisciplinary bridge", "ultimate sale", "targeted audiences", "expanding economy", "effective marketing", "57 relevant literatures", "intended use", "permitted use", "good product", "new businesses", "Neuromarketing field", "Technological advancements", "opportunities", "Abstract", "academic", "interest", "interpreting", "tool", "consumers", "article", "purpose", "authors", "total", "basic", "trend", "nals", "electroencephalogram", "EEG", "functional", "fMRI", "parallel", "classification", "ANN", "SVM", "LDA", "Keywords", "sharing", "adaptation", "distribution", "reproduction", "medium", "source", "link", "changes", "images", "permission", "1 Introduction", "application", "invasive", "neuroscience", "perception", "changing", "non-invasive brain signal record- ing techniques", "1 Advanced Intelligent Multidisciplinary Systems Lab", "transcranial mag- netic stimulator", "Functional mag- netic resonance", "Open Access Brain Informatics", "market- ing stimuli", "image processing techniques", "nal recording techniques", "functional near-infrared spectroscopy", "com- petitive market", "United International University", "positron emission tomography", "machine learning algorithms", "skin conductance measurements", "neuronal activ- ity", "Different stimuli trigger", "marketing research techniques", "ventional market research", "traditional survey methods", "neural recording devices", "various marketing stimuli", "consumers’ purchase decisions", "Neuromarketing World Forum", "Advanced Research", "neuronal signals", "human brain", "traditional marketing", "Neuro- marketing", "academic research", "qualitative assessment", "posteriori analysis", "Full list", "author information", "group discussion", "personal interviews", "consumer feedback", "time requirement", "high cost", "unreliable information", "inaccurate results", "possible meanings", "new door", "buying behavior", "tal states", "physiological signals", "heart rate", "physiological responses", "spectral analysis", "accurate depiction", "Early years", "contro- versy", "high promises", "consumer mind", "buy buttons", "consumer behavior", "Business Association", "annual event", "Neuromarketing research", "field trials", "unspoken cognitive", "emotional responses", "Neuromarketing Science", "consumer response", "associated response", "quantitative", "products", "surveys", "Correspondence", "frawnaque", "umassd", "Institute", "Dhaka", "Bangladesh", "end", "creativecommons", "licenses", "crossmark", "crossref", "org", "Page", "19Rawnaque", "observations", "approaches", "limitations", "contrast", "customer", "electroencephalography", "magnetoencephalography", "MEG", "TMS", "fNIRS", "examples", "withdrawal", "change", "brainwaves", "researchers", "help", "excitement", "engagement", "stress", "insight", "audience", "preferences", "likes", "academician", "marketers", "due", "lack", "groundwork", "claim", "scrutiny", "scope", "NMSBA", "gap", "dialogue", "other physiological signal recording device", "best brain signal recording tool", "address inclusion–exclusion criteria", "relevant academic journal articles", "neural recording tools", "industry–academia collaboration", "brief intro- duction", "unbiased evidence collection", "clear con- clusions", "Numerous literature reviews", "other literature review", "mar- keting stimuli", "date research scopes", "systematic literature review", "new research field", "signal processing", "inclusion criteria", "Academic research", "relevant inference", "new perspective", "brain signals", "cal tools", "systematic review", "research question", "brain regions", "150 consumer neuroscience", "big brands", "efficient way", "lytical accuracy", "building blocks", "theoretical aspect", "business ethics", "current methods", "tech- niques", "art findings", "synthesized result", "impartial conclusion", "exhaustive search", "experimental findings", "neu- ral", "biometric data", "Book chapters", "marketing stimuli", "empirical experiments", "engineering part", "pretational methodologies", "important results", "lowing questions", "Neuromarketing experiments", "platform", "panies", "globe", "Google", "Microsoft", "Unilever", "insights", "tailored", "breakthrough", "acceptance", "world", "capacities", "management", "psychology", "focus", "regard", "premises", "types", "analysis", "techniques", "comprehensive", "knowledge", "methodology", "state", "synthesis", "recommendation", "body", "objective", "obligation", "investigation", "existing", "literatures", "evance", "studies", "analytical", "BCI", "language", "English", "brain signal recording techniques", "Neural response recording techniques", "Brain signal processing", "relevant existing literatures", "Machine learning applications", "autonomous nervous system", "Neuromarket- ing field", "different brain regions", "galvanic skin response", "Wiley Online Library", "Neuromarketing Product Chew", "neural data", "3 Systematic review", "database source", "book chapters", "six databases", "Taylor Francis", "initial article", "critical analy", "action coding", "successful means", "withdrawal actions", "engineering perspective", "statistical analy", "lyze activities", "Price Çakar", "Grigaliūnaitė", "Soria Morillo", "marketing strategies", "Neuromarketing questions", "search item", "Science Direct", "IEEE Xplore", "Table 1 Number", "database Results", "Emerald insight", "Neuromarketing studies", "following dimensions", "Marketing stimuli", "Table 2 Studies", "57 research articles", "931 articles", "internet", "Neuro-marketing", "publications", "aggregation", "Sage", "mulation", "title", "abstract", "keywords", "sis", "terms", "trends", "advancements", "Activation", "facial", "consumer", "arousal", "attention", "study", "Name", "tools", "paper", "form", "Yadava", "Rojas", "Pozharliev", "Touchette", "Lee", "Marques", "Shen", "Çakir", "Hubert", "Hsu", "Chen", "Hoefer", "Gurbuj", "Toga", "Wriessnegger", "Wang", "Wolfe", "Bosshard", "Fehse", "al.", "Gong", "Pilelienė", "Boccia", "Venkatraman", "Baldo", "Promotion", "Yang", "Cherubino", "Vasiljević", "Daugherty", "Royo", "Etzold", "Casado-Aranda", "Randolph", "Pierquet", "Nomura", "Mitsukura", "Ungureanu", "Goyal", "Singh", "Oon", "neural recording systems", "signal capturing technologies", "heart rate Cherubino", "EEG Soria Morillo", "brain region", "brain functions", "brain anatomy", "brain areas", "brain activity", "EMG Missagila", "Eye tracking", "Galvanic skin", "atic review", "human behavior", "cal functions", "true essence", "anatomical functionality", "high accuracy", "external stimuli", "fNIRS Çakir", "Neuromarketing Cherubino", "fMRI Venkatraman", "Chew", "Çakar", "Boksem", "Smitds", "Bhardwaj", "Gordon", "Krampe", "Holst", "Henseler", "Cheng", "Jain", "Doborjeh", "Kaur", "Fan", "Touyama", "Rakshit", "Lahiri", "Ogino", "Ceravolo", "Magdin", "Clerico", "Taqwa", "subjects", "matter", "interconnection", "actions", "physiological", "hidden", "ences", "section", "targeted", "signals", "associated", "number", "3D (three dimensional) image", "machine learning techniques", "tral nervous system", "predictive modeling framework", "3D visualiza- tion", "other marketing models", "consumer behavior researchers", "E-commerce prod- ucts", "gift card limit", "virtual 3D bracelet", "30 existing image", "3D shapes", "consumer demand", "Consumer response", "consumer choice", "different strategies", "market- ing", "quantitative assessment", "rological data", "thinking procedures", "last 5  years", "two forms", "physical object", "important role", "user esthetics", "new area", "mathematical model", "lis superformula", "school bags", "first-time buyers", "partici- pants", "commerce website", "negative emotion", "necessary buttons", "sorting options", "Retail businesses", "large amount", "large number", "mock shop", "right-handed participants", "test participants", "different designs", "shoe designs", "E-commerce products", "retail products", "test subjects", "normal vision", "brain response", "user experience", "42 product images", "product search", "wrong product", "possible preference", "60 bracelet", "medications", "history", "neuropathology", "Nemorin", "price", "promotions", "service", "beverage", "decision", "objects", "recognition", "bracelets", "advantage", "apparels", "accessory", "items", "shirts", "sweaters", "shoes", "wrist", "watches", "view", "maximum", "money", "thousands", "blueprints", "manufacturing", "failures", "3.1", "corporate social respon- sibilities", "frontal asymmetry theory", "female undergraduate students", "capital white letter", "luxury) prod- ucts", "high emotional value", "higher emotional value", "shoe selection time", "high-resolution computer screen", "60 basic brand items", "wine tasting experiment", "regular brand products", "luxury brand products", "brain response-based prediction", "consumer brain response", "60 luxury items", "gift value", "brand images", "brand names", "brand logos", "national brand", "social atmosphere", "apparel products", "branded products", "shoe experiment", "EEG signals", "Likert scale", "self-report-based methods", "sales data", "12.1% profit growth", "36.4% profit growth", "young adults", "random order", "alone atmosphere", "brain responses", "consumer attitude", "Tahoma font", "black background", "other hand", "implicit response", "different types", "important factor", "interesting concept", "tional companies", "responsible companies", "decision-making time", "passive role", "keting strategies", "lower degree", "con- trol", "pivotal role", "purchase decision", "two wines", "lesser price", "rank", "simulation", "choice", "Davidson", "comparison", "brands", "blocks", "popular", "experiments", "branding", "user", "first-time", "promotional", "relation", "author", "company", "socially", "influence", "discounts", "gifts", "gift-giving", "ambiguity", "40", "mon experimental design procedure", "merchandise product advertisement clips", "wine tasting session", "older adults’ reaction", "mated review systems", "different aged population", "facial biometric sensors", "TV commer- cials", "six smartphone commercials", "super bowl commercials", "promotion-based Neuromarketing experiments", "The Neuromarketing experiments", "sustainable product designs", "seven TV commercials", "unfavorable TV commercials", "cognitive neurophysiological indices", "consecutive advertise- ments", "experimental setting", "conventional product", "14 TV commercials", "100 TV commercials", "different brands", "ral indices", "Nestle advertisement", "television commercials", "consecutive advertisements", "TV advertisements", "equal price", "short movies", "key focus", "higher rate", "ful promotions", "memory rate", "time distance", "neutral stimuli", "white screen", "green scenario", "electrical activity", "advanced algorithms", "emotional changes", "cerebral activity", "strong images", "pulse analysis", "print media", "animated commercial", "verbal narrative", "ing commercial", "visual narrative", "graduate students", "class rank", "emotional states", "visual attentions", "lit- eratures", "standard time", "video advertisements", "neural response", "consumer engagement", "audience brain", "web page", "user preference", "audiences’ taste", "user attention", "favorable advertisements", "static advertisements", "50 commercials", "communication", "Neuromarketers", "air", "extract", "happiness", "surprise", "10 s", "participants", "observation", "Krugman", "success", "neuroimaging", "gies", "TVC", "30 s", "other", "videos", "social adver- tisements", "social advertisement stimuli", "social groups", "documentary film", "gaming video", "true response", "different purposes", "gender-related advertisements", "appli- cation", "cigarette commercials", "smoking cessa", "atten- tion", "substantial role", "advertisement industry", "gender-targeted marketing", "tion frames", "drama", "Neuromarketing", "The", "ads", "messages", "smokers", "celebrity", "endorsement", "Missaglia", "research" ], "pii_entities": [ { "text": "Rawnaque", "type": "Person", "subtype": null, "offset": 1, "length": 8, "score": 0.96 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 40, "length": 4, "score": 0.8 }, { "text": "7:10", "type": "DateTime", "subtype": "Time", "offset": 46, "length": 4, "score": 0.8 }, { "text": "https://doi.org/10.1186/s40708-020-00109-x", "type": "URL", "subtype": null, "offset": 53, "length": 42, "score": 0.8 }, { "text": "Ferdousi Sabera Rawnaque1", "type": "Person", "subtype": null, "offset": 191, "length": 25, "score": 0.98 }, { "text": "Khandoker Mahmudur Rahman", "type": "Person", "subtype": null, "offset": 219, "length": 25, "score": 0.98 }, { "text": "Syed Ferhat Anwar", "type": "Person", "subtype": null, "offset": 247, "length": 17, "score": 0.99 }, { "text": "Ravi Vaidyanathan", "type": "Person", "subtype": null, "offset": 267, "length": 17, "score": 0.99 }, { "text": "Tom Chau", "type": "Person", "subtype": null, "offset": 288, "length": 8, "score": 0.99 }, { "text": "Farhana Sarker6", "type": "Person", "subtype": null, "offset": 299, "length": 15, "score": 0.99 }, { "text": "Khondaker Abdullah Al Mamun", "type": "Person", "subtype": null, "offset": 319, "length": 27, "score": 0.98 }, { "text": "consumers", "type": "PersonType", "subtype": null, "offset": 587, "length": 9, "score": 0.95 }, { "text": "last 5 years", "type": "DateTime", "subtype": "DateRange", "offset": 746, "length": 12, "score": 0.8 }, { "text": "authors", "type": "PersonType", "subtype": null, "offset": 778, "length": 7, "score": 0.94 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 1363, "length": 11, "score": 0.55 }, { "text": "authors", "type": "PersonType", "subtype": null, "offset": 2209, "length": 7, "score": 0.73 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 2258, "length": 11, "score": 0.83 }, { "text": "The Author", "type": "Organization", "subtype": null, "offset": 2470, "length": 10, "score": 0.66 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 2484, "length": 4, "score": 0.8 }, { "text": "author", "type": "PersonType", "subtype": null, "offset": 2730, "length": 6, "score": 0.92 }, { "text": "copyright holder", "type": "PersonType", "subtype": null, "offset": 3233, "length": 16, "score": 0.66 }, { "text": "consumers", "type": "PersonType", "subtype": null, "offset": 3634, "length": 9, "score": 0.64 }, { "text": "consumer", "type": "PersonType", "subtype": null, "offset": 3875, "length": 8, "score": 0.84 }, { "text": "consumers", "type": "PersonType", "subtype": null, "offset": 4015, "length": 9, "score": 0.79 }, { "text": "consumer", "type": "PersonType", "subtype": null, "offset": 4208, "length": 8, "score": 0.78 }, { "text": "frawnaque", "type": "Person", "subtype": null, "offset": 4336, "length": 9, "score": 0.59 }, { "text": "frawnaque@umassd.edu", "type": "Email", "subtype": null, "offset": 4336, "length": 20, "score": 0.8 }, { "text": "Advanced Intelligent Multidisciplinary Systems Lab", "type": "Organization", "subtype": null, "offset": 4359, "length": 50, "score": 0.8 }, { "text": "Institute", "type": "Organization", "subtype": "Sports", "offset": 4411, "length": 9, "score": 0.7 }, { "text": "United International University", "type": "Organization", "subtype": null, "offset": 4444, "length": 31, "score": 0.92 }, { "text": "http://creativecommons.org/licenses/by/4.0/", "type": "URL", "subtype": null, "offset": 4567, "length": 43, "score": 0.8 }, { "text": "http://creativecommons.org/licenses/by/4.0/", "type": "URL", "subtype": null, "offset": 4611, "length": 43, "score": 0.8 }, { "text": "http://crossmark.crossref.org/dialog/?doi=10.1186/s40708-020-00109-x&domain=pdf", "type": "URL", "subtype": null, "offset": 4655, "length": 79, "score": 0.8 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 4788, "length": 4, "score": 0.8 }, { "text": "7:10", "type": "DateTime", "subtype": "Time", "offset": 4794, "length": 4, "score": 0.8 }, { "text": "consumer", "type": "PersonType", "subtype": null, "offset": 4886, "length": 8, "score": 0.82 }, { "text": "consumers", "type": "PersonType", "subtype": null, "offset": 5250, "length": 9, "score": 0.89 }, { "text": "customer", "type": "PersonType", "subtype": null, "offset": 5390, "length": 8, "score": 0.77 }, { "text": "customer", "type": "PersonType", "subtype": null, "offset": 5967, "length": 8, "score": 0.97 }, { "text": "customers", "type": "PersonType", "subtype": null, "offset": 6405, "length": 9, "score": 0.96 }, { "text": "Now", "type": "DateTime", "subtype": null, "offset": 6439, "length": 3, "score": 0.8 }, { "text": "customer", "type": "PersonType", "subtype": null, "offset": 6511, "length": 8, "score": 0.94 }, { "text": "now", "type": "DateTime", "subtype": null, "offset": 7004, "length": 3, "score": 0.8 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 7413, "length": 11, "score": 0.94 }, { "text": "and Business Association", "type": "Organization", "subtype": null, "offset": 7629, "length": 24, "score": 0.89 }, { "text": "NMSBA", "type": "Organization", "subtype": null, "offset": 7655, "length": 5, "score": 0.91 }, { "text": "2012", "type": "DateTime", "subtype": "DateRange", "offset": 7683, "length": 4, "score": 0.8 }, { "text": "Neuromarket", "type": "Organization", "subtype": null, "offset": 7768, "length": 11, "score": 0.66 }, { "text": "annual", "type": "DateTime", "subtype": "Set", "offset": 7820, "length": 6, "score": 0.8 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 7917, "length": 3, "score": 0.8 }, { "text": "Google", "type": "Organization", "subtype": null, "offset": 8119, "length": 6, "score": 0.98 }, { "text": "Microsoft", "type": "Organization", "subtype": null, "offset": 8127, "length": 9, "score": 0.98 }, { "text": "Unilever", "type": "Organization", "subtype": "Medical", "offset": 8138, "length": 8, "score": 0.98 }, { "text": "Neuromar", "type": "Organization", "subtype": null, "offset": 8330, "length": 8, "score": 0.69 }, { "text": "consumer", "type": "PersonType", "subtype": null, "offset": 8739, "length": 8, "score": 0.62 }, { "text": "lowing", "type": "Person", "subtype": null, "offset": 9018, "length": 6, "score": 0.81 }, { "text": "mar", "type": "DateTime", "subtype": "DateRange", "offset": 9169, "length": 3, "score": 0.8 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 9931, "length": 11, "score": 0.88 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 10299, "length": 4, "score": 0.8 }, { "text": "7:10", "type": "DateTime", "subtype": "Time", "offset": 10305, "length": 4, "score": 0.8 }, { "text": "last 5 years", "type": "DateTime", "subtype": "DateRange", "offset": 10812, "length": 12, "score": 0.8 }, { "text": "from 2015 to 2019", "type": "DateTime", "subtype": "DateRange", "offset": 11203, "length": 17, "score": 0.8 }, { "text": "Science Direct", "type": "Organization", "subtype": null, "offset": 12524, "length": 14, "score": 0.75 }, { "text": "Emer", "type": "Organization", "subtype": null, "offset": 12540, "length": 4, "score": 0.61 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 12565, "length": 4, "score": 0.79 }, { "text": "Wiley", "type": "Organization", "subtype": "Sports", "offset": 12578, "length": 5, "score": 0.86 }, { "text": "Taylor Francis Online", "type": "Organization", "subtype": null, "offset": 12605, "length": 21, "score": 0.73 }, { "text": "281 55 12", "type": "PhoneNumber", "subtype": null, "offset": 14138, "length": 9, "score": 0.8 }, { "text": "Wiley", "type": "Organization", "subtype": "Sports", "offset": 14149, "length": 5, "score": 0.88 }, { "text": "Emerald insight", "type": "Organization", "subtype": null, "offset": 14172, "length": 15, "score": 0.88 }, { "text": "IEEE", "type": "Organization", "subtype": null, "offset": 14198, "length": 4, "score": 0.97 }, { "text": "Sage", "type": "Organization", "subtype": "Sports", "offset": 14212, "length": 4, "score": 0.92 }, { "text": "Taylor Francis", "type": "Person", "subtype": null, "offset": 14226, "length": 14, "score": 0.91 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 14365, "length": 4, "score": 0.8 }, { "text": "7:10", "type": "DateTime", "subtype": "Time", "offset": 14371, "length": 4, "score": 0.8 }, { "text": "Yadava", "type": "Person", "subtype": null, "offset": 14984, "length": 6, "score": 0.89 }, { "text": "Rojas", "type": "Person", "subtype": null, "offset": 15004, "length": 5, "score": 0.94 }, { "text": "Pozharliev", "type": "Person", "subtype": null, "offset": 15023, "length": 10, "score": 0.72 }, { "text": "Touchette", "type": "Person", "subtype": null, "offset": 15040, "length": 9, "score": 0.54 }, { "text": "Lee", "type": "Person", "subtype": null, "offset": 15055, "length": 3, "score": 0.94 }, { "text": "Marques et", "type": "Person", "subtype": null, "offset": 15065, "length": 10, "score": 0.73 }, { "text": "Shen", "type": "Person", "subtype": null, "offset": 15086, "length": 4, "score": 0.97 }, { "text": "Çakir et", "type": "Person", "subtype": null, "offset": 15104, "length": 8, "score": 0.72 }, { "text": "Hubert", "type": "Person", "subtype": null, "offset": 15123, "length": 6, "score": 0.96 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 15144, "length": 3, "score": 0.97 }, { "text": "Chen", "type": "Person", "subtype": null, "offset": 15152, "length": 4, "score": 0.64 }, { "text": "Hoefer", "type": "Person", "subtype": null, "offset": 15170, "length": 6, "score": 0.96 }, { "text": "Gurbuj", "type": "Person", "subtype": null, "offset": 15190, "length": 6, "score": 0.93 }, { "text": "Toga", "type": "Person", "subtype": null, "offset": 15201, "length": 4, "score": 0.58 }, { "text": "Wriessnegger et al", "type": "Person", "subtype": null, "offset": 15213, "length": 18, "score": 0.66 }, { "text": "Wang et al", "type": "Person", "subtype": null, "offset": 15239, "length": 10, "score": 0.63 }, { "text": "Wolfe et", "type": "Person", "subtype": null, "offset": 15257, "length": 8, "score": 0.72 }, { "text": "Bosshard", "type": "Person", "subtype": null, "offset": 15276, "length": 8, "score": 0.96 }, { "text": "Fehse", "type": "Person", "subtype": null, "offset": 15299, "length": 5, "score": 0.97 }, { "text": "Price Çakar", "type": "Person", "subtype": null, "offset": 15319, "length": 11, "score": 0.84 }, { "text": "Marques et al", "type": "Person", "subtype": null, "offset": 15344, "length": 13, "score": 0.7 }, { "text": "Çakir et al.", "type": "Person", "subtype": null, "offset": 15365, "length": 12, "score": 0.66 }, { "text": "Gong et al", "type": "Person", "subtype": null, "offset": 15384, "length": 10, "score": 0.74 }, { "text": "Pilelienė", "type": "Person", "subtype": null, "offset": 15402, "length": 9, "score": 0.94 }, { "text": "Grigaliūnaitė", "type": "Person", "subtype": null, "offset": 15417, "length": 13, "score": 0.96 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 15437, "length": 3, "score": 0.96 }, { "text": "Chen", "type": "Person", "subtype": null, "offset": 15445, "length": 4, "score": 0.51 }, { "text": "Boccia", "type": "Person", "subtype": null, "offset": 15456, "length": 6, "score": 0.96 }, { "text": "Venkatraman", "type": "Person", "subtype": null, "offset": 15476, "length": 11, "score": 0.9 }, { "text": "Baldo", "type": "Person", "subtype": null, "offset": 15502, "length": 5, "score": 0.96 }, { "text": "Soria Morillo et al", "type": "Person", "subtype": null, "offset": 15532, "length": 19, "score": 0.73 }, { "text": "Yang et al", "type": "Person", "subtype": null, "offset": 15559, "length": 10, "score": 0.72 }, { "text": "Cherubino et al", "type": "Person", "subtype": null, "offset": 15577, "length": 15, "score": 0.77 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 15600, "length": 13, "score": 0.81 }, { "text": "al", "type": "Person", "subtype": null, "offset": 15618, "length": 2, "score": 0.61 }, { "text": "Vasiljević et al.", "type": "Person", "subtype": null, "offset": 15628, "length": 17, "score": 0.71 }, { "text": "Yang et", "type": "Person", "subtype": null, "offset": 15652, "length": 7, "score": 0.76 }, { "text": "Pilelienė", "type": "Person", "subtype": null, "offset": 15670, "length": 9, "score": 0.96 }, { "text": "Grigaliūnaitė", "type": "Person", "subtype": null, "offset": 15684, "length": 13, "score": 0.93 }, { "text": "Daugherty et", "type": "Person", "subtype": null, "offset": 15705, "length": 12, "score": 0.74 }, { "text": "Royo et", "type": "Person", "subtype": null, "offset": 15728, "length": 7, "score": 0.75 }, { "text": "Etzold", "type": "Person", "subtype": null, "offset": 15746, "length": 6, "score": 0.95 }, { "text": "Chen", "type": "Person", "subtype": null, "offset": 15766, "length": 4, "score": 0.97 }, { "text": "Casado-Aranda", "type": "Person", "subtype": null, "offset": 15785, "length": 13, "score": 0.96 }, { "text": "Randolph", "type": "Person", "subtype": null, "offset": 15812, "length": 8, "score": 0.95 }, { "text": "Pierquet", "type": "Person", "subtype": null, "offset": 15825, "length": 8, "score": 0.64 }, { "text": "Nomura", "type": "Person", "subtype": null, "offset": 15840, "length": 6, "score": 0.94 }, { "text": "Mitsukura", "type": "Person", "subtype": null, "offset": 15852, "length": 9, "score": 0.96 }, { "text": "Ungureanu et al", "type": "Person", "subtype": null, "offset": 15868, "length": 15, "score": 0.73 }, { "text": "Goyal", "type": "Person", "subtype": null, "offset": 15891, "length": 5, "score": 0.97 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 15901, "length": 5, "score": 0.82 }, { "text": "Oon et al", "type": "Person", "subtype": null, "offset": 15913, "length": 9, "score": 0.71 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 15931, "length": 5, "score": 0.95 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 16007, "length": 13, "score": 0.93 }, { "text": "Chew et al", "type": "Person", "subtype": null, "offset": 16034, "length": 10, "score": 0.67 }, { "text": "Cherubino et", "type": "Person", "subtype": null, "offset": 16052, "length": 12, "score": 0.76 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 16075, "length": 13, "score": 0.92 }, { "text": "Çakar", "type": "Person", "subtype": null, "offset": 16103, "length": 5, "score": 0.96 }, { "text": "Boksem", "type": "Person", "subtype": null, "offset": 16122, "length": 6, "score": 0.92 }, { "text": "Smitds", "type": "Person", "subtype": null, "offset": 16133, "length": 6, "score": 0.55 }, { "text": "Bhardwaj et al", "type": "Person", "subtype": null, "offset": 16146, "length": 14, "score": 0.63 }, { "text": "katraman", "type": "Person", "subtype": null, "offset": 16173, "length": 8, "score": 0.94 }, { "text": "Touchette", "type": "Person", "subtype": null, "offset": 16195, "length": 9, "score": 0.94 }, { "text": "Lee", "type": "Person", "subtype": null, "offset": 16209, "length": 3, "score": 0.7 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 16219, "length": 4, "score": 0.94 }, { "text": "Marques", "type": "Person", "subtype": null, "offset": 16237, "length": 7, "score": 0.95 }, { "text": "Gong et al", "type": "Person", "subtype": null, "offset": 16259, "length": 10, "score": 0.71 }, { "text": "Gordon et al", "type": "Person", "subtype": null, "offset": 16277, "length": 12, "score": 0.67 }, { "text": "Krampe et", "type": "Person", "subtype": null, "offset": 16297, "length": 9, "score": 0.79 }, { "text": "Hubert et", "type": "Person", "subtype": null, "offset": 16317, "length": 9, "score": 0.76 }, { "text": "Çakir", "type": "Person", "subtype": null, "offset": 16338, "length": 5, "score": 0.97 }, { "text": "Holst", "type": "Person", "subtype": null, "offset": 16357, "length": 5, "score": 0.95 }, { "text": "Henseler", "type": "Person", "subtype": null, "offset": 16367, "length": 8, "score": 0.67 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 16382, "length": 3, "score": 0.94 }, { "text": "Hoefer", "type": "Person", "subtype": null, "offset": 16402, "length": 6, "score": 0.97 }, { "text": "Chen et al", "type": "Person", "subtype": null, "offset": 16423, "length": 10, "score": 0.69 }, { "text": "Casado-Aranda et al", "type": "Person", "subtype": null, "offset": 16441, "length": 19, "score": 0.8 }, { "text": "Wang et", "type": "Person", "subtype": null, "offset": 16468, "length": 7, "score": 0.79 }, { "text": "Jain et", "type": "Person", "subtype": null, "offset": 16486, "length": 7, "score": 0.72 }, { "text": "Wolfe", "type": "Person", "subtype": null, "offset": 16505, "length": 5, "score": 0.97 }, { "text": "Bosshard", "type": "Person", "subtype": null, "offset": 16524, "length": 8, "score": 0.96 }, { "text": "Fehse", "type": "Person", "subtype": null, "offset": 16546, "length": 5, "score": 0.97 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 16612, "length": 13, "score": 0.87 }, { "text": "Yang et", "type": "Person", "subtype": null, "offset": 16639, "length": 7, "score": 0.73 }, { "text": "Chew et", "type": "Person", "subtype": null, "offset": 16657, "length": 7, "score": 0.79 }, { "text": "Cherubino et", "type": "Person", "subtype": null, "offset": 16675, "length": 12, "score": 0.74 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 16699, "length": 13, "score": 0.96 }, { "text": "Yadava", "type": "Person", "subtype": null, "offset": 16726, "length": 6, "score": 0.97 }, { "text": "Doborjeh et", "type": "Person", "subtype": null, "offset": 16746, "length": 11, "score": 0.73 }, { "text": "Çakar", "type": "Person", "subtype": null, "offset": 16768, "length": 5, "score": 0.96 }, { "text": "Kaur et al", "type": "Person", "subtype": null, "offset": 16788, "length": 10, "score": 0.64 }, { "text": "Baldo et", "type": "Person", "subtype": null, "offset": 16806, "length": 8, "score": 0.71 }, { "text": "Boksem", "type": "Person", "subtype": null, "offset": 16825, "length": 6, "score": 0.84 }, { "text": "Pozharliev", "type": "Person", "subtype": null, "offset": 16849, "length": 10, "score": 0.72 }, { "text": "Venkatraman", "type": "Person", "subtype": null, "offset": 16874, "length": 11, "score": 0.97 }, { "text": "Touchette", "type": "Person", "subtype": null, "offset": 16892, "length": 9, "score": 0.96 }, { "text": "Lee", "type": "Person", "subtype": null, "offset": 16906, "length": 3, "score": 0.8 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 16916, "length": 4, "score": 0.96 }, { "text": "Pilelienė", "type": "Person", "subtype": null, "offset": 16934, "length": 9, "score": 0.93 }, { "text": "Grigaliūnaitė", "type": "Person", "subtype": null, "offset": 16949, "length": 13, "score": 0.97 }, { "text": "Shen", "type": "Person", "subtype": null, "offset": 16969, "length": 4, "score": 0.97 }, { "text": "Daugherty et al", "type": "Person", "subtype": null, "offset": 16987, "length": 15, "score": 0.64 }, { "text": "Royo", "type": "Person", "subtype": null, "offset": 17010, "length": 4, "score": 0.96 }, { "text": "Gong", "type": "Person", "subtype": null, "offset": 17029, "length": 4, "score": 0.97 }, { "text": "Gordon", "type": "Person", "subtype": null, "offset": 17047, "length": 6, "score": 0.96 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 17067, "length": 3, "score": 0.96 }, { "text": "Chen et", "type": "Person", "subtype": null, "offset": 17075, "length": 7, "score": 0.61 }, { "text": "Hoefer", "type": "Person", "subtype": null, "offset": 17093, "length": 6, "score": 0.97 }, { "text": "Randolph", "type": "Person", "subtype": null, "offset": 17114, "length": 8, "score": 0.97 }, { "text": "Pierquet", "type": "Person", "subtype": null, "offset": 17127, "length": 8, "score": 0.87 }, { "text": "Nomura", "type": "Person", "subtype": null, "offset": 17142, "length": 6, "score": 0.93 }, { "text": "Mitsukura", "type": "Person", "subtype": null, "offset": 17153, "length": 9, "score": 0.66 }, { "text": "Bhardwaj", "type": "Person", "subtype": null, "offset": 17169, "length": 8, "score": 0.96 }, { "text": "Fan", "type": "Person", "subtype": null, "offset": 17192, "length": 3, "score": 0.96 }, { "text": "Touyama", "type": "Person", "subtype": null, "offset": 17200, "length": 7, "score": 0.75 }, { "text": "Rakshit", "type": "Person", "subtype": null, "offset": 17214, "length": 7, "score": 0.93 }, { "text": "Jain et al", "type": "Person", "subtype": null, "offset": 17239, "length": 10, "score": 0.68 }, { "text": "Ogino", "type": "Person", "subtype": null, "offset": 17256, "length": 5, "score": 0.88 }, { "text": "Mitsukura", "type": "Person", "subtype": null, "offset": 17267, "length": 9, "score": 0.96 }, { "text": "Oon et al", "type": "Person", "subtype": null, "offset": 17283, "length": 9, "score": 0.68 }, { "text": "Bosshard", "type": "Person", "subtype": null, "offset": 17300, "length": 8, "score": 0.97 }, { "text": "Venkatraman", "type": "Person", "subtype": null, "offset": 17328, "length": 11, "score": 0.95 }, { "text": "Marques et", "type": "Person", "subtype": null, "offset": 17353, "length": 10, "score": 0.75 }, { "text": "Hubert et", "type": "Person", "subtype": null, "offset": 17374, "length": 9, "score": 0.76 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 17394, "length": 3, "score": 0.95 }, { "text": "Cheng", "type": "Person", "subtype": null, "offset": 17402, "length": 5, "score": 0.8 }, { "text": "Chen et al", "type": "Person", "subtype": null, "offset": 17415, "length": 10, "score": 0.75 }, { "text": "Casado-Aranda et al", "type": "Person", "subtype": null, "offset": 17433, "length": 19, "score": 0.84 }, { "text": "Wang et al", "type": "Person", "subtype": null, "offset": 17460, "length": 10, "score": 0.71 }, { "text": "Wolfe", "type": "Person", "subtype": null, "offset": 17478, "length": 5, "score": 0.97 }, { "text": "Fehse", "type": "Person", "subtype": null, "offset": 17498, "length": 5, "score": 0.96 }, { "text": "Çakir", "type": "Person", "subtype": null, "offset": 17524, "length": 5, "score": 0.81 }, { "text": "Krampe", "type": "Person", "subtype": null, "offset": 17543, "length": 6, "score": 0.96 }, { "text": "EMG Missagila", "type": "Person", "subtype": null, "offset": 17564, "length": 13, "score": 0.68 }, { "text": "Venkatraman", "type": "Person", "subtype": null, "offset": 17604, "length": 11, "score": 0.95 }, { "text": "Rojas", "type": "Person", "subtype": null, "offset": 17622, "length": 5, "score": 0.98 }, { "text": "Pilelienė", "type": "Person", "subtype": null, "offset": 17641, "length": 9, "score": 0.94 }, { "text": "Grigaliūnaitė", "type": "Person", "subtype": null, "offset": 17655, "length": 13, "score": 0.88 }, { "text": "Çakar", "type": "Person", "subtype": null, "offset": 17675, "length": 5, "score": 0.95 }, { "text": "Ceravolo", "type": "Person", "subtype": null, "offset": 17695, "length": 8, "score": 0.96 }, { "text": "Ungureanu et", "type": "Person", "subtype": null, "offset": 17717, "length": 12, "score": 0.72 }, { "text": "Cherubino et al", "type": "Person", "subtype": null, "offset": 17778, "length": 15, "score": 0.68 }, { "text": "Çakar", "type": "Person", "subtype": null, "offset": 17801, "length": 5, "score": 0.97 }, { "text": "Magdin et al", "type": "Person", "subtype": null, "offset": 17820, "length": 12, "score": 0.65 }, { "text": "Goyal", "type": "Person", "subtype": null, "offset": 17840, "length": 5, "score": 0.97 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 17850, "length": 5, "score": 0.72 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 17863, "length": 5, "score": 0.95 }, { "text": "Cherubino", "type": "Person", "subtype": null, "offset": 17929, "length": 9, "score": 0.95 }, { "text": "Bhardwaj", "type": "Person", "subtype": null, "offset": 17952, "length": 8, "score": 0.97 }, { "text": "Venkatraman", "type": "Person", "subtype": null, "offset": 17974, "length": 11, "score": 0.96 }, { "text": "Pozharliev", "type": "Person", "subtype": null, "offset": 17992, "length": 10, "score": 0.98 }, { "text": "Boksem", "type": "Person", "subtype": null, "offset": 18017, "length": 6, "score": 0.93 }, { "text": "Wriessnegger", "type": "Person", "subtype": null, "offset": 18041, "length": 12, "score": 0.96 }, { "text": "Fan", "type": "Person", "subtype": null, "offset": 18067, "length": 3, "score": 0.92 }, { "text": "Touyama", "type": "Person", "subtype": null, "offset": 18075, "length": 7, "score": 0.74 }, { "text": "Pilelienė", "type": "Person", "subtype": null, "offset": 18090, "length": 9, "score": 0.89 }, { "text": "Grigaliūnaitė", "type": "Person", "subtype": null, "offset": 18104, "length": 13, "score": 0.74 }, { "text": "Yadava et", "type": "Person", "subtype": null, "offset": 18124, "length": 9, "score": 0.71 }, { "text": "Baldo", "type": "Person", "subtype": null, "offset": 18144, "length": 5, "score": 0.95 }, { "text": "Clerico et al", "type": "Person", "subtype": null, "offset": 18164, "length": 13, "score": 0.67 }, { "text": "Chen et al", "type": "Person", "subtype": null, "offset": 18185, "length": 10, "score": 0.72 }, { "text": "Casado-Aranda et al", "type": "Person", "subtype": null, "offset": 18203, "length": 19, "score": 0.82 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 18230, "length": 3, "score": 0.97 }, { "text": "Cheng", "type": "Person", "subtype": null, "offset": 18238, "length": 5, "score": 0.73 }, { "text": "Taqwa et al", "type": "Person", "subtype": null, "offset": 18251, "length": 11, "score": 0.76 }, { "text": "Bhardwaj et al", "type": "Person", "subtype": null, "offset": 18270, "length": 14, "score": 0.68 }, { "text": "Wang et al", "type": "Person", "subtype": null, "offset": 18291, "length": 10, "score": 0.72 }, { "text": "Rakshit", "type": "Person", "subtype": null, "offset": 18309, "length": 7, "score": 0.95 }, { "text": "Goyal", "type": "Person", "subtype": null, "offset": 18335, "length": 5, "score": 0.97 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 18345, "length": 5, "score": 0.82 }, { "text": "Jain et al.", "type": "Person", "subtype": null, "offset": 18357, "length": 11, "score": 0.68 }, { "text": "Oon et al.", "type": "Person", "subtype": null, "offset": 18375, "length": 10, "score": 0.67 }, { "text": "Fehse et al", "type": "Person", "subtype": null, "offset": 18392, "length": 11, "score": 0.68 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 18463, "length": 13, "score": 0.86 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 18490, "length": 4, "score": 0.96 }, { "text": "Chew", "type": "Person", "subtype": null, "offset": 18508, "length": 4, "score": 0.96 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 18526, "length": 13, "score": 0.93 }, { "text": "Yadava et al", "type": "Person", "subtype": null, "offset": 18554, "length": 12, "score": 0.67 }, { "text": "Doborjeh", "type": "Person", "subtype": null, "offset": 18574, "length": 8, "score": 0.98 }, { "text": "Gordon", "type": "Person", "subtype": null, "offset": 18596, "length": 6, "score": 0.97 }, { "text": "Gurbuj", "type": "Person", "subtype": null, "offset": 18609, "length": 6, "score": 0.96 }, { "text": "Toga", "type": "Person", "subtype": null, "offset": 18620, "length": 4, "score": 0.81 }, { "text": "Wriessnegger et al", "type": "Person", "subtype": null, "offset": 18632, "length": 18, "score": 0.63 }, { "text": "Wang et al", "type": "Person", "subtype": null, "offset": 18658, "length": 10, "score": 0.65 }, { "text": "Taqwa et al", "type": "Person", "subtype": null, "offset": 18676, "length": 11, "score": 0.68 }, { "text": "Bhardwaj", "type": "Person", "subtype": null, "offset": 18695, "length": 8, "score": 0.96 }, { "text": "Randolph", "type": "Person", "subtype": null, "offset": 18718, "length": 8, "score": 0.97 }, { "text": "Pierquet", "type": "Person", "subtype": null, "offset": 18731, "length": 8, "score": 0.79 }, { "text": "Fan", "type": "Person", "subtype": null, "offset": 18746, "length": 3, "score": 0.96 }, { "text": "Touyama", "type": "Person", "subtype": null, "offset": 18754, "length": 7, "score": 0.89 }, { "text": "Rakshit", "type": "Person", "subtype": null, "offset": 18768, "length": 7, "score": 0.96 }, { "text": "Lahiri", "type": "Person", "subtype": null, "offset": 18780, "length": 6, "score": 0.69 }, { "text": "Goyal", "type": "Person", "subtype": null, "offset": 18794, "length": 5, "score": 0.97 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 18804, "length": 5, "score": 0.58 }, { "text": "Jain et al.", "type": "Person", "subtype": null, "offset": 18816, "length": 11, "score": 0.69 }, { "text": "Ogino", "type": "Person", "subtype": null, "offset": 18834, "length": 5, "score": 0.96 }, { "text": "Oon", "type": "Person", "subtype": null, "offset": 18860, "length": 3, "score": 0.85 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 18878, "length": 5, "score": 0.94 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 18951, "length": 4, "score": 0.8 }, { "text": "7:10", "type": "DateTime", "subtype": "Time", "offset": 18957, "length": 4, "score": 0.8 }, { "text": "subjects", "type": "PersonType", "subtype": null, "offset": 18965, "length": 8, "score": 0.5 }, { "text": "last 5 years", "type": "DateTime", "subtype": "DateRange", "offset": 19729, "length": 12, "score": 0.8 }, { "text": "test subjects", "type": "PersonType", "subtype": null, "offset": 20025, "length": 13, "score": 0.52 }, { "text": "participants", "type": "PersonType", "subtype": null, "offset": 20137, "length": 12, "score": 0.8 }, { "text": "researchers", "type": "PersonType", "subtype": null, "offset": 20404, "length": 11, "score": 0.59 }, { "text": "Nemorin", "type": "Person", "subtype": null, "offset": 20578, "length": 7, "score": 0.91 }, { "text": "Neuromarket", "type": "Organization", "subtype": null, "offset": 20606, "length": 11, "score": 0.78 }, { "text": "last 5  years", "type": "DateTime", "subtype": "DateRange", "offset": 20771, "length": 13, "score": 0.8 }, { "text": "consumer", "type": "PersonType", "subtype": null, "offset": 20955, "length": 8, "score": 0.63 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 21065, "length": 2, "score": 0.8 }, { "text": "Chew", "type": "Person", "subtype": null, "offset": 21547, "length": 4, "score": 0.97 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 21684, "length": 2, "score": 0.8 }, { "text": "authors", "type": "PersonType", "subtype": null, "offset": 21774, "length": 7, "score": 0.89 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 21840, "length": 2, "score": 0.8 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 21889, "length": 2, "score": 0.8 }, { "text": "3D", "type": "DateTime", "subtype": "Duration", "offset": 21960, "length": 2, "score": 0.8 }, { "text": "Yadava", "type": "Person", "subtype": null, "offset": 22156, "length": 6, "score": 0.98 }, { "text": "Çakar", "type": "Person", "subtype": null, "offset": 22174, "length": 5, "score": 0.97 }, { "text": "test", "type": "PersonType", "subtype": null, "offset": 22457, "length": 4, "score": 0.62 }, { "text": "participants", "type": "PersonType", "subtype": null, "offset": 22462, "length": 12, "score": 0.65 }, { "text": "Çakar", "type": "Person", "subtype": null, "offset": 22737, "length": 5, "score": 0.72 }, { "text": "time", "type": "PersonType", "subtype": null, "offset": 22838, "length": 4, "score": 0.5 }, { "text": "buyers", "type": "PersonType", "subtype": null, "offset": 22843, "length": 6, "score": 0.86 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 23379, "length": 3, "score": 0.8 }, { "text": "Baldo", "type": "Person", "subtype": null, "offset": 23767, "length": 5, "score": 0.9 }, { "text": "Touchette", "type": "Person", "subtype": null, "offset": 24365, "length": 9, "score": 0.93 }, { "text": "Lee", "type": "Person", "subtype": null, "offset": 24379, "length": 3, "score": 0.95 }, { "text": "Davidson", "type": "Person", "subtype": null, "offset": 24466, "length": 8, "score": 0.98 }, { "text": "Pozharliev", "type": "Person", "subtype": null, "offset": 24680, "length": 10, "score": 0.95 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 24772, "length": 4, "score": 0.8 }, { "text": "7:10", "type": "DateTime", "subtype": "Time", "offset": 24778, "length": 4, "score": 0.8 }, { "text": "marketers", "type": "PersonType", "subtype": null, "offset": 25232, "length": 9, "score": 0.83 }, { "text": "Bosshard", "type": "Person", "subtype": null, "offset": 25243, "length": 8, "score": 0.97 }, { "text": "Fehse", "type": "Person", "subtype": null, "offset": 25263, "length": 5, "score": 0.98 }, { "text": "Bosshard", "type": "Person", "subtype": null, "offset": 25442, "length": 8, "score": 0.98 }, { "text": "Fehse", "type": "Person", "subtype": null, "offset": 25735, "length": 5, "score": 0.94 }, { "text": "may", "type": "DateTime", "subtype": "DateRange", "offset": 25898, "length": 3, "score": 0.8 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 26067, "length": 4, "score": 0.89 }, { "text": "Çakar", "type": "Person", "subtype": null, "offset": 26217, "length": 5, "score": 0.86 }, { "text": "Marques et", "type": "Person", "subtype": null, "offset": 26336, "length": 10, "score": 0.73 }, { "text": "Çakir", "type": "Person", "subtype": null, "offset": 26357, "length": 5, "score": 0.96 }, { "text": "Gong", "type": "Person", "subtype": null, "offset": 26376, "length": 4, "score": 0.96 }, { "text": "Pilelienė", "type": "Person", "subtype": null, "offset": 26395, "length": 9, "score": 0.93 }, { "text": "Grigaliūnaitė", "type": "Person", "subtype": null, "offset": 26409, "length": 13, "score": 0.9 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 26429, "length": 3, "score": 0.96 }, { "text": "Chen", "type": "Person", "subtype": null, "offset": 26437, "length": 4, "score": 0.94 }, { "text": "Boccia", "type": "Person", "subtype": null, "offset": 26449, "length": 6, "score": 0.97 }, { "text": "Venkatraman", "type": "Person", "subtype": null, "offset": 26469, "length": 11, "score": 0.97 }, { "text": "Baldo et", "type": "Person", "subtype": null, "offset": 26498, "length": 8, "score": 0.7 }, { "text": "Boccia", "type": "Person", "subtype": null, "offset": 26631, "length": 6, "score": 0.96 }, { "text": "consumer", "type": "PersonType", "subtype": null, "offset": 26721, "length": 8, "score": 0.72 }, { "text": "Consumers", "type": "PersonType", "subtype": null, "offset": 26885, "length": 9, "score": 0.68 }, { "text": "Marques", "type": "Person", "subtype": null, "offset": 27007, "length": 7, "score": 0.95 }, { "text": "Gong", "type": "Person", "subtype": null, "offset": 27402, "length": 4, "score": 0.92 }, { "text": "mar", "type": "DateTime", "subtype": "DateRange", "offset": 27597, "length": 3, "score": 0.8 }, { "text": "Hsu", "type": "Person", "subtype": null, "offset": 27739, "length": 3, "score": 0.9 }, { "text": "Chen", "type": "Person", "subtype": null, "offset": 27747, "length": 4, "score": 0.95 }, { "text": "consumers", "type": "PersonType", "subtype": null, "offset": 28120, "length": 9, "score": 0.95 }, { "text": "consumer", "type": "PersonType", "subtype": null, "offset": 28312, "length": 8, "score": 0.7 }, { "text": "2015", "type": "DateTime", "subtype": "DateRange", "offset": 28482, "length": 4, "score": 0.8 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 28488, "length": 4, "score": 0.97 }, { "text": "mon", "type": "DateTime", "subtype": "Date", "offset": 28754, "length": 3, "score": 0.8 }, { "text": "10 s", "type": "DateTime", "subtype": "DateRange", "offset": 29002, "length": 4, "score": 0.8 }, { "text": "participants", "type": "PersonType", "subtype": null, "offset": 29145, "length": 12, "score": 0.9 }, { "text": "Soria Morillo", "type": "Person", "subtype": null, "offset": 29194, "length": 13, "score": 0.92 }, { "text": "audiences", "type": "PersonType", "subtype": null, "offset": 29328, "length": 9, "score": 0.64 }, { "text": "Cherubino", "type": "Person", "subtype": null, "offset": 29533, "length": 9, "score": 0.95 }, { "text": "Vasiljević", "type": "Person", "subtype": null, "offset": 29872, "length": 10, "score": 0.99 }, { "text": "Nestle", "type": "Organization", "subtype": null, "offset": 29902, "length": 6, "score": 0.91 }, { "text": "Daugherty", "type": "Person", "subtype": null, "offset": 29978, "length": 9, "score": 0.96 }, { "text": "Krugman", "type": "Person", "subtype": null, "offset": 30030, "length": 7, "score": 0.98 }, { "text": "1971", "type": "DateTime", "subtype": "DateRange", "offset": 30039, "length": 4, "score": 0.8 }, { "text": "consumers", "type": "PersonType", "subtype": null, "offset": 30125, "length": 9, "score": 0.86 }, { "text": "Venkatraman", "type": "Person", "subtype": null, "offset": 30464, "length": 11, "score": 0.97 }, { "text": "2020", "type": "DateTime", "subtype": "DateRange", "offset": 30600, "length": 4, "score": 0.8 }, { "text": "7:10", "type": "DateTime", "subtype": "Time", "offset": 30606, "length": 4, "score": 0.8 }, { "text": "Randolph", "type": "Person", "subtype": null, "offset": 30653, "length": 8, "score": 0.92 }, { "text": "Pierquet", "type": "Person", "subtype": null, "offset": 30667, "length": 8, "score": 0.96 }, { "text": "test", "type": "PersonType", "subtype": null, "offset": 30819, "length": 4, "score": 0.52 }, { "text": "Nomura", "type": "Person", "subtype": null, "offset": 30835, "length": 6, "score": 0.95 }, { "text": "Mitsukura", "type": "Person", "subtype": null, "offset": 30846, "length": 9, "score": 0.96 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 31090, "length": 5, "score": 0.96 }, { "text": "Ungureanu", "type": "Person", "subtype": null, "offset": 31234, "length": 9, "score": 0.94 }, { "text": "Goyal", "type": "Person", "subtype": null, "offset": 31381, "length": 5, "score": 0.98 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 31391, "length": 5, "score": 0.96 }, { "text": "user", "type": "PersonType", "subtype": null, "offset": 31578, "length": 4, "score": 0.74 }, { "text": "Singh", "type": "Person", "subtype": null, "offset": 31595, "length": 5, "score": 0.95 }, { "text": "audiences", "type": "PersonType", "subtype": null, "offset": 31672, "length": 9, "score": 0.75 }, { "text": "TVC", "type": "Organization", "subtype": null, "offset": 31696, "length": 3, "score": 0.8 }, { "text": "30 s", "type": "DateTime", "subtype": "DateRange", "offset": 31771, "length": 4, "score": 0.8 }, { "text": "consumers", "type": "PersonType", "subtype": null, "offset": 31935, "length": 9, "score": 0.96 }, { "text": "Chen", "type": "Person", "subtype": null, "offset": 32269, "length": 4, "score": 0.97 }, { "text": "Yang", "type": "Person", "subtype": null, "offset": 32481, "length": 4, "score": 0.95 }, { "text": "smokers", "type": "PersonType", "subtype": null, "offset": 32580, "length": 7, "score": 0.88 }, { "text": "non-smokers", "type": "PersonType", "subtype": null, "offset": 32592, "length": 11, "score": 0.64 } ] } ] }